{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d9f2b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e8f5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('healthcare-dataset-stroke-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17e9a36b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9046</td>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51676</td>\n",
       "      <td>Female</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>202.21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31112</td>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60182</td>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1665</td>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  gender   age  hypertension  heart_disease ever_married  \\\n",
       "0   9046    Male  67.0             0              1          Yes   \n",
       "1  51676  Female  61.0             0              0          Yes   \n",
       "2  31112    Male  80.0             0              1          Yes   \n",
       "3  60182  Female  49.0             0              0          Yes   \n",
       "4   1665  Female  79.0             1              0          Yes   \n",
       "\n",
       "       work_type Residence_type  avg_glucose_level   bmi   smoking_status  \\\n",
       "0        Private          Urban             228.69  36.6  formerly smoked   \n",
       "1  Self-employed          Rural             202.21   NaN     never smoked   \n",
       "2        Private          Rural             105.92  32.5     never smoked   \n",
       "3        Private          Urban             171.23  34.4           smokes   \n",
       "4  Self-employed          Rural             174.12  24.0     never smoked   \n",
       "\n",
       "   stroke  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35aff756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee1eb6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "      <td>4909.000000</td>\n",
       "      <td>5110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.226614</td>\n",
       "      <td>0.097456</td>\n",
       "      <td>0.054012</td>\n",
       "      <td>106.147677</td>\n",
       "      <td>28.893237</td>\n",
       "      <td>0.048728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.612647</td>\n",
       "      <td>0.296607</td>\n",
       "      <td>0.226063</td>\n",
       "      <td>45.283560</td>\n",
       "      <td>7.854067</td>\n",
       "      <td>0.215320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.120000</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.245000</td>\n",
       "      <td>23.500000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.885000</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>114.090000</td>\n",
       "      <td>33.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>271.740000</td>\n",
       "      <td>97.600000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age  hypertension  heart_disease  avg_glucose_level  \\\n",
       "count  5110.000000   5110.000000    5110.000000        5110.000000   \n",
       "mean     43.226614      0.097456       0.054012         106.147677   \n",
       "std      22.612647      0.296607       0.226063          45.283560   \n",
       "min       0.080000      0.000000       0.000000          55.120000   \n",
       "25%      25.000000      0.000000       0.000000          77.245000   \n",
       "50%      45.000000      0.000000       0.000000          91.885000   \n",
       "75%      61.000000      0.000000       0.000000         114.090000   \n",
       "max      82.000000      1.000000       1.000000         271.740000   \n",
       "\n",
       "               bmi       stroke  \n",
       "count  4909.000000  5110.000000  \n",
       "mean     28.893237     0.048728  \n",
       "std       7.854067     0.215320  \n",
       "min      10.300000     0.000000  \n",
       "25%      23.500000     0.000000  \n",
       "50%      28.100000     0.000000  \n",
       "75%      33.100000     0.000000  \n",
       "max      97.600000     1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bb6c36e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                 0\n",
       "age                    0\n",
       "hypertension           0\n",
       "heart_disease          0\n",
       "ever_married           0\n",
       "work_type              0\n",
       "Residence_type         0\n",
       "avg_glucose_level      0\n",
       "bmi                  201\n",
       "smoking_status         0\n",
       "stroke                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e3baab0",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                object\n",
       "age                  float64\n",
       "hypertension           int64\n",
       "heart_disease          int64\n",
       "ever_married          object\n",
       "work_type             object\n",
       "Residence_type        object\n",
       "avg_glucose_level    float64\n",
       "bmi                  float64\n",
       "smoking_status        object\n",
       "stroke                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de377872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continuous = df[['age', 'avg_glucose_level', 'bmi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee210f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing values where gender = 'Other'\n",
    "df = df[df['gender'] != 'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acb5fa07",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.894559902200502\n",
      "30.47129186602871\n",
      "28.824430729942552\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gender               0\n",
       "age                  0\n",
       "hypertension         0\n",
       "heart_disease        0\n",
       "ever_married         0\n",
       "work_type            0\n",
       "Residence_type       0\n",
       "avg_glucose_level    0\n",
       "bmi                  0\n",
       "smoking_status       0\n",
       "stroke               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bmi_mean = df['bmi'].mean()\n",
    "print(bmi_mean)\n",
    "\n",
    "stroke_mean_bmi = df.loc[df['stroke'] == 1, 'bmi'].mean()\n",
    "print(stroke_mean_bmi)\n",
    "\n",
    "nonstroke_mean_bmi = df.loc[df['stroke'] == 0, 'bmi'].mean()\n",
    "print(nonstroke_mean_bmi)\n",
    "\n",
    "df.loc[(df['stroke'] == 1) & (df['bmi'].isnull()), 'bmi'] = stroke_mean_bmi\n",
    "df.loc[(df['stroke'] == 0) & (df['bmi'].isnull()), 'bmi'] = nonstroke_mean_bmi\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "564736a2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Removing unknown smokers\n",
    "df= df[df['smoking_status'] != 'Unknown']\n",
    "stroke_counts = df['stroke'].value_counts()\n",
    "\n",
    "# Plot a pie chart of stroke values\n",
    "plt.pie(stroke_counts, labels=['No Stroke', 'Stroke'], autopct='%1.1f%%')\n",
    "plt.title('Stroke Value Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe1b2782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['gender','ever_married','work_type','Residence_type','smoking_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dc0c13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crossing age and bmi due to moderate correlation to capture any interactions\n",
    "df['age_bmi'] = df['age'] * df['bmi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "993b1834",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>gender_Female</th>\n",
       "      <th>gender_Male</th>\n",
       "      <th>ever_married_No</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>...</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>Residence_type_Rural</th>\n",
       "      <th>Residence_type_Urban</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "      <th>age_bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2452.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202.21</td>\n",
       "      <td>30.471292</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1858.748804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1685.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1896.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  hypertension  heart_disease  avg_glucose_level        bmi  stroke  \\\n",
       "0  67.0             0              1             228.69  36.600000       1   \n",
       "1  61.0             0              0             202.21  30.471292       1   \n",
       "2  80.0             0              1             105.92  32.500000       1   \n",
       "3  49.0             0              0             171.23  34.400000       1   \n",
       "4  79.0             1              0             174.12  24.000000       1   \n",
       "\n",
       "   gender_Female  gender_Male  ever_married_No  ever_married_Yes  ...  \\\n",
       "0              0            1                0                 1  ...   \n",
       "1              1            0                0                 1  ...   \n",
       "2              0            1                0                 1  ...   \n",
       "3              1            0                0                 1  ...   \n",
       "4              1            0                0                 1  ...   \n",
       "\n",
       "   work_type_Never_worked  work_type_Private  work_type_Self-employed  \\\n",
       "0                       0                  1                        0   \n",
       "1                       0                  0                        1   \n",
       "2                       0                  1                        0   \n",
       "3                       0                  1                        0   \n",
       "4                       0                  0                        1   \n",
       "\n",
       "   work_type_children  Residence_type_Rural  Residence_type_Urban  \\\n",
       "0                   0                     0                     1   \n",
       "1                   0                     1                     0   \n",
       "2                   0                     1                     0   \n",
       "3                   0                     0                     1   \n",
       "4                   0                     1                     0   \n",
       "\n",
       "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                               1                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            1   \n",
       "3                               0                            0   \n",
       "4                               0                            1   \n",
       "\n",
       "   smoking_status_smokes      age_bmi  \n",
       "0                      0  2452.200000  \n",
       "1                      0  1858.748804  \n",
       "2                      0  2600.000000  \n",
       "3                      1  1685.600000  \n",
       "4                      0  1896.000000  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1840a8b4",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "56f4eb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing standardization on continuous variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fit the StandardScaler to the training data\n",
    "scaler = StandardScaler()\n",
    "df[['age', 'avg_glucose_level', 'bmi']] = scaler.fit_transform(df[['age', 'avg_glucose_level', 'bmi']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb31e20",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42e05175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Variable Name    T stats   P-value\n",
      "0                           stroke        inf       0.0\n",
      "1                              age  15.462421       0.0\n",
      "2                          age_bmi  13.159806       0.0\n",
      "3                     hypertension   8.114004       0.0\n",
      "4                    heart_disease   7.785221       0.0\n",
      "5                avg_glucose_level    7.75112       0.0\n",
      "6                 ever_married_Yes   4.669437  0.000003\n",
      "7                  ever_married_No  -4.669437  0.000003\n",
      "8          work_type_Self-employed   3.623796  0.000294\n",
      "9   smoking_status_formerly smoked   3.344438  0.000833\n",
      "10     smoking_status_never smoked  -2.498859  0.012504\n",
      "11              work_type_children  -2.056443  0.039813\n",
      "12               work_type_Private  -1.421657  0.155213\n",
      "13              work_type_Govt_job  -1.077795  0.281198\n",
      "14                   gender_Female  -0.930103  0.352381\n",
      "15                     gender_Male   0.930103  0.352381\n",
      "16          work_type_Never_worked  -0.918672   0.35833\n",
      "17                             bmi   0.791663   0.42861\n",
      "18           smoking_status_smokes  -0.472141  0.636855\n",
      "19            Residence_type_Rural   -0.46578  0.641402\n",
      "20            Residence_type_Urban    0.46578  0.641402\n"
     ]
    }
   ],
   "source": [
    "numeric = df.select_dtypes(include=np.number).columns.tolist()\n",
    "tstats_df = pd.DataFrame()\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "for eachvariable in numeric:\n",
    "    tstats = stats.ttest_ind(df.loc[df[\"stroke\"] == 1, eachvariable], df.loc[df[\"stroke\"] == 0, eachvariable])\n",
    "    temp = pd.DataFrame([eachvariable, tstats[0], tstats[1]]).T\n",
    "    temp.columns = [\"Variable Name\", \"T stats\", \" P-value\"]\n",
    "    tstats_df = pd.concat([tstats_df, temp], axis = 0, ignore_index= True)\n",
    "tstats_df = tstats_df.sort_values(by=\" P-value\").reset_index(drop=True)\n",
    "print(tstats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ee95f2",
   "metadata": {},
   "source": [
    "## Removing Residence Type, Gender, and BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7af9adeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>stroke</th>\n",
       "      <th>ever_married_No</th>\n",
       "      <th>ever_married_Yes</th>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <th>work_type_Never_worked</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "      <th>age_bmi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.961273</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.479202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2452.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.643316</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.930834</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1858.748804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.650179</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.063211</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.289277</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1685.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.597186</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.349126</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1896.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5102</th>\n",
       "      <td>0.431345</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.642849</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1236.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5105</th>\n",
       "      <td>1.650179</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.522324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2305.954458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5106</th>\n",
       "      <td>1.703172</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.336054</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107</th>\n",
       "      <td>-0.734496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.538062</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1071.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>0.113388</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.186976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1305.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3565 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  hypertension  heart_disease  avg_glucose_level  stroke  \\\n",
       "0     0.961273             0              1           2.479202       1   \n",
       "1     0.643316             0              0           1.930834       1   \n",
       "2     1.650179             0              1          -0.063211       1   \n",
       "3     0.007403             0              0           1.289277       1   \n",
       "4     1.597186             1              0           1.349126       1   \n",
       "...        ...           ...            ...                ...     ...   \n",
       "5102  0.431345             0              0          -0.642849       0   \n",
       "5105  1.650179             1              0          -0.522324       0   \n",
       "5106  1.703172             0              0           0.336054       0   \n",
       "5107 -0.734496             0              0          -0.538062       0   \n",
       "5108  0.113388             0              0           1.186976       0   \n",
       "\n",
       "      ever_married_No  ever_married_Yes  work_type_Govt_job  \\\n",
       "0                   0                 1                   0   \n",
       "1                   0                 1                   0   \n",
       "2                   0                 1                   0   \n",
       "3                   0                 1                   0   \n",
       "4                   0                 1                   0   \n",
       "...               ...               ...                 ...   \n",
       "5102                0                 1                   0   \n",
       "5105                0                 1                   0   \n",
       "5106                0                 1                   0   \n",
       "5107                0                 1                   0   \n",
       "5108                0                 1                   0   \n",
       "\n",
       "      work_type_Never_worked  work_type_Private  work_type_Self-employed  \\\n",
       "0                          0                  1                        0   \n",
       "1                          0                  0                        1   \n",
       "2                          0                  1                        0   \n",
       "3                          0                  1                        0   \n",
       "4                          0                  0                        1   \n",
       "...                      ...                ...                      ...   \n",
       "5102                       0                  1                        0   \n",
       "5105                       0                  1                        0   \n",
       "5106                       0                  0                        1   \n",
       "5107                       0                  0                        1   \n",
       "5108                       0                  1                        0   \n",
       "\n",
       "      work_type_children  smoking_status_formerly smoked  \\\n",
       "0                      0                               1   \n",
       "1                      0                               0   \n",
       "2                      0                               0   \n",
       "3                      0                               0   \n",
       "4                      0                               0   \n",
       "...                  ...                             ...   \n",
       "5102                   0                               0   \n",
       "5105                   0                               0   \n",
       "5106                   0                               0   \n",
       "5107                   0                               0   \n",
       "5108                   0                               1   \n",
       "\n",
       "      smoking_status_never smoked  smoking_status_smokes      age_bmi  \n",
       "0                               0                      0  2452.200000  \n",
       "1                               1                      0  1858.748804  \n",
       "2                               1                      0  2600.000000  \n",
       "3                               0                      1  1685.600000  \n",
       "4                               1                      0  1896.000000  \n",
       "...                           ...                    ...          ...  \n",
       "5102                            1                      0  1236.900000  \n",
       "5105                            1                      0  2305.954458  \n",
       "5106                            1                      0  3240.000000  \n",
       "5107                            1                      0  1071.000000  \n",
       "5108                            0                      0  1305.600000  \n",
       "\n",
       "[3565 rows x 16 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_drop = ['Residence_type_Rural', 'Residence_type_Urban', 'gender_Male', 'gender_Female', 'bmi']\n",
    "df2 = df.drop(to_drop, axis=1)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71273ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=109)\n",
    "\n",
    "X_df2 = df2.drop('stroke', axis=1)\n",
    "y_df2 = df2['stroke']\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_df2, y_df2, test_size=0.3, random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f06a7785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before resampling: \n",
      "0    2339\n",
      "1     156\n",
      "Name: stroke, dtype: int64\n",
      "After resampling: \n",
      "0    2339\n",
      "1    1169\n",
      "Name: stroke, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# For original data set\n",
    "# Instantiate SMOTE object\n",
    "smote = SMOTE(random_state = 42, sampling_strategy = 0.5)\n",
    "\n",
    "# Resample the data\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print the number of samples in each class before and after resampling\n",
    "print(f\"Before resampling: \\n{y_train.value_counts()}\")\n",
    "print(f\"After resampling: \\n{y_resampled.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "748beeea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before resampling: \n",
      "0    2339\n",
      "1     156\n",
      "Name: stroke, dtype: int64\n",
      "After resampling: \n",
      "0    2339\n",
      "1    1169\n",
      "Name: stroke, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# for dataset without Residence Type, Gender, BMI\n",
    "\n",
    "# Instantiate SMOTE object\n",
    "smote = SMOTE(random_state = 42, sampling_strategy = 0.5)\n",
    "\n",
    "# Resample the data\n",
    "X_resampled2, y_resampled2 = smote.fit_resample(X_train2, y_train2)\n",
    "\n",
    "# Print the number of samples in each class before and after resampling\n",
    "print(f\"Before resampling: \\n{y_train2.value_counts()}\")\n",
    "print(f\"After resampling: \\n{y_resampled.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ecaad4",
   "metadata": {},
   "source": [
    "## Function for Model Classification Results (for Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c113a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to print out model's classification results \n",
    "def get_model_results_nn(classifier, predictions, y_pred, y_test):\n",
    "    \n",
    "    print(\"Results for \"+ classifier)\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(y_test,y_pred))\n",
    "    print(\"Recall:\", metrics.recall_score(y_test,y_pred))\n",
    "    print(\"Precision:\", metrics.precision_score(y_test,y_pred))\n",
    "    print(\"F1 Score:\", metrics.f1_score(y_test,y_pred))\n",
    "\n",
    "    # confusion matrix \n",
    "    cfn_matrix = metrics.confusion_matrix(y_test,y_pred,labels=[1,0])\n",
    "    print(\"\\nConfusion Matrix:\\n\")\n",
    "    print(cfn_matrix)\n",
    "\n",
    "    # Classification Report \n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test,y_pred)\n",
    "    recall = metrics.recall_score(y_test,y_pred)\n",
    "    precision = metrics.precision_score(y_test,y_pred)\n",
    "    f1 = metrics.f1_score(y_test,y_pred)\n",
    "    results = [accuracy, recall, precision, f1]\n",
    "\n",
    "    print(results)\n",
    "    # print the auc curve and show auc score \n",
    "    \n",
    "    # predicted probabilities of class 1 \n",
    "    by_pred_prob_model = predictions.ravel()\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, by_pred_prob_model)\n",
    "    auc = metrics.roc_auc_score(y_test, by_pred_prob_model)\n",
    "    \n",
    "    # plot roc curve \n",
    "    plt.plot(fpr, tpr, label='AUC = %0.2f' % auc)\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Random guessing')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde52c77",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe12613",
   "metadata": {},
   "source": [
    "### Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9269c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.layers as layers\n",
    "import keras.models\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "44db98e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Dense(11, activation='relu', input_dim=20))\n",
    "    model.add(layers.Dense(7, activation='relu', input_dim=20))\n",
    "    model.add(layers.Dense(5, activation='relu', input_dim=20))\n",
    "    model.add(layers.Dense(1, activation='sigmoid', name='predictions'))\n",
    "    # return model without compile\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(109)\n",
    "\n",
    "# hyperparameter tuning\n",
    "\n",
    "# create model\n",
    "model = KerasClassifier(model=create_model, loss=\"binary_crossentropy\", verbose=False, optimizer = keras.optimizers.Adam(lr=1e-5))\n",
    "\n",
    "# define the grid search parameters\n",
    "epochs = [250, 500, 750, 1000]\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "param_grid = dict(epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='f1')\n",
    "grid_result = grid.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b56d528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper parameters: {'batch_size': 10, 'epochs': 1000} Score 0.8032003892923794\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print('Best hyper parameters:', grid.best_params_, 'Score', grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9d6c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.Dense(11, activation='relu'))\n",
    "model.add(layers.Dense(7, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid', name='predictions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9f2877be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=keras.optimizers.Adam(lr=1e-5), \n",
    "              metrics=['accuracy',\n",
    "                       keras.metrics.Precision(name='precision'),\n",
    "                       keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84c3cd81",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "351/351 [==============================] - 0s 747us/step - loss: 0.2287 - accuracy: 0.9156 - precision: 0.9440 - recall: 0.7938\n",
      "Epoch 2/1000\n",
      "351/351 [==============================] - 0s 558us/step - loss: 0.2280 - accuracy: 0.9145 - precision: 0.9384 - recall: 0.7956\n",
      "Epoch 3/1000\n",
      "351/351 [==============================] - 0s 520us/step - loss: 0.2279 - accuracy: 0.9170 - precision: 0.9443 - recall: 0.7981\n",
      "Epoch 4/1000\n",
      "351/351 [==============================] - 0s 493us/step - loss: 0.2275 - accuracy: 0.9139 - precision: 0.9357 - recall: 0.7964\n",
      "Epoch 5/1000\n",
      "351/351 [==============================] - 0s 453us/step - loss: 0.2282 - accuracy: 0.9173 - precision: 0.9462 - recall: 0.7973\n",
      "Epoch 6/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2289 - accuracy: 0.9176 - precision: 0.9444 - recall: 0.7998\n",
      "Epoch 7/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2278 - accuracy: 0.9156 - precision: 0.9468 - recall: 0.7913\n",
      "Epoch 8/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2284 - accuracy: 0.9153 - precision: 0.9369 - recall: 0.7998\n",
      "Epoch 9/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2279 - accuracy: 0.9173 - precision: 0.9435 - recall: 0.7998\n",
      "Epoch 10/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2286 - accuracy: 0.9139 - precision: 0.9374 - recall: 0.7947\n",
      "Epoch 11/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2280 - accuracy: 0.9159 - precision: 0.9432 - recall: 0.7956\n",
      "Epoch 12/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2285 - accuracy: 0.9151 - precision: 0.9386 - recall: 0.7973\n",
      "Epoch 13/1000\n",
      "351/351 [==============================] - 0s 425us/step - loss: 0.2288 - accuracy: 0.9165 - precision: 0.9354 - recall: 0.8050\n",
      "Epoch 14/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2283 - accuracy: 0.9153 - precision: 0.9440 - recall: 0.7930\n",
      "Epoch 15/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2302 - accuracy: 0.9156 - precision: 0.9440 - recall: 0.7938\n",
      "Epoch 16/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2280 - accuracy: 0.9159 - precision: 0.9388 - recall: 0.7998\n",
      "Epoch 17/1000\n",
      "351/351 [==============================] - 0s 456us/step - loss: 0.2281 - accuracy: 0.9148 - precision: 0.9350 - recall: 0.7998\n",
      "Epoch 18/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2276 - accuracy: 0.9176 - precision: 0.9444 - recall: 0.7998\n",
      "Epoch 19/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2280 - accuracy: 0.9176 - precision: 0.9462 - recall: 0.7981\n",
      "Epoch 20/1000\n",
      "351/351 [==============================] - 0s 458us/step - loss: 0.2266 - accuracy: 0.9185 - precision: 0.9455 - recall: 0.8015\n",
      "Epoch 21/1000\n",
      "351/351 [==============================] - 0s 459us/step - loss: 0.2265 - accuracy: 0.9188 - precision: 0.9492 - recall: 0.7990\n",
      "Epoch 22/1000\n",
      "351/351 [==============================] - 0s 453us/step - loss: 0.2277 - accuracy: 0.9190 - precision: 0.9465 - recall: 0.8024\n",
      "Epoch 23/1000\n",
      "351/351 [==============================] - 0s 454us/step - loss: 0.2260 - accuracy: 0.9185 - precision: 0.9473 - recall: 0.7998\n",
      "Epoch 24/1000\n",
      "351/351 [==============================] - 0s 454us/step - loss: 0.2275 - accuracy: 0.9182 - precision: 0.9509 - recall: 0.7956\n",
      "Epoch 25/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2278 - accuracy: 0.9139 - precision: 0.9366 - recall: 0.7956\n",
      "Epoch 26/1000\n",
      "351/351 [==============================] - 0s 456us/step - loss: 0.2268 - accuracy: 0.9173 - precision: 0.9435 - recall: 0.7998\n",
      "Epoch 27/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2263 - accuracy: 0.9176 - precision: 0.9462 - recall: 0.7981\n",
      "Epoch 28/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2274 - accuracy: 0.9168 - precision: 0.9398 - recall: 0.8015\n",
      "Epoch 29/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2274 - accuracy: 0.9173 - precision: 0.9435 - recall: 0.7998\n",
      "Epoch 30/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2266 - accuracy: 0.9151 - precision: 0.9430 - recall: 0.7930\n",
      "Epoch 31/1000\n",
      "351/351 [==============================] - 0s 463us/step - loss: 0.2266 - accuracy: 0.9179 - precision: 0.9409 - recall: 0.8041\n",
      "Epoch 32/1000\n",
      "351/351 [==============================] - 0s 460us/step - loss: 0.2270 - accuracy: 0.9170 - precision: 0.9408 - recall: 0.8015\n",
      "Epoch 33/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2268 - accuracy: 0.9176 - precision: 0.9418 - recall: 0.8024\n",
      "Epoch 34/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2263 - accuracy: 0.9176 - precision: 0.9462 - recall: 0.7981\n",
      "Epoch 35/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2259 - accuracy: 0.9202 - precision: 0.9540 - recall: 0.7990\n",
      "Epoch 36/1000\n",
      "351/351 [==============================] - 0s 454us/step - loss: 0.2270 - accuracy: 0.9133 - precision: 0.9364 - recall: 0.7938\n",
      "Epoch 37/1000\n",
      "351/351 [==============================] - 0s 470us/step - loss: 0.2269 - accuracy: 0.9173 - precision: 0.9462 - recall: 0.7973\n",
      "Epoch 38/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2271 - accuracy: 0.9173 - precision: 0.9480 - recall: 0.7956\n",
      "Epoch 39/1000\n",
      "351/351 [==============================] - 0s 455us/step - loss: 0.2259 - accuracy: 0.9190 - precision: 0.9456 - recall: 0.8033\n",
      "Epoch 40/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2259 - accuracy: 0.9188 - precision: 0.9447 - recall: 0.8033\n",
      "Epoch 41/1000\n",
      "351/351 [==============================] - 0s 454us/step - loss: 0.2264 - accuracy: 0.9159 - precision: 0.9459 - recall: 0.7930\n",
      "Epoch 42/1000\n",
      "351/351 [==============================] - 0s 492us/step - loss: 0.2265 - accuracy: 0.9148 - precision: 0.9367 - recall: 0.7981\n",
      "Epoch 43/1000\n",
      "351/351 [==============================] - 0s 478us/step - loss: 0.2252 - accuracy: 0.9179 - precision: 0.9454 - recall: 0.7998\n",
      "Epoch 44/1000\n",
      "351/351 [==============================] - 0s 494us/step - loss: 0.2257 - accuracy: 0.9179 - precision: 0.9445 - recall: 0.8007\n",
      "Epoch 45/1000\n",
      "351/351 [==============================] - 0s 497us/step - loss: 0.2266 - accuracy: 0.9170 - precision: 0.9416 - recall: 0.8007\n",
      "Epoch 46/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2279 - accuracy: 0.9142 - precision: 0.9384 - recall: 0.7947\n",
      "Epoch 47/1000\n",
      "351/351 [==============================] - 0s 456us/step - loss: 0.2259 - accuracy: 0.9193 - precision: 0.9493 - recall: 0.8007\n",
      "Epoch 48/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2256 - accuracy: 0.9168 - precision: 0.9416 - recall: 0.7998\n",
      "Epoch 49/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2254 - accuracy: 0.9176 - precision: 0.9435 - recall: 0.8007\n",
      "Epoch 50/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2268 - accuracy: 0.9188 - precision: 0.9474 - recall: 0.8007\n",
      "Epoch 51/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2256 - accuracy: 0.9165 - precision: 0.9424 - recall: 0.7981\n",
      "Epoch 52/1000\n",
      "351/351 [==============================] - 0s 458us/step - loss: 0.2250 - accuracy: 0.9170 - precision: 0.9408 - recall: 0.8015\n",
      "Epoch 53/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2259 - accuracy: 0.9202 - precision: 0.9550 - recall: 0.7981\n",
      "Epoch 54/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2272 - accuracy: 0.9176 - precision: 0.9400 - recall: 0.8041\n",
      "Epoch 55/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2259 - accuracy: 0.9170 - precision: 0.9452 - recall: 0.7973\n",
      "Epoch 56/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2260 - accuracy: 0.9156 - precision: 0.9422 - recall: 0.7956\n",
      "Epoch 57/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2242 - accuracy: 0.9173 - precision: 0.9471 - recall: 0.7964\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 442us/step - loss: 0.2253 - accuracy: 0.9170 - precision: 0.9416 - recall: 0.8007\n",
      "Epoch 59/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2249 - accuracy: 0.9170 - precision: 0.9480 - recall: 0.7947\n",
      "Epoch 60/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2261 - accuracy: 0.9162 - precision: 0.9469 - recall: 0.7930\n",
      "Epoch 61/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2256 - accuracy: 0.9173 - precision: 0.9480 - recall: 0.7956\n",
      "Epoch 62/1000\n",
      "351/351 [==============================] - 0s 456us/step - loss: 0.2269 - accuracy: 0.9145 - precision: 0.9341 - recall: 0.7998\n",
      "Epoch 63/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2263 - accuracy: 0.9196 - precision: 0.9530 - recall: 0.7981\n",
      "Epoch 64/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2251 - accuracy: 0.9193 - precision: 0.9520 - recall: 0.7981\n",
      "Epoch 65/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2252 - accuracy: 0.9188 - precision: 0.9447 - recall: 0.8033\n",
      "Epoch 66/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2260 - accuracy: 0.9170 - precision: 0.9470 - recall: 0.7956\n",
      "Epoch 67/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2255 - accuracy: 0.9190 - precision: 0.9529 - recall: 0.7964\n",
      "Epoch 68/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2254 - accuracy: 0.9179 - precision: 0.9383 - recall: 0.8067\n",
      "Epoch 69/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2260 - accuracy: 0.9205 - precision: 0.9532 - recall: 0.8007\n",
      "Epoch 70/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2254 - accuracy: 0.9193 - precision: 0.9466 - recall: 0.8033\n",
      "Epoch 71/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2253 - accuracy: 0.9145 - precision: 0.9367 - recall: 0.7973\n",
      "Epoch 72/1000\n",
      "351/351 [==============================] - 0s 459us/step - loss: 0.2244 - accuracy: 0.9199 - precision: 0.9458 - recall: 0.8058\n",
      "Epoch 73/1000\n",
      "351/351 [==============================] - 0s 470us/step - loss: 0.2261 - accuracy: 0.9176 - precision: 0.9400 - recall: 0.8041\n",
      "Epoch 74/1000\n",
      "351/351 [==============================] - 0s 454us/step - loss: 0.2235 - accuracy: 0.9213 - precision: 0.9496 - recall: 0.8067\n",
      "Epoch 75/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2245 - accuracy: 0.9165 - precision: 0.9433 - recall: 0.7973\n",
      "Epoch 76/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2257 - accuracy: 0.9145 - precision: 0.9438 - recall: 0.7904\n",
      "Epoch 77/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2248 - accuracy: 0.9176 - precision: 0.9427 - recall: 0.8015\n",
      "Epoch 78/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2250 - accuracy: 0.9185 - precision: 0.9437 - recall: 0.8033\n",
      "Epoch 79/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2246 - accuracy: 0.9190 - precision: 0.9456 - recall: 0.8033\n",
      "Epoch 80/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2248 - accuracy: 0.9151 - precision: 0.9386 - recall: 0.7973\n",
      "Epoch 81/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2237 - accuracy: 0.9173 - precision: 0.9444 - recall: 0.7990\n",
      "Epoch 82/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2238 - accuracy: 0.9188 - precision: 0.9456 - recall: 0.8024\n",
      "Epoch 83/1000\n",
      "351/351 [==============================] - 0s 455us/step - loss: 0.2251 - accuracy: 0.9208 - precision: 0.9486 - recall: 0.8058\n",
      "Epoch 84/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2243 - accuracy: 0.9179 - precision: 0.9445 - recall: 0.8007\n",
      "Epoch 85/1000\n",
      "351/351 [==============================] - 0s 456us/step - loss: 0.2246 - accuracy: 0.9188 - precision: 0.9465 - recall: 0.8015\n",
      "Epoch 86/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2238 - accuracy: 0.9193 - precision: 0.9475 - recall: 0.8024\n",
      "Epoch 87/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2257 - accuracy: 0.9208 - precision: 0.9505 - recall: 0.8041\n",
      "Epoch 88/1000\n",
      "351/351 [==============================] - 0s 459us/step - loss: 0.2240 - accuracy: 0.9190 - precision: 0.9465 - recall: 0.8024\n",
      "Epoch 89/1000\n",
      "351/351 [==============================] - 0s 461us/step - loss: 0.2247 - accuracy: 0.9185 - precision: 0.9510 - recall: 0.7964\n",
      "Epoch 90/1000\n",
      "351/351 [==============================] - 0s 490us/step - loss: 0.2244 - accuracy: 0.9210 - precision: 0.9514 - recall: 0.8041\n",
      "Epoch 91/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2239 - accuracy: 0.9196 - precision: 0.9530 - recall: 0.7981\n",
      "Epoch 92/1000\n",
      "351/351 [==============================] - 0s 471us/step - loss: 0.2255 - accuracy: 0.9213 - precision: 0.9408 - recall: 0.8152\n",
      "Epoch 93/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2249 - accuracy: 0.9159 - precision: 0.9361 - recall: 0.8024\n",
      "Epoch 94/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2243 - accuracy: 0.9199 - precision: 0.9494 - recall: 0.8024\n",
      "Epoch 95/1000\n",
      "351/351 [==============================] - 0s 454us/step - loss: 0.2243 - accuracy: 0.9213 - precision: 0.9551 - recall: 0.8015\n",
      "Epoch 96/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2251 - accuracy: 0.9179 - precision: 0.9490 - recall: 0.7964\n",
      "Epoch 97/1000\n",
      "351/351 [==============================] - 0s 453us/step - loss: 0.2244 - accuracy: 0.9162 - precision: 0.9424 - recall: 0.7973\n",
      "Epoch 98/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2239 - accuracy: 0.9208 - precision: 0.9532 - recall: 0.8015\n",
      "Epoch 99/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2249 - accuracy: 0.9159 - precision: 0.9405 - recall: 0.7981\n",
      "Epoch 100/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2229 - accuracy: 0.9188 - precision: 0.9438 - recall: 0.8041\n",
      "Epoch 101/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2238 - accuracy: 0.9188 - precision: 0.9456 - recall: 0.8024\n",
      "Epoch 102/1000\n",
      "351/351 [==============================] - 0s 489us/step - loss: 0.2252 - accuracy: 0.9190 - precision: 0.9429 - recall: 0.8058\n",
      "Epoch 103/1000\n",
      "351/351 [==============================] - 0s 461us/step - loss: 0.2236 - accuracy: 0.9202 - precision: 0.9485 - recall: 0.8041\n",
      "Epoch 104/1000\n",
      "351/351 [==============================] - 0s 603us/step - loss: 0.2238 - accuracy: 0.9193 - precision: 0.9448 - recall: 0.8050\n",
      "Epoch 105/1000\n",
      "351/351 [==============================] - 0s 543us/step - loss: 0.2241 - accuracy: 0.9193 - precision: 0.9475 - recall: 0.8024\n",
      "Epoch 106/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2239 - accuracy: 0.9199 - precision: 0.9494 - recall: 0.8024\n",
      "Epoch 107/1000\n",
      "351/351 [==============================] - 0s 413us/step - loss: 0.2241 - accuracy: 0.9156 - precision: 0.9387 - recall: 0.7990\n",
      "Epoch 108/1000\n",
      "351/351 [==============================] - 0s 423us/step - loss: 0.2224 - accuracy: 0.9173 - precision: 0.9462 - recall: 0.7973\n",
      "Epoch 109/1000\n",
      "351/351 [==============================] - 0s 417us/step - loss: 0.2235 - accuracy: 0.9193 - precision: 0.9484 - recall: 0.8015\n",
      "Epoch 110/1000\n",
      "351/351 [==============================] - 0s 413us/step - loss: 0.2233 - accuracy: 0.9233 - precision: 0.9573 - recall: 0.8058\n",
      "Epoch 111/1000\n",
      "351/351 [==============================] - 0s 415us/step - loss: 0.2252 - accuracy: 0.9153 - precision: 0.9360 - recall: 0.8007\n",
      "Epoch 112/1000\n",
      "351/351 [==============================] - 0s 414us/step - loss: 0.2235 - accuracy: 0.9193 - precision: 0.9484 - recall: 0.8015\n",
      "Epoch 113/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2239 - accuracy: 0.9188 - precision: 0.9474 - recall: 0.8007\n",
      "Epoch 114/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2244 - accuracy: 0.9190 - precision: 0.9474 - recall: 0.8015\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 428us/step - loss: 0.2217 - accuracy: 0.9202 - precision: 0.9467 - recall: 0.8058\n",
      "Epoch 116/1000\n",
      "351/351 [==============================] - 0s 425us/step - loss: 0.2235 - accuracy: 0.9182 - precision: 0.9482 - recall: 0.7981\n",
      "Epoch 117/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2229 - accuracy: 0.9205 - precision: 0.9477 - recall: 0.8058\n",
      "Epoch 118/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2226 - accuracy: 0.9199 - precision: 0.9485 - recall: 0.8033\n",
      "Epoch 119/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2237 - accuracy: 0.9176 - precision: 0.9444 - recall: 0.7998\n",
      "Epoch 120/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2223 - accuracy: 0.9182 - precision: 0.9482 - recall: 0.7981\n",
      "Epoch 121/1000\n",
      "351/351 [==============================] - 0s 456us/step - loss: 0.2232 - accuracy: 0.9179 - precision: 0.9436 - recall: 0.8015\n",
      "Epoch 122/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2235 - accuracy: 0.9205 - precision: 0.9450 - recall: 0.8084\n",
      "Epoch 123/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2227 - accuracy: 0.9199 - precision: 0.9503 - recall: 0.8015\n",
      "Epoch 124/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2226 - accuracy: 0.9168 - precision: 0.9416 - recall: 0.7998\n",
      "Epoch 125/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2234 - accuracy: 0.9182 - precision: 0.9419 - recall: 0.8041\n",
      "Epoch 126/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2228 - accuracy: 0.9190 - precision: 0.9529 - recall: 0.7964\n",
      "Epoch 127/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2227 - accuracy: 0.9188 - precision: 0.9474 - recall: 0.8007\n",
      "Epoch 128/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2226 - accuracy: 0.9185 - precision: 0.9473 - recall: 0.7998\n",
      "Epoch 129/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2223 - accuracy: 0.9199 - precision: 0.9458 - recall: 0.8058\n",
      "Epoch 130/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2224 - accuracy: 0.9168 - precision: 0.9416 - recall: 0.7998\n",
      "Epoch 131/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2223 - accuracy: 0.9190 - precision: 0.9429 - recall: 0.8058\n",
      "Epoch 132/1000\n",
      "351/351 [==============================] - 0s 541us/step - loss: 0.2223 - accuracy: 0.9213 - precision: 0.9443 - recall: 0.8118\n",
      "Epoch 133/1000\n",
      "351/351 [==============================] - 0s 463us/step - loss: 0.2234 - accuracy: 0.9222 - precision: 0.9507 - recall: 0.8084\n",
      "Epoch 134/1000\n",
      "351/351 [==============================] - 0s 454us/step - loss: 0.2236 - accuracy: 0.9173 - precision: 0.9426 - recall: 0.8007\n",
      "Epoch 135/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2226 - accuracy: 0.9202 - precision: 0.9494 - recall: 0.8033\n",
      "Epoch 136/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2224 - accuracy: 0.9188 - precision: 0.9483 - recall: 0.7998\n",
      "Epoch 137/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2230 - accuracy: 0.9190 - precision: 0.9474 - recall: 0.8015\n",
      "Epoch 138/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2204 - accuracy: 0.9202 - precision: 0.9531 - recall: 0.7998\n",
      "Epoch 139/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2216 - accuracy: 0.9205 - precision: 0.9504 - recall: 0.8033\n",
      "Epoch 140/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2229 - accuracy: 0.9193 - precision: 0.9457 - recall: 0.8041\n",
      "Epoch 141/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2217 - accuracy: 0.9205 - precision: 0.9559 - recall: 0.7981\n",
      "Epoch 142/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2223 - accuracy: 0.9210 - precision: 0.9560 - recall: 0.7998\n",
      "Epoch 143/1000\n",
      "351/351 [==============================] - 0s 465us/step - loss: 0.2228 - accuracy: 0.9185 - precision: 0.9510 - recall: 0.7964\n",
      "Epoch 144/1000\n",
      "351/351 [==============================] - 0s 485us/step - loss: 0.2223 - accuracy: 0.9208 - precision: 0.9560 - recall: 0.7990\n",
      "Epoch 145/1000\n",
      "351/351 [==============================] - 0s 479us/step - loss: 0.2222 - accuracy: 0.9202 - precision: 0.9522 - recall: 0.8007\n",
      "Epoch 146/1000\n",
      "351/351 [==============================] - 0s 453us/step - loss: 0.2219 - accuracy: 0.9230 - precision: 0.9573 - recall: 0.8050\n",
      "Epoch 147/1000\n",
      "351/351 [==============================] - 0s 455us/step - loss: 0.2229 - accuracy: 0.9196 - precision: 0.9422 - recall: 0.8084\n",
      "Epoch 148/1000\n",
      "351/351 [==============================] - 0s 454us/step - loss: 0.2206 - accuracy: 0.9213 - precision: 0.9478 - recall: 0.8084\n",
      "Epoch 149/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2212 - accuracy: 0.9227 - precision: 0.9481 - recall: 0.8127\n",
      "Epoch 150/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2214 - accuracy: 0.9196 - precision: 0.9493 - recall: 0.8015\n",
      "Epoch 151/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2211 - accuracy: 0.9202 - precision: 0.9494 - recall: 0.8033\n",
      "Epoch 152/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2227 - accuracy: 0.9193 - precision: 0.9466 - recall: 0.8033\n",
      "Epoch 153/1000\n",
      "351/351 [==============================] - 0s 466us/step - loss: 0.2226 - accuracy: 0.9188 - precision: 0.9474 - recall: 0.8007\n",
      "Epoch 154/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2224 - accuracy: 0.9216 - precision: 0.9524 - recall: 0.8050\n",
      "Epoch 155/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2226 - accuracy: 0.9202 - precision: 0.9476 - recall: 0.8050\n",
      "Epoch 156/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2216 - accuracy: 0.9227 - precision: 0.9554 - recall: 0.8058\n",
      "Epoch 157/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2226 - accuracy: 0.9227 - precision: 0.9545 - recall: 0.8067\n",
      "Epoch 158/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2214 - accuracy: 0.9225 - precision: 0.9526 - recall: 0.8075\n",
      "Epoch 159/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2226 - accuracy: 0.9219 - precision: 0.9507 - recall: 0.8075\n",
      "Epoch 160/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2217 - accuracy: 0.9213 - precision: 0.9506 - recall: 0.8058\n",
      "Epoch 161/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2210 - accuracy: 0.9190 - precision: 0.9429 - recall: 0.8058\n",
      "Epoch 162/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2214 - accuracy: 0.9193 - precision: 0.9475 - recall: 0.8024\n",
      "Epoch 163/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2206 - accuracy: 0.9210 - precision: 0.9542 - recall: 0.8015\n",
      "Epoch 164/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2211 - accuracy: 0.9185 - precision: 0.9464 - recall: 0.8007\n",
      "Epoch 165/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2223 - accuracy: 0.9188 - precision: 0.9438 - recall: 0.8041\n",
      "Epoch 166/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2215 - accuracy: 0.9196 - precision: 0.9493 - recall: 0.8015\n",
      "Epoch 167/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2208 - accuracy: 0.9193 - precision: 0.9475 - recall: 0.8024\n",
      "Epoch 168/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2218 - accuracy: 0.9219 - precision: 0.9525 - recall: 0.8058\n",
      "Epoch 169/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2233 - accuracy: 0.9159 - precision: 0.9370 - recall: 0.8015\n",
      "Epoch 170/1000\n",
      "351/351 [==============================] - 0s 453us/step - loss: 0.2206 - accuracy: 0.9213 - precision: 0.9542 - recall: 0.8024\n",
      "Epoch 171/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2214 - accuracy: 0.9230 - precision: 0.9554 - recall: 0.8067\n",
      "Epoch 172/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 439us/step - loss: 0.2218 - accuracy: 0.9210 - precision: 0.9523 - recall: 0.8033\n",
      "Epoch 173/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2218 - accuracy: 0.9202 - precision: 0.9504 - recall: 0.8024\n",
      "Epoch 174/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2214 - accuracy: 0.9213 - precision: 0.9533 - recall: 0.8033\n",
      "Epoch 175/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2216 - accuracy: 0.9199 - precision: 0.9458 - recall: 0.8058\n",
      "Epoch 176/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2194 - accuracy: 0.9202 - precision: 0.9485 - recall: 0.8041\n",
      "Epoch 177/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2213 - accuracy: 0.9259 - precision: 0.9614 - recall: 0.8101\n",
      "Epoch 178/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2221 - accuracy: 0.9202 - precision: 0.9476 - recall: 0.8050\n",
      "Epoch 179/1000\n",
      "351/351 [==============================] - 0s 453us/step - loss: 0.2207 - accuracy: 0.9222 - precision: 0.9471 - recall: 0.8118\n",
      "Epoch 180/1000\n",
      "351/351 [==============================] - 0s 453us/step - loss: 0.2214 - accuracy: 0.9188 - precision: 0.9420 - recall: 0.8058\n",
      "Epoch 181/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2216 - accuracy: 0.9219 - precision: 0.9571 - recall: 0.8015\n",
      "Epoch 182/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2207 - accuracy: 0.9202 - precision: 0.9441 - recall: 0.8084\n",
      "Epoch 183/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2204 - accuracy: 0.9210 - precision: 0.9533 - recall: 0.8024\n",
      "Epoch 184/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2213 - accuracy: 0.9196 - precision: 0.9413 - recall: 0.8092\n",
      "Epoch 185/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2221 - accuracy: 0.9193 - precision: 0.9448 - recall: 0.8050\n",
      "Epoch 186/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2208 - accuracy: 0.9182 - precision: 0.9410 - recall: 0.8050\n",
      "Epoch 187/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2212 - accuracy: 0.9188 - precision: 0.9438 - recall: 0.8041\n",
      "Epoch 188/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2210 - accuracy: 0.9222 - precision: 0.9489 - recall: 0.8101\n",
      "Epoch 189/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2221 - accuracy: 0.9208 - precision: 0.9495 - recall: 0.8050\n",
      "Epoch 190/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2198 - accuracy: 0.9227 - precision: 0.9572 - recall: 0.8041\n",
      "Epoch 191/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2203 - accuracy: 0.9193 - precision: 0.9439 - recall: 0.8058\n",
      "Epoch 192/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2201 - accuracy: 0.9256 - precision: 0.9586 - recall: 0.8118\n",
      "Epoch 193/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2205 - accuracy: 0.9216 - precision: 0.9533 - recall: 0.8041\n",
      "Epoch 194/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2206 - accuracy: 0.9216 - precision: 0.9533 - recall: 0.8041\n",
      "Epoch 195/1000\n",
      "351/351 [==============================] - 0s 462us/step - loss: 0.2199 - accuracy: 0.9208 - precision: 0.9505 - recall: 0.8041\n",
      "Epoch 196/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2197 - accuracy: 0.9208 - precision: 0.9486 - recall: 0.8058\n",
      "Epoch 197/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2200 - accuracy: 0.9205 - precision: 0.9513 - recall: 0.8024\n",
      "Epoch 198/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2205 - accuracy: 0.9210 - precision: 0.9478 - recall: 0.8075\n",
      "Epoch 199/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2206 - accuracy: 0.9222 - precision: 0.9516 - recall: 0.8075\n",
      "Epoch 200/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2216 - accuracy: 0.9222 - precision: 0.9534 - recall: 0.8058\n",
      "Epoch 201/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2195 - accuracy: 0.9216 - precision: 0.9543 - recall: 0.8033\n",
      "Epoch 202/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2211 - accuracy: 0.9219 - precision: 0.9488 - recall: 0.8092\n",
      "Epoch 203/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2205 - accuracy: 0.9233 - precision: 0.9555 - recall: 0.8075\n",
      "Epoch 204/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2189 - accuracy: 0.9213 - precision: 0.9469 - recall: 0.8092\n",
      "Epoch 205/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2204 - accuracy: 0.9202 - precision: 0.9467 - recall: 0.8058\n",
      "Epoch 206/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2206 - accuracy: 0.9202 - precision: 0.9485 - recall: 0.8041\n",
      "Epoch 207/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2203 - accuracy: 0.9216 - precision: 0.9488 - recall: 0.8084\n",
      "Epoch 208/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2201 - accuracy: 0.9210 - precision: 0.9487 - recall: 0.8067\n",
      "Epoch 209/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2197 - accuracy: 0.9236 - precision: 0.9528 - recall: 0.8109\n",
      "Epoch 210/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2208 - accuracy: 0.9208 - precision: 0.9468 - recall: 0.8075\n",
      "Epoch 211/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2207 - accuracy: 0.9208 - precision: 0.9495 - recall: 0.8050\n",
      "Epoch 212/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2198 - accuracy: 0.9225 - precision: 0.9517 - recall: 0.8084\n",
      "Epoch 213/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2193 - accuracy: 0.9230 - precision: 0.9591 - recall: 0.8033\n",
      "Epoch 214/1000\n",
      "351/351 [==============================] - 0s 525us/step - loss: 0.2195 - accuracy: 0.9225 - precision: 0.9489 - recall: 0.8109\n",
      "Epoch 215/1000\n",
      "351/351 [==============================] - 0s 464us/step - loss: 0.2198 - accuracy: 0.9247 - precision: 0.9566 - recall: 0.8109\n",
      "Epoch 216/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2191 - accuracy: 0.9225 - precision: 0.9526 - recall: 0.8075\n",
      "Epoch 217/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2205 - accuracy: 0.9208 - precision: 0.9442 - recall: 0.8101\n",
      "Epoch 218/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2197 - accuracy: 0.9202 - precision: 0.9449 - recall: 0.8075\n",
      "Epoch 219/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2196 - accuracy: 0.9233 - precision: 0.9601 - recall: 0.8033\n",
      "Epoch 220/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2214 - accuracy: 0.9208 - precision: 0.9495 - recall: 0.8050\n",
      "Epoch 221/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2202 - accuracy: 0.9216 - precision: 0.9506 - recall: 0.8067\n",
      "Epoch 222/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2184 - accuracy: 0.9208 - precision: 0.9468 - recall: 0.8075\n",
      "Epoch 223/1000\n",
      "351/351 [==============================] - 0s 455us/step - loss: 0.2189 - accuracy: 0.9225 - precision: 0.9544 - recall: 0.8058\n",
      "Epoch 224/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2194 - accuracy: 0.9196 - precision: 0.9484 - recall: 0.8024\n",
      "Epoch 225/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2185 - accuracy: 0.9239 - precision: 0.9492 - recall: 0.8152\n",
      "Epoch 226/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2185 - accuracy: 0.9239 - precision: 0.9556 - recall: 0.8092\n",
      "Epoch 227/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2188 - accuracy: 0.9199 - precision: 0.9467 - recall: 0.8050\n",
      "Epoch 228/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2210 - accuracy: 0.9236 - precision: 0.9546 - recall: 0.8092\n",
      "Epoch 229/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 439us/step - loss: 0.2186 - accuracy: 0.9222 - precision: 0.9507 - recall: 0.8084\n",
      "Epoch 230/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2187 - accuracy: 0.9225 - precision: 0.9553 - recall: 0.8050\n",
      "Epoch 231/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2191 - accuracy: 0.9222 - precision: 0.9498 - recall: 0.8092\n",
      "Epoch 232/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2182 - accuracy: 0.9222 - precision: 0.9544 - recall: 0.8050\n",
      "Epoch 233/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2177 - accuracy: 0.9213 - precision: 0.9469 - recall: 0.8092\n",
      "Epoch 234/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2188 - accuracy: 0.9213 - precision: 0.9515 - recall: 0.8050\n",
      "Epoch 235/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2189 - accuracy: 0.9230 - precision: 0.9563 - recall: 0.8058\n",
      "Epoch 236/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2186 - accuracy: 0.9222 - precision: 0.9534 - recall: 0.8058\n",
      "Epoch 237/1000\n",
      "351/351 [==============================] - 0s 463us/step - loss: 0.2180 - accuracy: 0.9210 - precision: 0.9469 - recall: 0.8084\n",
      "Epoch 238/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2177 - accuracy: 0.9233 - precision: 0.9564 - recall: 0.8067\n",
      "Epoch 239/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2196 - accuracy: 0.9222 - precision: 0.9534 - recall: 0.8058\n",
      "Epoch 240/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2190 - accuracy: 0.9216 - precision: 0.9435 - recall: 0.8135\n",
      "Epoch 241/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2207 - accuracy: 0.9193 - precision: 0.9493 - recall: 0.8007\n",
      "Epoch 242/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2190 - accuracy: 0.9233 - precision: 0.9545 - recall: 0.8084\n",
      "Epoch 243/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2200 - accuracy: 0.9236 - precision: 0.9602 - recall: 0.8041\n",
      "Epoch 244/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2200 - accuracy: 0.9216 - precision: 0.9479 - recall: 0.8092\n",
      "Epoch 245/1000\n",
      "351/351 [==============================] - 0s 475us/step - loss: 0.2201 - accuracy: 0.9216 - precision: 0.9488 - recall: 0.8084\n",
      "Epoch 246/1000\n",
      "351/351 [==============================] - 0s 483us/step - loss: 0.2191 - accuracy: 0.9222 - precision: 0.9544 - recall: 0.8050\n",
      "Epoch 247/1000\n",
      "351/351 [==============================] - 0s 480us/step - loss: 0.2186 - accuracy: 0.9230 - precision: 0.9554 - recall: 0.8067\n",
      "Epoch 248/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2187 - accuracy: 0.9233 - precision: 0.9564 - recall: 0.8067\n",
      "Epoch 249/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2195 - accuracy: 0.9225 - precision: 0.9498 - recall: 0.8101\n",
      "Epoch 250/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2190 - accuracy: 0.9213 - precision: 0.9515 - recall: 0.8050\n",
      "Epoch 251/1000\n",
      "351/351 [==============================] - 0s 458us/step - loss: 0.2190 - accuracy: 0.9222 - precision: 0.9498 - recall: 0.8092\n",
      "Epoch 252/1000\n",
      "351/351 [==============================] - 0s 457us/step - loss: 0.2177 - accuracy: 0.9213 - precision: 0.9496 - recall: 0.8067\n",
      "Epoch 253/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2185 - accuracy: 0.9219 - precision: 0.9462 - recall: 0.8118\n",
      "Epoch 254/1000\n",
      "351/351 [==============================] - 0s 455us/step - loss: 0.2192 - accuracy: 0.9230 - precision: 0.9563 - recall: 0.8058\n",
      "Epoch 255/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2187 - accuracy: 0.9219 - precision: 0.9534 - recall: 0.8050\n",
      "Epoch 256/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2202 - accuracy: 0.9225 - precision: 0.9544 - recall: 0.8058\n",
      "Epoch 257/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2188 - accuracy: 0.9219 - precision: 0.9497 - recall: 0.8084\n",
      "Epoch 258/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2188 - accuracy: 0.9233 - precision: 0.9545 - recall: 0.8084\n",
      "Epoch 259/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2196 - accuracy: 0.9216 - precision: 0.9479 - recall: 0.8092\n",
      "Epoch 260/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2194 - accuracy: 0.9225 - precision: 0.9544 - recall: 0.8058\n",
      "Epoch 261/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2185 - accuracy: 0.9239 - precision: 0.9519 - recall: 0.8127\n",
      "Epoch 262/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2189 - accuracy: 0.9213 - precision: 0.9461 - recall: 0.8101\n",
      "Epoch 263/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2170 - accuracy: 0.9205 - precision: 0.9468 - recall: 0.8067\n",
      "Epoch 264/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2176 - accuracy: 0.9227 - precision: 0.9554 - recall: 0.8058\n",
      "Epoch 265/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2175 - accuracy: 0.9227 - precision: 0.9499 - recall: 0.8109\n",
      "Epoch 266/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2178 - accuracy: 0.9227 - precision: 0.9582 - recall: 0.8033\n",
      "Epoch 267/1000\n",
      "351/351 [==============================] - 0s 459us/step - loss: 0.2193 - accuracy: 0.9242 - precision: 0.9529 - recall: 0.8127\n",
      "Epoch 268/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2194 - accuracy: 0.9213 - precision: 0.9452 - recall: 0.8109\n",
      "Epoch 269/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2182 - accuracy: 0.9233 - precision: 0.9536 - recall: 0.8092\n",
      "Epoch 270/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2175 - accuracy: 0.9245 - precision: 0.9538 - recall: 0.8127\n",
      "Epoch 271/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2171 - accuracy: 0.9213 - precision: 0.9506 - recall: 0.8058\n",
      "Epoch 272/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2172 - accuracy: 0.9245 - precision: 0.9556 - recall: 0.8109\n",
      "Epoch 273/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2167 - accuracy: 0.9222 - precision: 0.9507 - recall: 0.8084\n",
      "Epoch 274/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2180 - accuracy: 0.9227 - precision: 0.9454 - recall: 0.8152\n",
      "Epoch 275/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2172 - accuracy: 0.9242 - precision: 0.9565 - recall: 0.8092\n",
      "Epoch 276/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2184 - accuracy: 0.9210 - precision: 0.9496 - recall: 0.8058\n",
      "Epoch 277/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2179 - accuracy: 0.9213 - precision: 0.9487 - recall: 0.8075\n",
      "Epoch 278/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2192 - accuracy: 0.9247 - precision: 0.9594 - recall: 0.8084\n",
      "Epoch 279/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2176 - accuracy: 0.9239 - precision: 0.9510 - recall: 0.8135\n",
      "Epoch 280/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2179 - accuracy: 0.9225 - precision: 0.9517 - recall: 0.8084\n",
      "Epoch 281/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2174 - accuracy: 0.9245 - precision: 0.9538 - recall: 0.8127\n",
      "Epoch 282/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2164 - accuracy: 0.9219 - precision: 0.9516 - recall: 0.8067\n",
      "Epoch 283/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2191 - accuracy: 0.9230 - precision: 0.9499 - recall: 0.8118\n",
      "Epoch 284/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2167 - accuracy: 0.9222 - precision: 0.9498 - recall: 0.8092\n",
      "Epoch 285/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2175 - accuracy: 0.9242 - precision: 0.9584 - recall: 0.8075\n",
      "Epoch 286/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 440us/step - loss: 0.2168 - accuracy: 0.9233 - precision: 0.9536 - recall: 0.8092\n",
      "Epoch 287/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2178 - accuracy: 0.9236 - precision: 0.9537 - recall: 0.8101\n",
      "Epoch 288/1000\n",
      "351/351 [==============================] - 0s 461us/step - loss: 0.2172 - accuracy: 0.9210 - precision: 0.9514 - recall: 0.8041\n",
      "Epoch 289/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2175 - accuracy: 0.9230 - precision: 0.9491 - recall: 0.8127\n",
      "Epoch 290/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2189 - accuracy: 0.9202 - precision: 0.9467 - recall: 0.8058\n",
      "Epoch 291/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2166 - accuracy: 0.9262 - precision: 0.9624 - recall: 0.8101\n",
      "Epoch 292/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2176 - accuracy: 0.9242 - precision: 0.9602 - recall: 0.8058\n",
      "Epoch 293/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2179 - accuracy: 0.9216 - precision: 0.9506 - recall: 0.8067\n",
      "Epoch 294/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2159 - accuracy: 0.9270 - precision: 0.9606 - recall: 0.8144\n",
      "Epoch 295/1000\n",
      "351/351 [==============================] - 0s 433us/step - loss: 0.2176 - accuracy: 0.9190 - precision: 0.9483 - recall: 0.8007\n",
      "Epoch 296/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2164 - accuracy: 0.9262 - precision: 0.9577 - recall: 0.8144\n",
      "Epoch 297/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2170 - accuracy: 0.9245 - precision: 0.9556 - recall: 0.8109\n",
      "Epoch 298/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2164 - accuracy: 0.9236 - precision: 0.9574 - recall: 0.8067\n",
      "Epoch 299/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2164 - accuracy: 0.9239 - precision: 0.9528 - recall: 0.8118\n",
      "Epoch 300/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2163 - accuracy: 0.9245 - precision: 0.9566 - recall: 0.8101\n",
      "Epoch 301/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2165 - accuracy: 0.9245 - precision: 0.9538 - recall: 0.8127\n",
      "Epoch 302/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2168 - accuracy: 0.9256 - precision: 0.9567 - recall: 0.8135\n",
      "Epoch 303/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2160 - accuracy: 0.9213 - precision: 0.9515 - recall: 0.8050\n",
      "Epoch 304/1000\n",
      "351/351 [==============================] - 0s 473us/step - loss: 0.2167 - accuracy: 0.9199 - precision: 0.9476 - recall: 0.8041\n",
      "Epoch 305/1000\n",
      "351/351 [==============================] - 0s 455us/step - loss: 0.2160 - accuracy: 0.9239 - precision: 0.9519 - recall: 0.8127\n",
      "Epoch 306/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2176 - accuracy: 0.9239 - precision: 0.9537 - recall: 0.8109\n",
      "Epoch 307/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2172 - accuracy: 0.9239 - precision: 0.9546 - recall: 0.8101\n",
      "Epoch 308/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2159 - accuracy: 0.9250 - precision: 0.9557 - recall: 0.8127\n",
      "Epoch 309/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2167 - accuracy: 0.9227 - precision: 0.9545 - recall: 0.8067\n",
      "Epoch 310/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2181 - accuracy: 0.9222 - precision: 0.9498 - recall: 0.8092\n",
      "Epoch 311/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2157 - accuracy: 0.9262 - precision: 0.9577 - recall: 0.8144\n",
      "Epoch 312/1000\n",
      "351/351 [==============================] - 0s 543us/step - loss: 0.2160 - accuracy: 0.9225 - precision: 0.9489 - recall: 0.8109\n",
      "Epoch 313/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2167 - accuracy: 0.9245 - precision: 0.9593 - recall: 0.8075\n",
      "Epoch 314/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2158 - accuracy: 0.9245 - precision: 0.9556 - recall: 0.8109\n",
      "Epoch 315/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2174 - accuracy: 0.9247 - precision: 0.9530 - recall: 0.8144\n",
      "Epoch 316/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2166 - accuracy: 0.9233 - precision: 0.9509 - recall: 0.8118\n",
      "Epoch 317/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2160 - accuracy: 0.9233 - precision: 0.9555 - recall: 0.8075\n",
      "Epoch 318/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2159 - accuracy: 0.9227 - precision: 0.9526 - recall: 0.8084\n",
      "Epoch 319/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2166 - accuracy: 0.9256 - precision: 0.9567 - recall: 0.8135\n",
      "Epoch 320/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2168 - accuracy: 0.9236 - precision: 0.9528 - recall: 0.8109\n",
      "Epoch 321/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2157 - accuracy: 0.9230 - precision: 0.9563 - recall: 0.8058\n",
      "Epoch 322/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2168 - accuracy: 0.9236 - precision: 0.9555 - recall: 0.8084\n",
      "Epoch 323/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2162 - accuracy: 0.9219 - precision: 0.9497 - recall: 0.8084\n",
      "Epoch 324/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2166 - accuracy: 0.9236 - precision: 0.9564 - recall: 0.8075\n",
      "Epoch 325/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2157 - accuracy: 0.9250 - precision: 0.9557 - recall: 0.8127\n",
      "Epoch 326/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2169 - accuracy: 0.9239 - precision: 0.9565 - recall: 0.8084\n",
      "Epoch 327/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2167 - accuracy: 0.9233 - precision: 0.9536 - recall: 0.8092\n",
      "Epoch 328/1000\n",
      "351/351 [==============================] - 0s 427us/step - loss: 0.2154 - accuracy: 0.9245 - precision: 0.9566 - recall: 0.8101\n",
      "Epoch 329/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2164 - accuracy: 0.9247 - precision: 0.9494 - recall: 0.8178\n",
      "Epoch 330/1000\n",
      "351/351 [==============================] - 0s 433us/step - loss: 0.2153 - accuracy: 0.9279 - precision: 0.9608 - recall: 0.8169\n",
      "Epoch 331/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2159 - accuracy: 0.9216 - precision: 0.9461 - recall: 0.8109\n",
      "Epoch 332/1000\n",
      "351/351 [==============================] - 0s 433us/step - loss: 0.2152 - accuracy: 0.9259 - precision: 0.9596 - recall: 0.8118\n",
      "Epoch 333/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2155 - accuracy: 0.9230 - precision: 0.9545 - recall: 0.8075\n",
      "Epoch 334/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2159 - accuracy: 0.9230 - precision: 0.9545 - recall: 0.8075\n",
      "Epoch 335/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2156 - accuracy: 0.9219 - precision: 0.9471 - recall: 0.8109\n",
      "Epoch 336/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2162 - accuracy: 0.9225 - precision: 0.9481 - recall: 0.8118\n",
      "Epoch 337/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2151 - accuracy: 0.9245 - precision: 0.9566 - recall: 0.8101\n",
      "Epoch 338/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2151 - accuracy: 0.9245 - precision: 0.9556 - recall: 0.8109\n",
      "Epoch 339/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2152 - accuracy: 0.9236 - precision: 0.9519 - recall: 0.8118\n",
      "Epoch 340/1000\n",
      "351/351 [==============================] - 0s 455us/step - loss: 0.2145 - accuracy: 0.9259 - precision: 0.9531 - recall: 0.8178\n",
      "Epoch 341/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2154 - accuracy: 0.9236 - precision: 0.9611 - recall: 0.8033\n",
      "Epoch 342/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2169 - accuracy: 0.9227 - precision: 0.9481 - recall: 0.8127\n",
      "Epoch 343/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 430us/step - loss: 0.2142 - accuracy: 0.9239 - precision: 0.9556 - recall: 0.8092\n",
      "Epoch 344/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2155 - accuracy: 0.9236 - precision: 0.9555 - recall: 0.8084\n",
      "Epoch 345/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2161 - accuracy: 0.9213 - precision: 0.9461 - recall: 0.8101\n",
      "Epoch 346/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2161 - accuracy: 0.9230 - precision: 0.9518 - recall: 0.8101\n",
      "Epoch 347/1000\n",
      "351/351 [==============================] - 0s 463us/step - loss: 0.2161 - accuracy: 0.9222 - precision: 0.9553 - recall: 0.8041\n",
      "Epoch 348/1000\n",
      "351/351 [==============================] - 0s 463us/step - loss: 0.2158 - accuracy: 0.9245 - precision: 0.9538 - recall: 0.8127\n",
      "Epoch 349/1000\n",
      "351/351 [==============================] - 0s 474us/step - loss: 0.2150 - accuracy: 0.9253 - precision: 0.9540 - recall: 0.8152\n",
      "Epoch 350/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2152 - accuracy: 0.9210 - precision: 0.9533 - recall: 0.8024\n",
      "Epoch 351/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2163 - accuracy: 0.9210 - precision: 0.9496 - recall: 0.8058\n",
      "Epoch 352/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2155 - accuracy: 0.9265 - precision: 0.9615 - recall: 0.8118\n",
      "Epoch 353/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2158 - accuracy: 0.9262 - precision: 0.9615 - recall: 0.8109\n",
      "Epoch 354/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2156 - accuracy: 0.9233 - precision: 0.9509 - recall: 0.8118\n",
      "Epoch 355/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2151 - accuracy: 0.9245 - precision: 0.9593 - recall: 0.8075\n",
      "Epoch 356/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2145 - accuracy: 0.9230 - precision: 0.9509 - recall: 0.8109\n",
      "Epoch 357/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2146 - accuracy: 0.9230 - precision: 0.9499 - recall: 0.8118\n",
      "Epoch 358/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2145 - accuracy: 0.9253 - precision: 0.9567 - recall: 0.8127\n",
      "Epoch 359/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2155 - accuracy: 0.9233 - precision: 0.9536 - recall: 0.8092\n",
      "Epoch 360/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2170 - accuracy: 0.9239 - precision: 0.9510 - recall: 0.8135\n",
      "Epoch 361/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2156 - accuracy: 0.9230 - precision: 0.9518 - recall: 0.8101\n",
      "Epoch 362/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2156 - accuracy: 0.9239 - precision: 0.9546 - recall: 0.8101\n",
      "Epoch 363/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2155 - accuracy: 0.9247 - precision: 0.9585 - recall: 0.8092\n",
      "Epoch 364/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2145 - accuracy: 0.9253 - precision: 0.9530 - recall: 0.8161\n",
      "Epoch 365/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2150 - accuracy: 0.9259 - precision: 0.9586 - recall: 0.8127\n",
      "Epoch 366/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2164 - accuracy: 0.9233 - precision: 0.9527 - recall: 0.8101\n",
      "Epoch 367/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2151 - accuracy: 0.9250 - precision: 0.9567 - recall: 0.8118\n",
      "Epoch 368/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2140 - accuracy: 0.9247 - precision: 0.9557 - recall: 0.8118\n",
      "Epoch 369/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2148 - accuracy: 0.9270 - precision: 0.9635 - recall: 0.8118\n",
      "Epoch 370/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2138 - accuracy: 0.9242 - precision: 0.9556 - recall: 0.8101\n",
      "Epoch 371/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2142 - accuracy: 0.9265 - precision: 0.9578 - recall: 0.8152\n",
      "Epoch 372/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2148 - accuracy: 0.9267 - precision: 0.9588 - recall: 0.8152\n",
      "Epoch 373/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2152 - accuracy: 0.9245 - precision: 0.9547 - recall: 0.8118\n",
      "Epoch 374/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2145 - accuracy: 0.9259 - precision: 0.9586 - recall: 0.8127\n",
      "Epoch 375/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2149 - accuracy: 0.9242 - precision: 0.9556 - recall: 0.8101\n",
      "Epoch 376/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2144 - accuracy: 0.9245 - precision: 0.9547 - recall: 0.8118\n",
      "Epoch 377/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2148 - accuracy: 0.9267 - precision: 0.9578 - recall: 0.8161\n",
      "Epoch 378/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2142 - accuracy: 0.9250 - precision: 0.9585 - recall: 0.8101\n",
      "Epoch 379/1000\n",
      "351/351 [==============================] - 0s 459us/step - loss: 0.2142 - accuracy: 0.9225 - precision: 0.9508 - recall: 0.8092\n",
      "Epoch 380/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2146 - accuracy: 0.9253 - precision: 0.9530 - recall: 0.8161\n",
      "Epoch 381/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2137 - accuracy: 0.9293 - precision: 0.9600 - recall: 0.8221\n",
      "Epoch 382/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2146 - accuracy: 0.9250 - precision: 0.9512 - recall: 0.8169\n",
      "Epoch 383/1000\n",
      "351/351 [==============================] - 0s 433us/step - loss: 0.2139 - accuracy: 0.9253 - precision: 0.9567 - recall: 0.8127\n",
      "Epoch 384/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2138 - accuracy: 0.9256 - precision: 0.9567 - recall: 0.8135\n",
      "Epoch 385/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2141 - accuracy: 0.9247 - precision: 0.9520 - recall: 0.8152\n",
      "Epoch 386/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2143 - accuracy: 0.9242 - precision: 0.9556 - recall: 0.8101\n",
      "Epoch 387/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2142 - accuracy: 0.9253 - precision: 0.9530 - recall: 0.8161\n",
      "Epoch 388/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2155 - accuracy: 0.9247 - precision: 0.9548 - recall: 0.8127\n",
      "Epoch 389/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2153 - accuracy: 0.9267 - precision: 0.9597 - recall: 0.8144\n",
      "Epoch 390/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2129 - accuracy: 0.9230 - precision: 0.9499 - recall: 0.8118\n",
      "Epoch 391/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2136 - accuracy: 0.9267 - precision: 0.9615 - recall: 0.8127\n",
      "Epoch 392/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2126 - accuracy: 0.9279 - precision: 0.9562 - recall: 0.8212\n",
      "Epoch 393/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2144 - accuracy: 0.9253 - precision: 0.9549 - recall: 0.8144\n",
      "Epoch 394/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2145 - accuracy: 0.9287 - precision: 0.9590 - recall: 0.8212\n",
      "Epoch 395/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2134 - accuracy: 0.9262 - precision: 0.9559 - recall: 0.8161\n",
      "Epoch 396/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2147 - accuracy: 0.9225 - precision: 0.9535 - recall: 0.8067\n",
      "Epoch 397/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2137 - accuracy: 0.9267 - precision: 0.9644 - recall: 0.8101\n",
      "Epoch 398/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2145 - accuracy: 0.9236 - precision: 0.9500 - recall: 0.8135\n",
      "Epoch 399/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2137 - accuracy: 0.9265 - precision: 0.9606 - recall: 0.8127\n",
      "Epoch 400/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 437us/step - loss: 0.2136 - accuracy: 0.9256 - precision: 0.9586 - recall: 0.8118\n",
      "Epoch 401/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2133 - accuracy: 0.9242 - precision: 0.9484 - recall: 0.8169\n",
      "Epoch 402/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2139 - accuracy: 0.9242 - precision: 0.9547 - recall: 0.8109\n",
      "Epoch 403/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2145 - accuracy: 0.9250 - precision: 0.9557 - recall: 0.8127\n",
      "Epoch 404/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2135 - accuracy: 0.9247 - precision: 0.9557 - recall: 0.8118\n",
      "Epoch 405/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2127 - accuracy: 0.9270 - precision: 0.9625 - recall: 0.8127\n",
      "Epoch 406/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2136 - accuracy: 0.9247 - precision: 0.9585 - recall: 0.8092\n",
      "Epoch 407/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2137 - accuracy: 0.9259 - precision: 0.9550 - recall: 0.8161\n",
      "Epoch 408/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2145 - accuracy: 0.9250 - precision: 0.9576 - recall: 0.8109\n",
      "Epoch 409/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2136 - accuracy: 0.9279 - precision: 0.9580 - recall: 0.8195\n",
      "Epoch 410/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2133 - accuracy: 0.9276 - precision: 0.9664 - recall: 0.8109\n",
      "Epoch 411/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2141 - accuracy: 0.9227 - precision: 0.9508 - recall: 0.8101\n",
      "Epoch 412/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2133 - accuracy: 0.9259 - precision: 0.9596 - recall: 0.8118\n",
      "Epoch 413/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2143 - accuracy: 0.9236 - precision: 0.9592 - recall: 0.8050\n",
      "Epoch 414/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2140 - accuracy: 0.9227 - precision: 0.9508 - recall: 0.8101\n",
      "Epoch 415/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2139 - accuracy: 0.9265 - precision: 0.9606 - recall: 0.8127\n",
      "Epoch 416/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2128 - accuracy: 0.9245 - precision: 0.9556 - recall: 0.8109\n",
      "Epoch 417/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2129 - accuracy: 0.9267 - precision: 0.9625 - recall: 0.8118\n",
      "Epoch 418/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2145 - accuracy: 0.9242 - precision: 0.9493 - recall: 0.8161\n",
      "Epoch 419/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2141 - accuracy: 0.9233 - precision: 0.9555 - recall: 0.8075\n",
      "Epoch 420/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2135 - accuracy: 0.9210 - precision: 0.9514 - recall: 0.8041\n",
      "Epoch 421/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2141 - accuracy: 0.9262 - precision: 0.9559 - recall: 0.8161\n",
      "Epoch 422/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2130 - accuracy: 0.9265 - precision: 0.9578 - recall: 0.8152\n",
      "Epoch 423/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2134 - accuracy: 0.9239 - precision: 0.9537 - recall: 0.8109\n",
      "Epoch 424/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2132 - accuracy: 0.9239 - precision: 0.9528 - recall: 0.8118\n",
      "Epoch 425/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2133 - accuracy: 0.9262 - precision: 0.9550 - recall: 0.8169\n",
      "Epoch 426/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2147 - accuracy: 0.9236 - precision: 0.9537 - recall: 0.8101\n",
      "Epoch 427/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2134 - accuracy: 0.9216 - precision: 0.9497 - recall: 0.8075\n",
      "Epoch 428/1000\n",
      "351/351 [==============================] - 0s 455us/step - loss: 0.2143 - accuracy: 0.9230 - precision: 0.9545 - recall: 0.8075\n",
      "Epoch 429/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2131 - accuracy: 0.9270 - precision: 0.9560 - recall: 0.8186\n",
      "Epoch 430/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2144 - accuracy: 0.9267 - precision: 0.9597 - recall: 0.8144\n",
      "Epoch 431/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2139 - accuracy: 0.9267 - precision: 0.9615 - recall: 0.8127\n",
      "Epoch 432/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2113 - accuracy: 0.9279 - precision: 0.9645 - recall: 0.8135\n",
      "Epoch 433/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2128 - accuracy: 0.9250 - precision: 0.9467 - recall: 0.8212\n",
      "Epoch 434/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2133 - accuracy: 0.9273 - precision: 0.9626 - recall: 0.8135\n",
      "Epoch 435/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2139 - accuracy: 0.9276 - precision: 0.9598 - recall: 0.8169\n",
      "Epoch 436/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2129 - accuracy: 0.9236 - precision: 0.9500 - recall: 0.8135\n",
      "Epoch 437/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2123 - accuracy: 0.9245 - precision: 0.9547 - recall: 0.8118\n",
      "Epoch 438/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2135 - accuracy: 0.9253 - precision: 0.9585 - recall: 0.8109\n",
      "Epoch 439/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2131 - accuracy: 0.9242 - precision: 0.9547 - recall: 0.8109\n",
      "Epoch 440/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2129 - accuracy: 0.9265 - precision: 0.9578 - recall: 0.8152\n",
      "Epoch 441/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2129 - accuracy: 0.9253 - precision: 0.9530 - recall: 0.8161\n",
      "Epoch 442/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2122 - accuracy: 0.9262 - precision: 0.9550 - recall: 0.8169\n",
      "Epoch 443/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2139 - accuracy: 0.9265 - precision: 0.9587 - recall: 0.8144\n",
      "Epoch 444/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2133 - accuracy: 0.9270 - precision: 0.9644 - recall: 0.8109\n",
      "Epoch 445/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2132 - accuracy: 0.9270 - precision: 0.9597 - recall: 0.8152\n",
      "Epoch 446/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2123 - accuracy: 0.9256 - precision: 0.9558 - recall: 0.8144\n",
      "Epoch 447/1000\n",
      "351/351 [==============================] - 0s 427us/step - loss: 0.2140 - accuracy: 0.9242 - precision: 0.9547 - recall: 0.8109\n",
      "Epoch 448/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2116 - accuracy: 0.9276 - precision: 0.9626 - recall: 0.8144\n",
      "Epoch 449/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2125 - accuracy: 0.9273 - precision: 0.9626 - recall: 0.8135\n",
      "Epoch 450/1000\n",
      "351/351 [==============================] - 0s 461us/step - loss: 0.2130 - accuracy: 0.9262 - precision: 0.9605 - recall: 0.8118\n",
      "Epoch 451/1000\n",
      "351/351 [==============================] - 0s 473us/step - loss: 0.2122 - accuracy: 0.9259 - precision: 0.9568 - recall: 0.8144\n",
      "Epoch 452/1000\n",
      "351/351 [==============================] - 0s 491us/step - loss: 0.2122 - accuracy: 0.9265 - precision: 0.9606 - recall: 0.8127\n",
      "Epoch 453/1000\n",
      "351/351 [==============================] - 0s 466us/step - loss: 0.2112 - accuracy: 0.9247 - precision: 0.9548 - recall: 0.8127\n",
      "Epoch 454/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2127 - accuracy: 0.9256 - precision: 0.9604 - recall: 0.8101\n",
      "Epoch 455/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2121 - accuracy: 0.9287 - precision: 0.9590 - recall: 0.8212\n",
      "Epoch 456/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2134 - accuracy: 0.9239 - precision: 0.9537 - recall: 0.8109\n",
      "Epoch 457/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 438us/step - loss: 0.2117 - accuracy: 0.9253 - precision: 0.9512 - recall: 0.8178\n",
      "Epoch 458/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2121 - accuracy: 0.9273 - precision: 0.9579 - recall: 0.8178\n",
      "Epoch 459/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2128 - accuracy: 0.9242 - precision: 0.9574 - recall: 0.8084\n",
      "Epoch 460/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2109 - accuracy: 0.9256 - precision: 0.9549 - recall: 0.8152\n",
      "Epoch 461/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2128 - accuracy: 0.9247 - precision: 0.9530 - recall: 0.8144\n",
      "Epoch 462/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2134 - accuracy: 0.9245 - precision: 0.9556 - recall: 0.8109\n",
      "Epoch 463/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2120 - accuracy: 0.9279 - precision: 0.9636 - recall: 0.8144\n",
      "Epoch 464/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2119 - accuracy: 0.9262 - precision: 0.9577 - recall: 0.8144\n",
      "Epoch 465/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2119 - accuracy: 0.9239 - precision: 0.9537 - recall: 0.8109\n",
      "Epoch 466/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2132 - accuracy: 0.9265 - precision: 0.9615 - recall: 0.8118\n",
      "Epoch 467/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2125 - accuracy: 0.9270 - precision: 0.9616 - recall: 0.8135\n",
      "Epoch 468/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2116 - accuracy: 0.9276 - precision: 0.9598 - recall: 0.8169\n",
      "Epoch 469/1000\n",
      "351/351 [==============================] - 0s 433us/step - loss: 0.2115 - accuracy: 0.9265 - precision: 0.9587 - recall: 0.8144\n",
      "Epoch 470/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2113 - accuracy: 0.9250 - precision: 0.9585 - recall: 0.8101\n",
      "Epoch 471/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2125 - accuracy: 0.9256 - precision: 0.9642 - recall: 0.8067\n",
      "Epoch 472/1000\n",
      "351/351 [==============================] - 0s 453us/step - loss: 0.2141 - accuracy: 0.9239 - precision: 0.9574 - recall: 0.8075\n",
      "Epoch 473/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2132 - accuracy: 0.9259 - precision: 0.9568 - recall: 0.8144\n",
      "Epoch 474/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2114 - accuracy: 0.9279 - precision: 0.9636 - recall: 0.8144\n",
      "Epoch 475/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2113 - accuracy: 0.9273 - precision: 0.9598 - recall: 0.8161\n",
      "Epoch 476/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2135 - accuracy: 0.9265 - precision: 0.9596 - recall: 0.8135\n",
      "Epoch 477/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2110 - accuracy: 0.9265 - precision: 0.9606 - recall: 0.8127\n",
      "Epoch 478/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2124 - accuracy: 0.9250 - precision: 0.9594 - recall: 0.8092\n",
      "Epoch 479/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2123 - accuracy: 0.9225 - precision: 0.9517 - recall: 0.8084\n",
      "Epoch 480/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2114 - accuracy: 0.9304 - precision: 0.9715 - recall: 0.8152\n",
      "Epoch 481/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2114 - accuracy: 0.9245 - precision: 0.9593 - recall: 0.8075\n",
      "Epoch 482/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2107 - accuracy: 0.9276 - precision: 0.9589 - recall: 0.8178\n",
      "Epoch 483/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2114 - accuracy: 0.9270 - precision: 0.9597 - recall: 0.8152\n",
      "Epoch 484/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2110 - accuracy: 0.9290 - precision: 0.9646 - recall: 0.8169\n",
      "Epoch 485/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2114 - accuracy: 0.9273 - precision: 0.9644 - recall: 0.8118\n",
      "Epoch 486/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2123 - accuracy: 0.9236 - precision: 0.9528 - recall: 0.8109\n",
      "Epoch 487/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2123 - accuracy: 0.9245 - precision: 0.9612 - recall: 0.8058\n",
      "Epoch 488/1000\n",
      "351/351 [==============================] - 0s 427us/step - loss: 0.2129 - accuracy: 0.9259 - precision: 0.9605 - recall: 0.8109\n",
      "Epoch 489/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2114 - accuracy: 0.9276 - precision: 0.9645 - recall: 0.8127\n",
      "Epoch 490/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2122 - accuracy: 0.9250 - precision: 0.9585 - recall: 0.8101\n",
      "Epoch 491/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2104 - accuracy: 0.9282 - precision: 0.9599 - recall: 0.8186\n",
      "Epoch 492/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2128 - accuracy: 0.9239 - precision: 0.9519 - recall: 0.8127\n",
      "Epoch 493/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2115 - accuracy: 0.9253 - precision: 0.9567 - recall: 0.8127\n",
      "Epoch 494/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2104 - accuracy: 0.9270 - precision: 0.9635 - recall: 0.8118\n",
      "Epoch 495/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2116 - accuracy: 0.9242 - precision: 0.9510 - recall: 0.8144\n",
      "Epoch 496/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2116 - accuracy: 0.9267 - precision: 0.9588 - recall: 0.8152\n",
      "Epoch 497/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2119 - accuracy: 0.9245 - precision: 0.9566 - recall: 0.8101\n",
      "Epoch 498/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2109 - accuracy: 0.9296 - precision: 0.9657 - recall: 0.8178\n",
      "Epoch 499/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2118 - accuracy: 0.9273 - precision: 0.9588 - recall: 0.8169\n",
      "Epoch 500/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2118 - accuracy: 0.9247 - precision: 0.9530 - recall: 0.8144\n",
      "Epoch 501/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2114 - accuracy: 0.9273 - precision: 0.9654 - recall: 0.8109\n",
      "Epoch 502/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2119 - accuracy: 0.9253 - precision: 0.9576 - recall: 0.8118\n",
      "Epoch 503/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2110 - accuracy: 0.9287 - precision: 0.9618 - recall: 0.8186\n",
      "Epoch 504/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2112 - accuracy: 0.9259 - precision: 0.9540 - recall: 0.8169\n",
      "Epoch 505/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2117 - accuracy: 0.9265 - precision: 0.9587 - recall: 0.8144\n",
      "Epoch 506/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2113 - accuracy: 0.9245 - precision: 0.9529 - recall: 0.8135\n",
      "Epoch 507/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2117 - accuracy: 0.9259 - precision: 0.9586 - recall: 0.8127\n",
      "Epoch 508/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2112 - accuracy: 0.9282 - precision: 0.9599 - recall: 0.8186\n",
      "Epoch 509/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2108 - accuracy: 0.9247 - precision: 0.9557 - recall: 0.8118\n",
      "Epoch 510/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2112 - accuracy: 0.9256 - precision: 0.9540 - recall: 0.8161\n",
      "Epoch 511/1000\n",
      "351/351 [==============================] - 0s 456us/step - loss: 0.2112 - accuracy: 0.9250 - precision: 0.9548 - recall: 0.8135\n",
      "Epoch 512/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2118 - accuracy: 0.9265 - precision: 0.9615 - recall: 0.8118\n",
      "Epoch 513/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2112 - accuracy: 0.9270 - precision: 0.9588 - recall: 0.8161\n",
      "Epoch 514/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 439us/step - loss: 0.2096 - accuracy: 0.9259 - precision: 0.9577 - recall: 0.8135\n",
      "Epoch 515/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2116 - accuracy: 0.9236 - precision: 0.9528 - recall: 0.8109\n",
      "Epoch 516/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2120 - accuracy: 0.9250 - precision: 0.9567 - recall: 0.8118\n",
      "Epoch 517/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2112 - accuracy: 0.9270 - precision: 0.9570 - recall: 0.8178\n",
      "Epoch 518/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2113 - accuracy: 0.9247 - precision: 0.9585 - recall: 0.8092\n",
      "Epoch 519/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2086 - accuracy: 0.9265 - precision: 0.9587 - recall: 0.8144\n",
      "Epoch 520/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2112 - accuracy: 0.9273 - precision: 0.9626 - recall: 0.8135\n",
      "Epoch 521/1000\n",
      "351/351 [==============================] - 0s 461us/step - loss: 0.2108 - accuracy: 0.9233 - precision: 0.9545 - recall: 0.8084\n",
      "Epoch 522/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2103 - accuracy: 0.9253 - precision: 0.9549 - recall: 0.8144\n",
      "Epoch 523/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2101 - accuracy: 0.9267 - precision: 0.9615 - recall: 0.8127\n",
      "Epoch 524/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2106 - accuracy: 0.9282 - precision: 0.9636 - recall: 0.8152\n",
      "Epoch 525/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2114 - accuracy: 0.9242 - precision: 0.9538 - recall: 0.8118\n",
      "Epoch 526/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2111 - accuracy: 0.9296 - precision: 0.9666 - recall: 0.8169\n",
      "Epoch 527/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2123 - accuracy: 0.9250 - precision: 0.9548 - recall: 0.8135\n",
      "Epoch 528/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2104 - accuracy: 0.9262 - precision: 0.9615 - recall: 0.8109\n",
      "Epoch 529/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2103 - accuracy: 0.9253 - precision: 0.9585 - recall: 0.8109\n",
      "Epoch 530/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2107 - accuracy: 0.9262 - precision: 0.9596 - recall: 0.8127\n",
      "Epoch 531/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2119 - accuracy: 0.9276 - precision: 0.9626 - recall: 0.8144\n",
      "Epoch 532/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2110 - accuracy: 0.9247 - precision: 0.9548 - recall: 0.8127\n",
      "Epoch 533/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2112 - accuracy: 0.9253 - precision: 0.9623 - recall: 0.8075\n",
      "Epoch 534/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2104 - accuracy: 0.9265 - precision: 0.9596 - recall: 0.8135\n",
      "Epoch 535/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2103 - accuracy: 0.9267 - precision: 0.9560 - recall: 0.8178\n",
      "Epoch 536/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2107 - accuracy: 0.9265 - precision: 0.9550 - recall: 0.8178\n",
      "Epoch 537/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2086 - accuracy: 0.9279 - precision: 0.9598 - recall: 0.8178\n",
      "Epoch 538/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2107 - accuracy: 0.9262 - precision: 0.9587 - recall: 0.8135\n",
      "Epoch 539/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2107 - accuracy: 0.9267 - precision: 0.9597 - recall: 0.8144\n",
      "Epoch 540/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2096 - accuracy: 0.9284 - precision: 0.9655 - recall: 0.8144\n",
      "Epoch 541/1000\n",
      "351/351 [==============================] - 0s 454us/step - loss: 0.2107 - accuracy: 0.9245 - precision: 0.9566 - recall: 0.8101\n",
      "Epoch 542/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2103 - accuracy: 0.9276 - precision: 0.9673 - recall: 0.8101\n",
      "Epoch 543/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2106 - accuracy: 0.9259 - precision: 0.9531 - recall: 0.8178\n",
      "Epoch 544/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2098 - accuracy: 0.9273 - precision: 0.9570 - recall: 0.8186\n",
      "Epoch 545/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2097 - accuracy: 0.9259 - precision: 0.9550 - recall: 0.8161\n",
      "Epoch 546/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2099 - accuracy: 0.9304 - precision: 0.9667 - recall: 0.8195\n",
      "Epoch 547/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2102 - accuracy: 0.9273 - precision: 0.9616 - recall: 0.8144\n",
      "Epoch 548/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2099 - accuracy: 0.9245 - precision: 0.9511 - recall: 0.8152\n",
      "Epoch 549/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2103 - accuracy: 0.9296 - precision: 0.9601 - recall: 0.8229\n",
      "Epoch 550/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2095 - accuracy: 0.9273 - precision: 0.9598 - recall: 0.8161\n",
      "Epoch 551/1000\n",
      "351/351 [==============================] - 0s 471us/step - loss: 0.2104 - accuracy: 0.9256 - precision: 0.9604 - recall: 0.8101\n",
      "Epoch 552/1000\n",
      "351/351 [==============================] - 0s 608us/step - loss: 0.2107 - accuracy: 0.9242 - precision: 0.9556 - recall: 0.8101\n",
      "Epoch 553/1000\n",
      "351/351 [==============================] - 0s 539us/step - loss: 0.2096 - accuracy: 0.9276 - precision: 0.9617 - recall: 0.8152\n",
      "Epoch 554/1000\n",
      "351/351 [==============================] - 0s 469us/step - loss: 0.2097 - accuracy: 0.9253 - precision: 0.9558 - recall: 0.8135\n",
      "Epoch 555/1000\n",
      "351/351 [==============================] - 0s 473us/step - loss: 0.2090 - accuracy: 0.9279 - precision: 0.9626 - recall: 0.8152\n",
      "Epoch 556/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2098 - accuracy: 0.9270 - precision: 0.9588 - recall: 0.8161\n",
      "Epoch 557/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2099 - accuracy: 0.9265 - precision: 0.9596 - recall: 0.8135\n",
      "Epoch 558/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2100 - accuracy: 0.9265 - precision: 0.9615 - recall: 0.8118\n",
      "Epoch 559/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2098 - accuracy: 0.9259 - precision: 0.9550 - recall: 0.8161\n",
      "Epoch 560/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2099 - accuracy: 0.9265 - precision: 0.9569 - recall: 0.8161\n",
      "Epoch 561/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2096 - accuracy: 0.9279 - precision: 0.9617 - recall: 0.8161\n",
      "Epoch 562/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2099 - accuracy: 0.9256 - precision: 0.9577 - recall: 0.8127\n",
      "Epoch 563/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2101 - accuracy: 0.9279 - precision: 0.9608 - recall: 0.8169\n",
      "Epoch 564/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2091 - accuracy: 0.9267 - precision: 0.9597 - recall: 0.8144\n",
      "Epoch 565/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2093 - accuracy: 0.9279 - precision: 0.9645 - recall: 0.8135\n",
      "Epoch 566/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2102 - accuracy: 0.9256 - precision: 0.9604 - recall: 0.8101\n",
      "Epoch 567/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2094 - accuracy: 0.9284 - precision: 0.9599 - recall: 0.8195\n",
      "Epoch 568/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2091 - accuracy: 0.9270 - precision: 0.9663 - recall: 0.8092\n",
      "Epoch 569/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2088 - accuracy: 0.9270 - precision: 0.9597 - recall: 0.8152\n",
      "Epoch 570/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2106 - accuracy: 0.9256 - precision: 0.9577 - recall: 0.8127\n",
      "Epoch 571/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 433us/step - loss: 0.2098 - accuracy: 0.9262 - precision: 0.9615 - recall: 0.8109\n",
      "Epoch 572/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2102 - accuracy: 0.9262 - precision: 0.9577 - recall: 0.8144\n",
      "Epoch 573/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2100 - accuracy: 0.9284 - precision: 0.9655 - recall: 0.8144\n",
      "Epoch 574/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2101 - accuracy: 0.9267 - precision: 0.9625 - recall: 0.8118\n",
      "Epoch 575/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2095 - accuracy: 0.9253 - precision: 0.9576 - recall: 0.8118\n",
      "Epoch 576/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2092 - accuracy: 0.9262 - precision: 0.9624 - recall: 0.8101\n",
      "Epoch 577/1000\n",
      "351/351 [==============================] - 0s 427us/step - loss: 0.2083 - accuracy: 0.9267 - precision: 0.9634 - recall: 0.8109\n",
      "Epoch 578/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2107 - accuracy: 0.9262 - precision: 0.9577 - recall: 0.8144\n",
      "Epoch 579/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2095 - accuracy: 0.9262 - precision: 0.9577 - recall: 0.8144\n",
      "Epoch 580/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2092 - accuracy: 0.9279 - precision: 0.9598 - recall: 0.8178\n",
      "Epoch 581/1000\n",
      "351/351 [==============================] - 0s 518us/step - loss: 0.2091 - accuracy: 0.9279 - precision: 0.9645 - recall: 0.8135\n",
      "Epoch 582/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2097 - accuracy: 0.9265 - precision: 0.9578 - recall: 0.8152\n",
      "Epoch 583/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2093 - accuracy: 0.9267 - precision: 0.9578 - recall: 0.8161\n",
      "Epoch 584/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2086 - accuracy: 0.9270 - precision: 0.9606 - recall: 0.8144\n",
      "Epoch 585/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2087 - accuracy: 0.9276 - precision: 0.9626 - recall: 0.8144\n",
      "Epoch 586/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2094 - accuracy: 0.9267 - precision: 0.9615 - recall: 0.8127\n",
      "Epoch 587/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2096 - accuracy: 0.9247 - precision: 0.9575 - recall: 0.8101\n",
      "Epoch 588/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2088 - accuracy: 0.9282 - precision: 0.9617 - recall: 0.8169\n",
      "Epoch 589/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2098 - accuracy: 0.9253 - precision: 0.9576 - recall: 0.8118\n",
      "Epoch 590/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2084 - accuracy: 0.9259 - precision: 0.9596 - recall: 0.8118\n",
      "Epoch 591/1000\n",
      "351/351 [==============================] - 0s 456us/step - loss: 0.2098 - accuracy: 0.9265 - precision: 0.9578 - recall: 0.8152\n",
      "Epoch 592/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2109 - accuracy: 0.9259 - precision: 0.9586 - recall: 0.8127\n",
      "Epoch 593/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2104 - accuracy: 0.9276 - precision: 0.9607 - recall: 0.8161\n",
      "Epoch 594/1000\n",
      "351/351 [==============================] - 0s 433us/step - loss: 0.2090 - accuracy: 0.9290 - precision: 0.9628 - recall: 0.8186\n",
      "Epoch 595/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2081 - accuracy: 0.9270 - precision: 0.9692 - recall: 0.8067\n",
      "Epoch 596/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2079 - accuracy: 0.9279 - precision: 0.9617 - recall: 0.8161\n",
      "Epoch 597/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2095 - accuracy: 0.9267 - precision: 0.9634 - recall: 0.8109\n",
      "Epoch 598/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2076 - accuracy: 0.9282 - precision: 0.9608 - recall: 0.8178\n",
      "Epoch 599/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2094 - accuracy: 0.9267 - precision: 0.9588 - recall: 0.8152\n",
      "Epoch 600/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2083 - accuracy: 0.9296 - precision: 0.9638 - recall: 0.8195\n",
      "Epoch 601/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2088 - accuracy: 0.9256 - precision: 0.9558 - recall: 0.8144\n",
      "Epoch 602/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2100 - accuracy: 0.9256 - precision: 0.9558 - recall: 0.8144\n",
      "Epoch 603/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2089 - accuracy: 0.9304 - precision: 0.9676 - recall: 0.8186\n",
      "Epoch 604/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2086 - accuracy: 0.9282 - precision: 0.9617 - recall: 0.8169\n",
      "Epoch 605/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2090 - accuracy: 0.9259 - precision: 0.9596 - recall: 0.8118\n",
      "Epoch 606/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2107 - accuracy: 0.9259 - precision: 0.9624 - recall: 0.8092\n",
      "Epoch 607/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2090 - accuracy: 0.9259 - precision: 0.9614 - recall: 0.8101\n",
      "Epoch 608/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2088 - accuracy: 0.9287 - precision: 0.9656 - recall: 0.8152\n",
      "Epoch 609/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2083 - accuracy: 0.9299 - precision: 0.9648 - recall: 0.8195\n",
      "Epoch 610/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2100 - accuracy: 0.9267 - precision: 0.9597 - recall: 0.8144\n",
      "Epoch 611/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2094 - accuracy: 0.9267 - precision: 0.9588 - recall: 0.8152\n",
      "Epoch 612/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2087 - accuracy: 0.9282 - precision: 0.9599 - recall: 0.8186\n",
      "Epoch 613/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2087 - accuracy: 0.9302 - precision: 0.9657 - recall: 0.8195\n",
      "Epoch 614/1000\n",
      "351/351 [==============================] - 0s 455us/step - loss: 0.2095 - accuracy: 0.9279 - precision: 0.9598 - recall: 0.8178\n",
      "Epoch 615/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2085 - accuracy: 0.9279 - precision: 0.9654 - recall: 0.8127\n",
      "Epoch 616/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2091 - accuracy: 0.9270 - precision: 0.9606 - recall: 0.8144\n",
      "Epoch 617/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2091 - accuracy: 0.9282 - precision: 0.9655 - recall: 0.8135\n",
      "Epoch 618/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2090 - accuracy: 0.9296 - precision: 0.9638 - recall: 0.8195\n",
      "Epoch 619/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2086 - accuracy: 0.9259 - precision: 0.9531 - recall: 0.8178\n",
      "Epoch 620/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2080 - accuracy: 0.9259 - precision: 0.9586 - recall: 0.8127\n",
      "Epoch 621/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2070 - accuracy: 0.9302 - precision: 0.9657 - recall: 0.8195\n",
      "Epoch 622/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2075 - accuracy: 0.9296 - precision: 0.9629 - recall: 0.8204\n",
      "Epoch 623/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2097 - accuracy: 0.9279 - precision: 0.9626 - recall: 0.8152\n",
      "Epoch 624/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2079 - accuracy: 0.9273 - precision: 0.9570 - recall: 0.8186\n",
      "Epoch 625/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2084 - accuracy: 0.9276 - precision: 0.9580 - recall: 0.8186\n",
      "Epoch 626/1000\n",
      "351/351 [==============================] - 0s 461us/step - loss: 0.2084 - accuracy: 0.9284 - precision: 0.9618 - recall: 0.8178\n",
      "Epoch 627/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2076 - accuracy: 0.9290 - precision: 0.9703 - recall: 0.8118\n",
      "Epoch 628/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 436us/step - loss: 0.2092 - accuracy: 0.9256 - precision: 0.9586 - recall: 0.8118\n",
      "Epoch 629/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2076 - accuracy: 0.9273 - precision: 0.9570 - recall: 0.8186\n",
      "Epoch 630/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2087 - accuracy: 0.9284 - precision: 0.9608 - recall: 0.8186\n",
      "Epoch 631/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2098 - accuracy: 0.9265 - precision: 0.9615 - recall: 0.8118\n",
      "Epoch 632/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2065 - accuracy: 0.9276 - precision: 0.9589 - recall: 0.8178\n",
      "Epoch 633/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2094 - accuracy: 0.9293 - precision: 0.9647 - recall: 0.8178\n",
      "Epoch 634/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2082 - accuracy: 0.9284 - precision: 0.9655 - recall: 0.8144\n",
      "Epoch 635/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2096 - accuracy: 0.9253 - precision: 0.9576 - recall: 0.8118\n",
      "Epoch 636/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2088 - accuracy: 0.9273 - precision: 0.9579 - recall: 0.8178\n",
      "Epoch 637/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2083 - accuracy: 0.9262 - precision: 0.9605 - recall: 0.8118\n",
      "Epoch 638/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2076 - accuracy: 0.9270 - precision: 0.9606 - recall: 0.8144\n",
      "Epoch 639/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2085 - accuracy: 0.9293 - precision: 0.9647 - recall: 0.8178\n",
      "Epoch 640/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2085 - accuracy: 0.9279 - precision: 0.9598 - recall: 0.8178\n",
      "Epoch 641/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2091 - accuracy: 0.9284 - precision: 0.9608 - recall: 0.8186\n",
      "Epoch 642/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2084 - accuracy: 0.9270 - precision: 0.9616 - recall: 0.8135\n",
      "Epoch 643/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2080 - accuracy: 0.9279 - precision: 0.9636 - recall: 0.8144\n",
      "Epoch 644/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2080 - accuracy: 0.9273 - precision: 0.9579 - recall: 0.8178\n",
      "Epoch 645/1000\n",
      "351/351 [==============================] - 0s 453us/step - loss: 0.2078 - accuracy: 0.9267 - precision: 0.9615 - recall: 0.8127\n",
      "Epoch 646/1000\n",
      "351/351 [==============================] - 0s 484us/step - loss: 0.2077 - accuracy: 0.9304 - precision: 0.9676 - recall: 0.8186\n",
      "Epoch 647/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2089 - accuracy: 0.9287 - precision: 0.9600 - recall: 0.8204\n",
      "Epoch 648/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2086 - accuracy: 0.9290 - precision: 0.9656 - recall: 0.8161\n",
      "Epoch 649/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2084 - accuracy: 0.9296 - precision: 0.9657 - recall: 0.8178\n",
      "Epoch 650/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2084 - accuracy: 0.9256 - precision: 0.9558 - recall: 0.8144\n",
      "Epoch 651/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2085 - accuracy: 0.9282 - precision: 0.9599 - recall: 0.8186\n",
      "Epoch 652/1000\n",
      "351/351 [==============================] - 0s 427us/step - loss: 0.2080 - accuracy: 0.9299 - precision: 0.9629 - recall: 0.8212\n",
      "Epoch 653/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2078 - accuracy: 0.9265 - precision: 0.9624 - recall: 0.8109\n",
      "Epoch 654/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2074 - accuracy: 0.9259 - precision: 0.9586 - recall: 0.8127\n",
      "Epoch 655/1000\n",
      "351/351 [==============================] - 0s 493us/step - loss: 0.2099 - accuracy: 0.9290 - precision: 0.9637 - recall: 0.8178\n",
      "Epoch 656/1000\n",
      "351/351 [==============================] - 0s 479us/step - loss: 0.2064 - accuracy: 0.9313 - precision: 0.9687 - recall: 0.8204\n",
      "Epoch 657/1000\n",
      "351/351 [==============================] - 0s 465us/step - loss: 0.2074 - accuracy: 0.9290 - precision: 0.9665 - recall: 0.8152\n",
      "Epoch 658/1000\n",
      "351/351 [==============================] - 0s 460us/step - loss: 0.2076 - accuracy: 0.9302 - precision: 0.9667 - recall: 0.8186\n",
      "Epoch 659/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2090 - accuracy: 0.9284 - precision: 0.9581 - recall: 0.8212\n",
      "Epoch 660/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2078 - accuracy: 0.9304 - precision: 0.9620 - recall: 0.8238\n",
      "Epoch 661/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2075 - accuracy: 0.9265 - precision: 0.9624 - recall: 0.8109\n",
      "Epoch 662/1000\n",
      "351/351 [==============================] - 0s 458us/step - loss: 0.2084 - accuracy: 0.9284 - precision: 0.9608 - recall: 0.8186\n",
      "Epoch 663/1000\n",
      "351/351 [==============================] - 0s 501us/step - loss: 0.2070 - accuracy: 0.9282 - precision: 0.9655 - recall: 0.8135\n",
      "Epoch 664/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2068 - accuracy: 0.9259 - precision: 0.9642 - recall: 0.8075\n",
      "Epoch 665/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2069 - accuracy: 0.9265 - precision: 0.9634 - recall: 0.8101\n",
      "Epoch 666/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2075 - accuracy: 0.9282 - precision: 0.9655 - recall: 0.8135\n",
      "Epoch 667/1000\n",
      "351/351 [==============================] - 0s 460us/step - loss: 0.2065 - accuracy: 0.9296 - precision: 0.9647 - recall: 0.8186\n",
      "Epoch 668/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2083 - accuracy: 0.9259 - precision: 0.9605 - recall: 0.8109\n",
      "Epoch 669/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2070 - accuracy: 0.9284 - precision: 0.9590 - recall: 0.8204\n",
      "Epoch 670/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2074 - accuracy: 0.9279 - precision: 0.9626 - recall: 0.8152\n",
      "Epoch 671/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2086 - accuracy: 0.9253 - precision: 0.9585 - recall: 0.8109\n",
      "Epoch 672/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2067 - accuracy: 0.9276 - precision: 0.9664 - recall: 0.8109\n",
      "Epoch 673/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2067 - accuracy: 0.9284 - precision: 0.9608 - recall: 0.8186\n",
      "Epoch 674/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2079 - accuracy: 0.9282 - precision: 0.9655 - recall: 0.8135\n",
      "Epoch 675/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2093 - accuracy: 0.9282 - precision: 0.9617 - recall: 0.8169\n",
      "Epoch 676/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2081 - accuracy: 0.9276 - precision: 0.9626 - recall: 0.8144\n",
      "Epoch 677/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2071 - accuracy: 0.9299 - precision: 0.9629 - recall: 0.8212\n",
      "Epoch 678/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2071 - accuracy: 0.9282 - precision: 0.9627 - recall: 0.8161\n",
      "Epoch 679/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2068 - accuracy: 0.9279 - precision: 0.9626 - recall: 0.8152\n",
      "Epoch 680/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2072 - accuracy: 0.9265 - precision: 0.9550 - recall: 0.8178\n",
      "Epoch 681/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2068 - accuracy: 0.9290 - precision: 0.9628 - recall: 0.8186\n",
      "Epoch 682/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2078 - accuracy: 0.9276 - precision: 0.9607 - recall: 0.8161\n",
      "Epoch 683/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2071 - accuracy: 0.9287 - precision: 0.9637 - recall: 0.8169\n",
      "Epoch 684/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2068 - accuracy: 0.9290 - precision: 0.9637 - recall: 0.8178\n",
      "Epoch 685/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 438us/step - loss: 0.2065 - accuracy: 0.9299 - precision: 0.9676 - recall: 0.8169\n",
      "Epoch 686/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2080 - accuracy: 0.9284 - precision: 0.9590 - recall: 0.8204\n",
      "Epoch 687/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2069 - accuracy: 0.9245 - precision: 0.9584 - recall: 0.8084\n",
      "Epoch 688/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2094 - accuracy: 0.9287 - precision: 0.9637 - recall: 0.8169\n",
      "Epoch 689/1000\n",
      "351/351 [==============================] - 0s 427us/step - loss: 0.2066 - accuracy: 0.9302 - precision: 0.9657 - recall: 0.8195\n",
      "Epoch 690/1000\n",
      "351/351 [==============================] - 0s 427us/step - loss: 0.2072 - accuracy: 0.9287 - precision: 0.9627 - recall: 0.8178\n",
      "Epoch 691/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2070 - accuracy: 0.9284 - precision: 0.9655 - recall: 0.8144\n",
      "Epoch 692/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2055 - accuracy: 0.9293 - precision: 0.9656 - recall: 0.8169\n",
      "Epoch 693/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2072 - accuracy: 0.9284 - precision: 0.9627 - recall: 0.8169\n",
      "Epoch 694/1000\n",
      "351/351 [==============================] - 0s 426us/step - loss: 0.2071 - accuracy: 0.9284 - precision: 0.9590 - recall: 0.8204\n",
      "Epoch 695/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2065 - accuracy: 0.9290 - precision: 0.9665 - recall: 0.8152\n",
      "Epoch 696/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2082 - accuracy: 0.9273 - precision: 0.9588 - recall: 0.8169\n",
      "Epoch 697/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2064 - accuracy: 0.9293 - precision: 0.9637 - recall: 0.8186\n",
      "Epoch 698/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2066 - accuracy: 0.9273 - precision: 0.9644 - recall: 0.8118\n",
      "Epoch 699/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2068 - accuracy: 0.9282 - precision: 0.9664 - recall: 0.8127\n",
      "Epoch 700/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2072 - accuracy: 0.9290 - precision: 0.9582 - recall: 0.8229\n",
      "Epoch 701/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2055 - accuracy: 0.9287 - precision: 0.9674 - recall: 0.8135\n",
      "Epoch 702/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2066 - accuracy: 0.9276 - precision: 0.9617 - recall: 0.8152\n",
      "Epoch 703/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2066 - accuracy: 0.9302 - precision: 0.9648 - recall: 0.8204\n",
      "Epoch 704/1000\n",
      "351/351 [==============================] - 0s 523us/step - loss: 0.2069 - accuracy: 0.9293 - precision: 0.9647 - recall: 0.8178\n",
      "Epoch 705/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2063 - accuracy: 0.9299 - precision: 0.9648 - recall: 0.8195\n",
      "Epoch 706/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2063 - accuracy: 0.9265 - precision: 0.9606 - recall: 0.8127\n",
      "Epoch 707/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2063 - accuracy: 0.9296 - precision: 0.9647 - recall: 0.8186\n",
      "Epoch 708/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2059 - accuracy: 0.9290 - precision: 0.9637 - recall: 0.8178\n",
      "Epoch 709/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2057 - accuracy: 0.9304 - precision: 0.9695 - recall: 0.8169\n",
      "Epoch 710/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2071 - accuracy: 0.9310 - precision: 0.9677 - recall: 0.8204\n",
      "Epoch 711/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2078 - accuracy: 0.9267 - precision: 0.9569 - recall: 0.8169\n",
      "Epoch 712/1000\n",
      "351/351 [==============================] - 0s 427us/step - loss: 0.2083 - accuracy: 0.9270 - precision: 0.9597 - recall: 0.8152\n",
      "Epoch 713/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2060 - accuracy: 0.9282 - precision: 0.9693 - recall: 0.8101\n",
      "Epoch 714/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2056 - accuracy: 0.9279 - precision: 0.9589 - recall: 0.8186\n",
      "Epoch 715/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2067 - accuracy: 0.9302 - precision: 0.9695 - recall: 0.8161\n",
      "Epoch 716/1000\n",
      "351/351 [==============================] - 0s 456us/step - loss: 0.2064 - accuracy: 0.9287 - precision: 0.9637 - recall: 0.8169\n",
      "Epoch 717/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2060 - accuracy: 0.9299 - precision: 0.9657 - recall: 0.8186\n",
      "Epoch 718/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2062 - accuracy: 0.9250 - precision: 0.9557 - recall: 0.8127\n",
      "Epoch 719/1000\n",
      "351/351 [==============================] - 0s 455us/step - loss: 0.2058 - accuracy: 0.9302 - precision: 0.9657 - recall: 0.8195\n",
      "Epoch 720/1000\n",
      "351/351 [==============================] - 0s 477us/step - loss: 0.2055 - accuracy: 0.9296 - precision: 0.9695 - recall: 0.8144\n",
      "Epoch 721/1000\n",
      "351/351 [==============================] - 0s 455us/step - loss: 0.2051 - accuracy: 0.9296 - precision: 0.9601 - recall: 0.8229\n",
      "Epoch 722/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2063 - accuracy: 0.9293 - precision: 0.9619 - recall: 0.8204\n",
      "Epoch 723/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2067 - accuracy: 0.9282 - precision: 0.9645 - recall: 0.8144\n",
      "Epoch 724/1000\n",
      "351/351 [==============================] - 0s 456us/step - loss: 0.2055 - accuracy: 0.9302 - precision: 0.9648 - recall: 0.8204\n",
      "Epoch 725/1000\n",
      "351/351 [==============================] - 0s 473us/step - loss: 0.2051 - accuracy: 0.9304 - precision: 0.9611 - recall: 0.8246\n",
      "Epoch 726/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2051 - accuracy: 0.9293 - precision: 0.9647 - recall: 0.8178\n",
      "Epoch 727/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2061 - accuracy: 0.9279 - precision: 0.9654 - recall: 0.8127\n",
      "Epoch 728/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2067 - accuracy: 0.9262 - precision: 0.9643 - recall: 0.8084\n",
      "Epoch 729/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2057 - accuracy: 0.9313 - precision: 0.9659 - recall: 0.8229\n",
      "Epoch 730/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2059 - accuracy: 0.9290 - precision: 0.9628 - recall: 0.8186\n",
      "Epoch 731/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2061 - accuracy: 0.9290 - precision: 0.9646 - recall: 0.8169\n",
      "Epoch 732/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2065 - accuracy: 0.9270 - precision: 0.9616 - recall: 0.8135\n",
      "Epoch 733/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2059 - accuracy: 0.9304 - precision: 0.9686 - recall: 0.8178\n",
      "Epoch 734/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2051 - accuracy: 0.9279 - precision: 0.9580 - recall: 0.8195\n",
      "Epoch 735/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2054 - accuracy: 0.9290 - precision: 0.9665 - recall: 0.8152\n",
      "Epoch 736/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2076 - accuracy: 0.9282 - precision: 0.9636 - recall: 0.8152\n",
      "Epoch 737/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2069 - accuracy: 0.9262 - precision: 0.9596 - recall: 0.8127\n",
      "Epoch 738/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2061 - accuracy: 0.9270 - precision: 0.9625 - recall: 0.8127\n",
      "Epoch 739/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2067 - accuracy: 0.9256 - precision: 0.9567 - recall: 0.8135\n",
      "Epoch 740/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2054 - accuracy: 0.9273 - precision: 0.9607 - recall: 0.8152\n",
      "Epoch 741/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2055 - accuracy: 0.9313 - precision: 0.9668 - recall: 0.8221\n",
      "Epoch 742/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 449us/step - loss: 0.2054 - accuracy: 0.9293 - precision: 0.9637 - recall: 0.8186\n",
      "Epoch 743/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2064 - accuracy: 0.9296 - precision: 0.9657 - recall: 0.8178\n",
      "Epoch 744/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2053 - accuracy: 0.9239 - precision: 0.9501 - recall: 0.8144\n",
      "Epoch 745/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2057 - accuracy: 0.9290 - precision: 0.9656 - recall: 0.8161\n",
      "Epoch 746/1000\n",
      "351/351 [==============================] - 0s 427us/step - loss: 0.2050 - accuracy: 0.9296 - precision: 0.9685 - recall: 0.8152\n",
      "Epoch 747/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2064 - accuracy: 0.9279 - precision: 0.9636 - recall: 0.8144\n",
      "Epoch 748/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2057 - accuracy: 0.9270 - precision: 0.9588 - recall: 0.8161\n",
      "Epoch 749/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2058 - accuracy: 0.9270 - precision: 0.9560 - recall: 0.8186\n",
      "Epoch 750/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2059 - accuracy: 0.9299 - precision: 0.9676 - recall: 0.8169\n",
      "Epoch 751/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2051 - accuracy: 0.9276 - precision: 0.9635 - recall: 0.8135\n",
      "Epoch 752/1000\n",
      "351/351 [==============================] - 0s 426us/step - loss: 0.2053 - accuracy: 0.9276 - precision: 0.9645 - recall: 0.8127\n",
      "Epoch 753/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2057 - accuracy: 0.9267 - precision: 0.9560 - recall: 0.8178\n",
      "Epoch 754/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2050 - accuracy: 0.9296 - precision: 0.9610 - recall: 0.8221\n",
      "Epoch 755/1000\n",
      "351/351 [==============================] - 0s 427us/step - loss: 0.2067 - accuracy: 0.9290 - precision: 0.9656 - recall: 0.8161\n",
      "Epoch 756/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2052 - accuracy: 0.9282 - precision: 0.9608 - recall: 0.8178\n",
      "Epoch 757/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2050 - accuracy: 0.9290 - precision: 0.9675 - recall: 0.8144\n",
      "Epoch 758/1000\n",
      "351/351 [==============================] - 0s 469us/step - loss: 0.2048 - accuracy: 0.9322 - precision: 0.9707 - recall: 0.8212\n",
      "Epoch 759/1000\n",
      "351/351 [==============================] - 0s 457us/step - loss: 0.2063 - accuracy: 0.9279 - precision: 0.9645 - recall: 0.8135\n",
      "Epoch 760/1000\n",
      "351/351 [==============================] - 0s 470us/step - loss: 0.2054 - accuracy: 0.9262 - precision: 0.9550 - recall: 0.8169\n",
      "Epoch 761/1000\n",
      "351/351 [==============================] - 0s 461us/step - loss: 0.2053 - accuracy: 0.9296 - precision: 0.9695 - recall: 0.8144\n",
      "Epoch 762/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2072 - accuracy: 0.9282 - precision: 0.9655 - recall: 0.8135\n",
      "Epoch 763/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2068 - accuracy: 0.9284 - precision: 0.9618 - recall: 0.8178\n",
      "Epoch 764/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2043 - accuracy: 0.9322 - precision: 0.9707 - recall: 0.8212\n",
      "Epoch 765/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2067 - accuracy: 0.9279 - precision: 0.9580 - recall: 0.8195\n",
      "Epoch 766/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2079 - accuracy: 0.9262 - precision: 0.9605 - recall: 0.8118\n",
      "Epoch 767/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2051 - accuracy: 0.9282 - precision: 0.9608 - recall: 0.8178\n",
      "Epoch 768/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2044 - accuracy: 0.9304 - precision: 0.9639 - recall: 0.8221\n",
      "Epoch 769/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2052 - accuracy: 0.9273 - precision: 0.9635 - recall: 0.8127\n",
      "Epoch 770/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2061 - accuracy: 0.9284 - precision: 0.9590 - recall: 0.8204\n",
      "Epoch 771/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2060 - accuracy: 0.9290 - precision: 0.9675 - recall: 0.8144\n",
      "Epoch 772/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2068 - accuracy: 0.9256 - precision: 0.9633 - recall: 0.8075\n",
      "Epoch 773/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2062 - accuracy: 0.9273 - precision: 0.9607 - recall: 0.8152\n",
      "Epoch 774/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2046 - accuracy: 0.9299 - precision: 0.9657 - recall: 0.8186\n",
      "Epoch 775/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2063 - accuracy: 0.9262 - precision: 0.9541 - recall: 0.8178\n",
      "Epoch 776/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2069 - accuracy: 0.9265 - precision: 0.9606 - recall: 0.8127\n",
      "Epoch 777/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2051 - accuracy: 0.9290 - precision: 0.9656 - recall: 0.8161\n",
      "Epoch 778/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2055 - accuracy: 0.9296 - precision: 0.9610 - recall: 0.8221\n",
      "Epoch 779/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2052 - accuracy: 0.9307 - precision: 0.9658 - recall: 0.8212\n",
      "Epoch 780/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2067 - accuracy: 0.9304 - precision: 0.9620 - recall: 0.8238\n",
      "Epoch 781/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2058 - accuracy: 0.9296 - precision: 0.9666 - recall: 0.8169\n",
      "Epoch 782/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2060 - accuracy: 0.9265 - precision: 0.9541 - recall: 0.8186\n",
      "Epoch 783/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2047 - accuracy: 0.9279 - precision: 0.9608 - recall: 0.8169\n",
      "Epoch 784/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2043 - accuracy: 0.9267 - precision: 0.9615 - recall: 0.8127\n",
      "Epoch 785/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2046 - accuracy: 0.9296 - precision: 0.9629 - recall: 0.8204\n",
      "Epoch 786/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2058 - accuracy: 0.9270 - precision: 0.9551 - recall: 0.8195\n",
      "Epoch 787/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2055 - accuracy: 0.9299 - precision: 0.9657 - recall: 0.8186\n",
      "Epoch 788/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2037 - accuracy: 0.9282 - precision: 0.9645 - recall: 0.8144\n",
      "Epoch 789/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2055 - accuracy: 0.9282 - precision: 0.9636 - recall: 0.8152\n",
      "Epoch 790/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2052 - accuracy: 0.9296 - precision: 0.9629 - recall: 0.8204\n",
      "Epoch 791/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2040 - accuracy: 0.9302 - precision: 0.9657 - recall: 0.8195\n",
      "Epoch 792/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2048 - accuracy: 0.9296 - precision: 0.9657 - recall: 0.8178\n",
      "Epoch 793/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2077 - accuracy: 0.9242 - precision: 0.9593 - recall: 0.8067\n",
      "Epoch 794/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2048 - accuracy: 0.9276 - precision: 0.9580 - recall: 0.8186\n",
      "Epoch 795/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2041 - accuracy: 0.9310 - precision: 0.9706 - recall: 0.8178\n",
      "Epoch 796/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2061 - accuracy: 0.9279 - precision: 0.9617 - recall: 0.8161\n",
      "Epoch 797/1000\n",
      "351/351 [==============================] - 0s 475us/step - loss: 0.2063 - accuracy: 0.9282 - precision: 0.9617 - recall: 0.8169\n",
      "Epoch 798/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2058 - accuracy: 0.9276 - precision: 0.9654 - recall: 0.8118\n",
      "Epoch 799/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 437us/step - loss: 0.2051 - accuracy: 0.9284 - precision: 0.9646 - recall: 0.8152\n",
      "Epoch 800/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2050 - accuracy: 0.9307 - precision: 0.9696 - recall: 0.8178\n",
      "Epoch 801/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2043 - accuracy: 0.9279 - precision: 0.9580 - recall: 0.8195\n",
      "Epoch 802/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2040 - accuracy: 0.9273 - precision: 0.9616 - recall: 0.8144\n",
      "Epoch 803/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2048 - accuracy: 0.9270 - precision: 0.9606 - recall: 0.8144\n",
      "Epoch 804/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2051 - accuracy: 0.9287 - precision: 0.9656 - recall: 0.8152\n",
      "Epoch 805/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2052 - accuracy: 0.9299 - precision: 0.9666 - recall: 0.8178\n",
      "Epoch 806/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2048 - accuracy: 0.9276 - precision: 0.9626 - recall: 0.8144\n",
      "Epoch 807/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2050 - accuracy: 0.9307 - precision: 0.9705 - recall: 0.8169\n",
      "Epoch 808/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2060 - accuracy: 0.9282 - precision: 0.9617 - recall: 0.8169\n",
      "Epoch 809/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2051 - accuracy: 0.9282 - precision: 0.9627 - recall: 0.8161\n",
      "Epoch 810/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2035 - accuracy: 0.9279 - precision: 0.9589 - recall: 0.8186\n",
      "Epoch 811/1000\n",
      "351/351 [==============================] - 0s 453us/step - loss: 0.2045 - accuracy: 0.9307 - precision: 0.9734 - recall: 0.8144\n",
      "Epoch 812/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2043 - accuracy: 0.9287 - precision: 0.9637 - recall: 0.8169\n",
      "Epoch 813/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2047 - accuracy: 0.9287 - precision: 0.9618 - recall: 0.8186\n",
      "Epoch 814/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2040 - accuracy: 0.9279 - precision: 0.9664 - recall: 0.8118\n",
      "Epoch 815/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2051 - accuracy: 0.9273 - precision: 0.9635 - recall: 0.8127\n",
      "Epoch 816/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2051 - accuracy: 0.9279 - precision: 0.9645 - recall: 0.8135\n",
      "Epoch 817/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2046 - accuracy: 0.9267 - precision: 0.9597 - recall: 0.8144\n",
      "Epoch 818/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2060 - accuracy: 0.9282 - precision: 0.9664 - recall: 0.8127\n",
      "Epoch 819/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2045 - accuracy: 0.9299 - precision: 0.9695 - recall: 0.8152\n",
      "Epoch 820/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2036 - accuracy: 0.9307 - precision: 0.9649 - recall: 0.8221\n",
      "Epoch 821/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2043 - accuracy: 0.9287 - precision: 0.9665 - recall: 0.8144\n",
      "Epoch 822/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2049 - accuracy: 0.9296 - precision: 0.9638 - recall: 0.8195\n",
      "Epoch 823/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2039 - accuracy: 0.9296 - precision: 0.9666 - recall: 0.8169\n",
      "Epoch 824/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2056 - accuracy: 0.9265 - precision: 0.9587 - recall: 0.8144\n",
      "Epoch 825/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2035 - accuracy: 0.9267 - precision: 0.9560 - recall: 0.8178\n",
      "Epoch 826/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2056 - accuracy: 0.9256 - precision: 0.9604 - recall: 0.8101\n",
      "Epoch 827/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2047 - accuracy: 0.9290 - precision: 0.9694 - recall: 0.8127\n",
      "Epoch 828/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2048 - accuracy: 0.9299 - precision: 0.9648 - recall: 0.8195\n",
      "Epoch 829/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2049 - accuracy: 0.9302 - precision: 0.9629 - recall: 0.8221\n",
      "Epoch 830/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2048 - accuracy: 0.9276 - precision: 0.9626 - recall: 0.8144\n",
      "Epoch 831/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2053 - accuracy: 0.9282 - precision: 0.9664 - recall: 0.8127\n",
      "Epoch 832/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2045 - accuracy: 0.9282 - precision: 0.9627 - recall: 0.8161\n",
      "Epoch 833/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2052 - accuracy: 0.9304 - precision: 0.9639 - recall: 0.8221\n",
      "Epoch 834/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2038 - accuracy: 0.9293 - precision: 0.9628 - recall: 0.8195\n",
      "Epoch 835/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2047 - accuracy: 0.9270 - precision: 0.9616 - recall: 0.8135\n",
      "Epoch 836/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2038 - accuracy: 0.9282 - precision: 0.9571 - recall: 0.8212\n",
      "Epoch 837/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2051 - accuracy: 0.9273 - precision: 0.9588 - recall: 0.8169\n",
      "Epoch 838/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2051 - accuracy: 0.9302 - precision: 0.9705 - recall: 0.8152\n",
      "Epoch 839/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2048 - accuracy: 0.9287 - precision: 0.9646 - recall: 0.8161\n",
      "Epoch 840/1000\n",
      "351/351 [==============================] - 0s 470us/step - loss: 0.2050 - accuracy: 0.9299 - precision: 0.9629 - recall: 0.8212\n",
      "Epoch 841/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2051 - accuracy: 0.9302 - precision: 0.9676 - recall: 0.8178\n",
      "Epoch 842/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2039 - accuracy: 0.9282 - precision: 0.9627 - recall: 0.8161\n",
      "Epoch 843/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2040 - accuracy: 0.9290 - precision: 0.9628 - recall: 0.8186\n",
      "Epoch 844/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2035 - accuracy: 0.9284 - precision: 0.9618 - recall: 0.8178\n",
      "Epoch 845/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2044 - accuracy: 0.9293 - precision: 0.9713 - recall: 0.8118\n",
      "Epoch 846/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2038 - accuracy: 0.9279 - precision: 0.9654 - recall: 0.8127\n",
      "Epoch 847/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2044 - accuracy: 0.9319 - precision: 0.9613 - recall: 0.8289\n",
      "Epoch 848/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2037 - accuracy: 0.9307 - precision: 0.9696 - recall: 0.8178\n",
      "Epoch 849/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2040 - accuracy: 0.9284 - precision: 0.9646 - recall: 0.8152\n",
      "Epoch 850/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2046 - accuracy: 0.9290 - precision: 0.9609 - recall: 0.8204\n",
      "Epoch 851/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2053 - accuracy: 0.9270 - precision: 0.9597 - recall: 0.8152\n",
      "Epoch 852/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2043 - accuracy: 0.9282 - precision: 0.9645 - recall: 0.8144\n",
      "Epoch 853/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2044 - accuracy: 0.9276 - precision: 0.9617 - recall: 0.8152\n",
      "Epoch 854/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2036 - accuracy: 0.9270 - precision: 0.9635 - recall: 0.8118\n",
      "Epoch 855/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2038 - accuracy: 0.9302 - precision: 0.9686 - recall: 0.8169\n",
      "Epoch 856/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 444us/step - loss: 0.2035 - accuracy: 0.9304 - precision: 0.9667 - recall: 0.8195\n",
      "Epoch 857/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2028 - accuracy: 0.9302 - precision: 0.9629 - recall: 0.8221\n",
      "Epoch 858/1000\n",
      "351/351 [==============================] - 0s 449us/step - loss: 0.2034 - accuracy: 0.9293 - precision: 0.9637 - recall: 0.8186\n",
      "Epoch 859/1000\n",
      "351/351 [==============================] - 0s 470us/step - loss: 0.2037 - accuracy: 0.9290 - precision: 0.9656 - recall: 0.8161\n",
      "Epoch 860/1000\n",
      "351/351 [==============================] - 0s 537us/step - loss: 0.2035 - accuracy: 0.9296 - precision: 0.9714 - recall: 0.8127\n",
      "Epoch 861/1000\n",
      "351/351 [==============================] - 0s 490us/step - loss: 0.2040 - accuracy: 0.9284 - precision: 0.9599 - recall: 0.8195\n",
      "Epoch 862/1000\n",
      "351/351 [==============================] - 0s 488us/step - loss: 0.2034 - accuracy: 0.9307 - precision: 0.9639 - recall: 0.8229\n",
      "Epoch 863/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2037 - accuracy: 0.9287 - precision: 0.9646 - recall: 0.8161\n",
      "Epoch 864/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2028 - accuracy: 0.9319 - precision: 0.9678 - recall: 0.8229\n",
      "Epoch 865/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2036 - accuracy: 0.9282 - precision: 0.9571 - recall: 0.8212\n",
      "Epoch 866/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2035 - accuracy: 0.9299 - precision: 0.9695 - recall: 0.8152\n",
      "Epoch 867/1000\n",
      "351/351 [==============================] - 0s 427us/step - loss: 0.2034 - accuracy: 0.9304 - precision: 0.9676 - recall: 0.8186\n",
      "Epoch 868/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2043 - accuracy: 0.9296 - precision: 0.9638 - recall: 0.8195\n",
      "Epoch 869/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2038 - accuracy: 0.9290 - precision: 0.9703 - recall: 0.8118\n",
      "Epoch 870/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2042 - accuracy: 0.9290 - precision: 0.9646 - recall: 0.8169\n",
      "Epoch 871/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2034 - accuracy: 0.9336 - precision: 0.9737 - recall: 0.8229\n",
      "Epoch 872/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2028 - accuracy: 0.9265 - precision: 0.9578 - recall: 0.8152\n",
      "Epoch 873/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2027 - accuracy: 0.9293 - precision: 0.9656 - recall: 0.8169\n",
      "Epoch 874/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2036 - accuracy: 0.9273 - precision: 0.9616 - recall: 0.8144\n",
      "Epoch 875/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2032 - accuracy: 0.9307 - precision: 0.9696 - recall: 0.8178\n",
      "Epoch 876/1000\n",
      "351/351 [==============================] - 0s 427us/step - loss: 0.2033 - accuracy: 0.9302 - precision: 0.9639 - recall: 0.8212\n",
      "Epoch 877/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2043 - accuracy: 0.9316 - precision: 0.9706 - recall: 0.8195\n",
      "Epoch 878/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2032 - accuracy: 0.9284 - precision: 0.9599 - recall: 0.8195\n",
      "Epoch 879/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2035 - accuracy: 0.9302 - precision: 0.9676 - recall: 0.8178\n",
      "Epoch 880/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2052 - accuracy: 0.9296 - precision: 0.9666 - recall: 0.8169\n",
      "Epoch 881/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2053 - accuracy: 0.9284 - precision: 0.9618 - recall: 0.8178\n",
      "Epoch 882/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2035 - accuracy: 0.9296 - precision: 0.9647 - recall: 0.8186\n",
      "Epoch 883/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2025 - accuracy: 0.9296 - precision: 0.9675 - recall: 0.8161\n",
      "Epoch 884/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2049 - accuracy: 0.9273 - precision: 0.9607 - recall: 0.8152\n",
      "Epoch 885/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2033 - accuracy: 0.9282 - precision: 0.9608 - recall: 0.8178\n",
      "Epoch 886/1000\n",
      "351/351 [==============================] - 0s 448us/step - loss: 0.2023 - accuracy: 0.9307 - precision: 0.9677 - recall: 0.8195\n",
      "Epoch 887/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2030 - accuracy: 0.9307 - precision: 0.9677 - recall: 0.8195\n",
      "Epoch 888/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2024 - accuracy: 0.9290 - precision: 0.9618 - recall: 0.8195\n",
      "Epoch 889/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2029 - accuracy: 0.9310 - precision: 0.9677 - recall: 0.8204\n",
      "Epoch 890/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2033 - accuracy: 0.9284 - precision: 0.9665 - recall: 0.8135\n",
      "Epoch 891/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2039 - accuracy: 0.9276 - precision: 0.9683 - recall: 0.8092\n",
      "Epoch 892/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2039 - accuracy: 0.9313 - precision: 0.9715 - recall: 0.8178\n",
      "Epoch 893/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2033 - accuracy: 0.9299 - precision: 0.9629 - recall: 0.8212\n",
      "Epoch 894/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2032 - accuracy: 0.9293 - precision: 0.9637 - recall: 0.8186\n",
      "Epoch 895/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2027 - accuracy: 0.9299 - precision: 0.9676 - recall: 0.8169\n",
      "Epoch 896/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2026 - accuracy: 0.9319 - precision: 0.9641 - recall: 0.8263\n",
      "Epoch 897/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2038 - accuracy: 0.9290 - precision: 0.9675 - recall: 0.8144\n",
      "Epoch 898/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2040 - accuracy: 0.9273 - precision: 0.9579 - recall: 0.8178\n",
      "Epoch 899/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2022 - accuracy: 0.9327 - precision: 0.9785 - recall: 0.8161\n",
      "Epoch 900/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2037 - accuracy: 0.9290 - precision: 0.9618 - recall: 0.8195\n",
      "Epoch 901/1000\n",
      "351/351 [==============================] - 0s 441us/step - loss: 0.2021 - accuracy: 0.9299 - precision: 0.9648 - recall: 0.8195\n",
      "Epoch 902/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2035 - accuracy: 0.9313 - precision: 0.9696 - recall: 0.8195\n",
      "Epoch 903/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2025 - accuracy: 0.9322 - precision: 0.9707 - recall: 0.8212\n",
      "Epoch 904/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2042 - accuracy: 0.9279 - precision: 0.9664 - recall: 0.8118\n",
      "Epoch 905/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2031 - accuracy: 0.9293 - precision: 0.9666 - recall: 0.8161\n",
      "Epoch 906/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2027 - accuracy: 0.9322 - precision: 0.9707 - recall: 0.8212\n",
      "Epoch 907/1000\n",
      "351/351 [==============================] - 0s 433us/step - loss: 0.2035 - accuracy: 0.9279 - precision: 0.9626 - recall: 0.8152\n",
      "Epoch 908/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2031 - accuracy: 0.9322 - precision: 0.9697 - recall: 0.8221\n",
      "Epoch 909/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2034 - accuracy: 0.9304 - precision: 0.9695 - recall: 0.8169\n",
      "Epoch 910/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2018 - accuracy: 0.9310 - precision: 0.9658 - recall: 0.8221\n",
      "Epoch 911/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2028 - accuracy: 0.9296 - precision: 0.9695 - recall: 0.8144\n",
      "Epoch 912/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2024 - accuracy: 0.9322 - precision: 0.9716 - recall: 0.8204\n",
      "Epoch 913/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 434us/step - loss: 0.2029 - accuracy: 0.9279 - precision: 0.9654 - recall: 0.8127\n",
      "Epoch 914/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2030 - accuracy: 0.9293 - precision: 0.9647 - recall: 0.8178\n",
      "Epoch 915/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2031 - accuracy: 0.9302 - precision: 0.9724 - recall: 0.8135\n",
      "Epoch 916/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2032 - accuracy: 0.9310 - precision: 0.9696 - recall: 0.8186\n",
      "Epoch 917/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2014 - accuracy: 0.9319 - precision: 0.9706 - recall: 0.8204\n",
      "Epoch 918/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2020 - accuracy: 0.9304 - precision: 0.9667 - recall: 0.8195\n",
      "Epoch 919/1000\n",
      "351/351 [==============================] - 0s 450us/step - loss: 0.2029 - accuracy: 0.9302 - precision: 0.9695 - recall: 0.8161\n",
      "Epoch 920/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2017 - accuracy: 0.9299 - precision: 0.9676 - recall: 0.8169\n",
      "Epoch 921/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2041 - accuracy: 0.9287 - precision: 0.9646 - recall: 0.8161\n",
      "Epoch 922/1000\n",
      "351/351 [==============================] - 0s 443us/step - loss: 0.2030 - accuracy: 0.9299 - precision: 0.9676 - recall: 0.8169\n",
      "Epoch 923/1000\n",
      "351/351 [==============================] - 0s 474us/step - loss: 0.2031 - accuracy: 0.9310 - precision: 0.9677 - recall: 0.8204\n",
      "Epoch 924/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2042 - accuracy: 0.9293 - precision: 0.9666 - recall: 0.8161\n",
      "Epoch 925/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2023 - accuracy: 0.9276 - precision: 0.9654 - recall: 0.8118\n",
      "Epoch 926/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2010 - accuracy: 0.9296 - precision: 0.9610 - recall: 0.8221\n",
      "Epoch 927/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2027 - accuracy: 0.9293 - precision: 0.9628 - recall: 0.8195\n",
      "Epoch 928/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2021 - accuracy: 0.9296 - precision: 0.9685 - recall: 0.8152\n",
      "Epoch 929/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2037 - accuracy: 0.9313 - precision: 0.9706 - recall: 0.8186\n",
      "Epoch 930/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2031 - accuracy: 0.9284 - precision: 0.9636 - recall: 0.8161\n",
      "Epoch 931/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2038 - accuracy: 0.9296 - precision: 0.9657 - recall: 0.8178\n",
      "Epoch 932/1000\n",
      "351/351 [==============================] - 0s 447us/step - loss: 0.2017 - accuracy: 0.9316 - precision: 0.9706 - recall: 0.8195\n",
      "Epoch 933/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2033 - accuracy: 0.9310 - precision: 0.9687 - recall: 0.8195\n",
      "Epoch 934/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2024 - accuracy: 0.9322 - precision: 0.9707 - recall: 0.8212\n",
      "Epoch 935/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2027 - accuracy: 0.9322 - precision: 0.9688 - recall: 0.8229\n",
      "Epoch 936/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2030 - accuracy: 0.9302 - precision: 0.9667 - recall: 0.8186\n",
      "Epoch 937/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2027 - accuracy: 0.9290 - precision: 0.9628 - recall: 0.8186\n",
      "Epoch 938/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2013 - accuracy: 0.9284 - precision: 0.9627 - recall: 0.8169\n",
      "Epoch 939/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2031 - accuracy: 0.9310 - precision: 0.9706 - recall: 0.8178\n",
      "Epoch 940/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2025 - accuracy: 0.9304 - precision: 0.9667 - recall: 0.8195\n",
      "Epoch 941/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2026 - accuracy: 0.9313 - precision: 0.9677 - recall: 0.8212\n",
      "Epoch 942/1000\n",
      "351/351 [==============================] - 0s 568us/step - loss: 0.2030 - accuracy: 0.9316 - precision: 0.9725 - recall: 0.8178\n",
      "Epoch 943/1000\n",
      "351/351 [==============================] - 0s 454us/step - loss: 0.2036 - accuracy: 0.9293 - precision: 0.9675 - recall: 0.8152\n",
      "Epoch 944/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2024 - accuracy: 0.9267 - precision: 0.9597 - recall: 0.8144\n",
      "Epoch 945/1000\n",
      "351/351 [==============================] - 0s 490us/step - loss: 0.2029 - accuracy: 0.9296 - precision: 0.9638 - recall: 0.8195\n",
      "Epoch 946/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2021 - accuracy: 0.9313 - precision: 0.9668 - recall: 0.8221\n",
      "Epoch 947/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2023 - accuracy: 0.9293 - precision: 0.9628 - recall: 0.8195\n",
      "Epoch 948/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2008 - accuracy: 0.9316 - precision: 0.9697 - recall: 0.8204\n",
      "Epoch 949/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2029 - accuracy: 0.9299 - precision: 0.9666 - recall: 0.8178\n",
      "Epoch 950/1000\n",
      "351/351 [==============================] - 0s 444us/step - loss: 0.2024 - accuracy: 0.9313 - precision: 0.9764 - recall: 0.8135\n",
      "Epoch 951/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2014 - accuracy: 0.9313 - precision: 0.9725 - recall: 0.8169\n",
      "Epoch 952/1000\n",
      "351/351 [==============================] - 0s 434us/step - loss: 0.2015 - accuracy: 0.9322 - precision: 0.9707 - recall: 0.8212\n",
      "Epoch 953/1000\n",
      "351/351 [==============================] - 0s 435us/step - loss: 0.2018 - accuracy: 0.9310 - precision: 0.9696 - recall: 0.8186\n",
      "Epoch 954/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2025 - accuracy: 0.9293 - precision: 0.9666 - recall: 0.8161\n",
      "Epoch 955/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2016 - accuracy: 0.9276 - precision: 0.9617 - recall: 0.8152\n",
      "Epoch 956/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2018 - accuracy: 0.9316 - precision: 0.9687 - recall: 0.8212\n",
      "Epoch 957/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2013 - accuracy: 0.9284 - precision: 0.9636 - recall: 0.8161\n",
      "Epoch 958/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2030 - accuracy: 0.9299 - precision: 0.9685 - recall: 0.8161\n",
      "Epoch 959/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2023 - accuracy: 0.9290 - precision: 0.9637 - recall: 0.8178\n",
      "Epoch 960/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2026 - accuracy: 0.9302 - precision: 0.9714 - recall: 0.8144\n",
      "Epoch 961/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2017 - accuracy: 0.9327 - precision: 0.9670 - recall: 0.8263\n",
      "Epoch 962/1000\n",
      "351/351 [==============================] - 0s 452us/step - loss: 0.2018 - accuracy: 0.9287 - precision: 0.9646 - recall: 0.8161\n",
      "Epoch 963/1000\n",
      "351/351 [==============================] - 0s 481us/step - loss: 0.2022 - accuracy: 0.9290 - precision: 0.9628 - recall: 0.8186\n",
      "Epoch 964/1000\n",
      "351/351 [==============================] - 0s 495us/step - loss: 0.2025 - accuracy: 0.9284 - precision: 0.9599 - recall: 0.8195\n",
      "Epoch 965/1000\n",
      "351/351 [==============================] - 0s 464us/step - loss: 0.2030 - accuracy: 0.9284 - precision: 0.9590 - recall: 0.8204\n",
      "Epoch 966/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2019 - accuracy: 0.9299 - precision: 0.9610 - recall: 0.8229\n",
      "Epoch 967/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2031 - accuracy: 0.9296 - precision: 0.9666 - recall: 0.8169\n",
      "Epoch 968/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2026 - accuracy: 0.9287 - precision: 0.9637 - recall: 0.8169\n",
      "Epoch 969/1000\n",
      "351/351 [==============================] - 0s 438us/step - loss: 0.2022 - accuracy: 0.9296 - precision: 0.9695 - recall: 0.8144\n",
      "Epoch 970/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 0s 440us/step - loss: 0.2023 - accuracy: 0.9299 - precision: 0.9638 - recall: 0.8204\n",
      "Epoch 971/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2018 - accuracy: 0.9304 - precision: 0.9695 - recall: 0.8169\n",
      "Epoch 972/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2017 - accuracy: 0.9299 - precision: 0.9676 - recall: 0.8169\n",
      "Epoch 973/1000\n",
      "351/351 [==============================] - 0s 436us/step - loss: 0.2024 - accuracy: 0.9299 - precision: 0.9685 - recall: 0.8161\n",
      "Epoch 974/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2021 - accuracy: 0.9304 - precision: 0.9658 - recall: 0.8204\n",
      "Epoch 975/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2012 - accuracy: 0.9322 - precision: 0.9697 - recall: 0.8221\n",
      "Epoch 976/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2013 - accuracy: 0.9284 - precision: 0.9646 - recall: 0.8152\n",
      "Epoch 977/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2025 - accuracy: 0.9322 - precision: 0.9774 - recall: 0.8152\n",
      "Epoch 978/1000\n",
      "351/351 [==============================] - 0s 437us/step - loss: 0.2025 - accuracy: 0.9290 - precision: 0.9609 - recall: 0.8204\n",
      "Epoch 979/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2024 - accuracy: 0.9267 - precision: 0.9597 - recall: 0.8144\n",
      "Epoch 980/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2026 - accuracy: 0.9304 - precision: 0.9676 - recall: 0.8186\n",
      "Epoch 981/1000\n",
      "351/351 [==============================] - 0s 427us/step - loss: 0.2016 - accuracy: 0.9296 - precision: 0.9629 - recall: 0.8204\n",
      "Epoch 982/1000\n",
      "351/351 [==============================] - 0s 432us/step - loss: 0.2016 - accuracy: 0.9313 - precision: 0.9696 - recall: 0.8195\n",
      "Epoch 983/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2022 - accuracy: 0.9319 - precision: 0.9726 - recall: 0.8186\n",
      "Epoch 984/1000\n",
      "351/351 [==============================] - 0s 445us/step - loss: 0.2018 - accuracy: 0.9299 - precision: 0.9685 - recall: 0.8161\n",
      "Epoch 985/1000\n",
      "351/351 [==============================] - 0s 439us/step - loss: 0.2014 - accuracy: 0.9307 - precision: 0.9658 - recall: 0.8212\n",
      "Epoch 986/1000\n",
      "351/351 [==============================] - 0s 440us/step - loss: 0.2015 - accuracy: 0.9322 - precision: 0.9660 - recall: 0.8255\n",
      "Epoch 987/1000\n",
      "351/351 [==============================] - 0s 446us/step - loss: 0.2012 - accuracy: 0.9293 - precision: 0.9647 - recall: 0.8178\n",
      "Epoch 988/1000\n",
      "351/351 [==============================] - 0s 451us/step - loss: 0.2028 - accuracy: 0.9299 - precision: 0.9648 - recall: 0.8195\n",
      "Epoch 989/1000\n",
      "351/351 [==============================] - 0s 442us/step - loss: 0.2018 - accuracy: 0.9287 - precision: 0.9656 - recall: 0.8152\n",
      "Epoch 990/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2012 - accuracy: 0.9319 - precision: 0.9688 - recall: 0.8221\n",
      "Epoch 991/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2026 - accuracy: 0.9293 - precision: 0.9637 - recall: 0.8186\n",
      "Epoch 992/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2010 - accuracy: 0.9327 - precision: 0.9755 - recall: 0.8186\n",
      "Epoch 993/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2022 - accuracy: 0.9279 - precision: 0.9562 - recall: 0.8212\n",
      "Epoch 994/1000\n",
      "351/351 [==============================] - 0s 431us/step - loss: 0.2019 - accuracy: 0.9313 - precision: 0.9725 - recall: 0.8169\n",
      "Epoch 995/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2012 - accuracy: 0.9316 - precision: 0.9716 - recall: 0.8186\n",
      "Epoch 996/1000\n",
      "351/351 [==============================] - 0s 425us/step - loss: 0.2007 - accuracy: 0.9290 - precision: 0.9656 - recall: 0.8161\n",
      "Epoch 997/1000\n",
      "351/351 [==============================] - 0s 428us/step - loss: 0.2028 - accuracy: 0.9302 - precision: 0.9629 - recall: 0.8221\n",
      "Epoch 998/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2004 - accuracy: 0.9282 - precision: 0.9655 - recall: 0.8135\n",
      "Epoch 999/1000\n",
      "351/351 [==============================] - 0s 429us/step - loss: 0.2004 - accuracy: 0.9290 - precision: 0.9675 - recall: 0.8144\n",
      "Epoch 1000/1000\n",
      "351/351 [==============================] - 0s 430us/step - loss: 0.2025 - accuracy: 0.9302 - precision: 0.9639 - recall: 0.8212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e8044f10>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with data \n",
    "model.fit(X_resampled, y_resampled, epochs=1000, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aba0a9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 416us/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "y_pred = [\n",
    "    1 if prob > 0.5 else 0 for prob in np.ravel(predictions)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fbcfe50f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Neural Network\n",
      "Accuracy: 0.9504672897196261\n",
      "Recall: 0.021739130434782608\n",
      "Precision: 0.1111111111111111\n",
      "F1 Score: 0.03636363636363637\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[   1   45]\n",
      " [   8 1016]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1024\n",
      "           1       0.11      0.02      0.04        46\n",
      "\n",
      "    accuracy                           0.95      1070\n",
      "   macro avg       0.53      0.51      0.51      1070\n",
      "weighted avg       0.92      0.95      0.93      1070\n",
      "\n",
      "[0.9504672897196261, 0.021739130434782608, 0.1111111111111111, 0.03636363636363637]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "get_model_results_nn(\"Neural Network\", predictions, y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e91965",
   "metadata": {},
   "source": [
    "### Dataset without Residence Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0145cc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model2():\n",
    "    # create model\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Dense(11, activation='relu', input_dim=15))\n",
    "    model.add(layers.Dense(7, activation='relu', input_dim=15))\n",
    "    model.add(layers.Dense(5, activation='relu', input_dim=15))\n",
    "    model.add(layers.Dense(1, activation='sigmoid', name='predictions'))\n",
    "    # return model without compile\n",
    "    return model\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(109)\n",
    "\n",
    "# hyperparameter tuning\n",
    "# create model\n",
    "model2 = KerasClassifier(model=create_model2, loss=\"binary_crossentropy\", verbose=False, optimizer = keras.optimizers.Adam(lr=1e-5))\n",
    "\n",
    "grid2 = GridSearchCV(estimator=model2, param_grid=param_grid, scoring='f1')\n",
    "grid_result2 = grid2.fit(X_resampled2, y_resampled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "afeb65ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyper parameters: {'batch_size': 20, 'epochs': 1000} Score 0.6422465606224405\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print('Best hyper parameters:', grid2.best_params_, 'Score', grid2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "061673d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.Sequential()\n",
    "model2.add(layers.Dense(11, activation='relu'))\n",
    "model2.add(layers.Dense(7, activation='relu'))\n",
    "model2.add(layers.Dense(5, activation='relu'))\n",
    "model2.add(layers.Dense(1, activation='sigmoid', name='predictions'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8ea31bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy', \n",
    "               optimizer=keras.optimizers.Adam(lr=1e-5), \n",
    "               metrics=['accuracy',\n",
    "                        keras.metrics.Precision(name='precision'),\n",
    "                        keras.metrics.Recall(name='recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce874b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "176/176 [==============================] - 1s 876us/step - loss: 1.4929 - accuracy: 0.3332 - precision: 0.3332 - recall: 1.0000\n",
      "Epoch 2/1000\n",
      "176/176 [==============================] - 0s 775us/step - loss: 1.2888 - accuracy: 0.3332 - precision: 0.3332 - recall: 1.0000\n",
      "Epoch 3/1000\n",
      "176/176 [==============================] - 0s 658us/step - loss: 1.1848 - accuracy: 0.3332 - precision: 0.3332 - recall: 1.0000\n",
      "Epoch 4/1000\n",
      "176/176 [==============================] - 0s 622us/step - loss: 1.0917 - accuracy: 0.3332 - precision: 0.3332 - recall: 1.0000\n",
      "Epoch 5/1000\n",
      "176/176 [==============================] - 0s 674us/step - loss: 1.0109 - accuracy: 0.3332 - precision: 0.3332 - recall: 1.0000\n",
      "Epoch 6/1000\n",
      "176/176 [==============================] - 0s 636us/step - loss: 0.9420 - accuracy: 0.3332 - precision: 0.3332 - recall: 1.0000\n",
      "Epoch 7/1000\n",
      "176/176 [==============================] - 0s 582us/step - loss: 0.8841 - accuracy: 0.3332 - precision: 0.3332 - recall: 1.0000\n",
      "Epoch 8/1000\n",
      "176/176 [==============================] - 0s 581us/step - loss: 0.8363 - accuracy: 0.3332 - precision: 0.3332 - recall: 1.0000\n",
      "Epoch 9/1000\n",
      "176/176 [==============================] - 0s 572us/step - loss: 0.7976 - accuracy: 0.3332 - precision: 0.3332 - recall: 1.0000\n",
      "Epoch 10/1000\n",
      "176/176 [==============================] - 0s 591us/step - loss: 0.7667 - accuracy: 0.3332 - precision: 0.3332 - recall: 1.0000\n",
      "Epoch 11/1000\n",
      "176/176 [==============================] - 0s 511us/step - loss: 0.7426 - accuracy: 0.3332 - precision: 0.3332 - recall: 1.0000\n",
      "Epoch 12/1000\n",
      "176/176 [==============================] - 0s 520us/step - loss: 0.7241 - accuracy: 0.3332 - precision: 0.3332 - recall: 1.0000\n",
      "Epoch 13/1000\n",
      "176/176 [==============================] - 0s 518us/step - loss: 0.7102 - accuracy: 0.3335 - precision: 0.3333 - recall: 1.0000\n",
      "Epoch 14/1000\n",
      "176/176 [==============================] - 0s 513us/step - loss: 0.7002 - accuracy: 0.3469 - precision: 0.3379 - recall: 1.0000\n",
      "Epoch 15/1000\n",
      "176/176 [==============================] - 0s 521us/step - loss: 0.6930 - accuracy: 0.5068 - precision: 0.3887 - recall: 0.8383\n",
      "Epoch 16/1000\n",
      "176/176 [==============================] - 0s 517us/step - loss: 0.6879 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "176/176 [==============================] - 0s 511us/step - loss: 0.6845 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "176/176 [==============================] - 0s 506us/step - loss: 0.6822 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "176/176 [==============================] - 0s 479us/step - loss: 0.6808 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "176/176 [==============================] - 0s 485us/step - loss: 0.6799 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6793 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "176/176 [==============================] - 0s 479us/step - loss: 0.6789 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "176/176 [==============================] - 0s 503us/step - loss: 0.6788 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "176/176 [==============================] - 0s 476us/step - loss: 0.6786 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "176/176 [==============================] - 0s 632us/step - loss: 0.6784 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "176/176 [==============================] - 0s 516us/step - loss: 0.6783 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "176/176 [==============================] - 0s 470us/step - loss: 0.6782 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6781 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "176/176 [==============================] - 0s 470us/step - loss: 0.6781 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "176/176 [==============================] - 0s 491us/step - loss: 0.6780 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "176/176 [==============================] - 0s 475us/step - loss: 0.6779 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6778 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "176/176 [==============================] - 0s 495us/step - loss: 0.6777 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "176/176 [==============================] - 0s 530us/step - loss: 0.6776 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "176/176 [==============================] - 0s 484us/step - loss: 0.6774 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "176/176 [==============================] - 0s 464us/step - loss: 0.6774 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "176/176 [==============================] - 0s 468us/step - loss: 0.6773 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6772 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6771 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6770 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6768 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "176/176 [==============================] - 0s 463us/step - loss: 0.6767 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "176/176 [==============================] - 0s 484us/step - loss: 0.6766 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "176/176 [==============================] - 0s 502us/step - loss: 0.6766 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "176/176 [==============================] - 0s 473us/step - loss: 0.6764 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "176/176 [==============================] - 0s 474us/step - loss: 0.6763 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "176/176 [==============================] - 0s 470us/step - loss: 0.6762 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6761 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6760 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "176/176 [==============================] - 0s 479us/step - loss: 0.6759 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "176/176 [==============================] - 0s 494us/step - loss: 0.6758 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "176/176 [==============================] - 0s 446us/step - loss: 0.6756 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "176/176 [==============================] - 0s 469us/step - loss: 0.6756 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "176/176 [==============================] - 0s 426us/step - loss: 0.6755 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "176/176 [==============================] - 0s 481us/step - loss: 0.6753 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 56/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 438us/step - loss: 0.6753 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "176/176 [==============================] - 0s 439us/step - loss: 0.6752 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6751 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "176/176 [==============================] - 0s 439us/step - loss: 0.6749 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 60/1000\n",
      "176/176 [==============================] - 0s 496us/step - loss: 0.6748 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 61/1000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 0.6747 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 62/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6746 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 63/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6745 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 64/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6744 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 65/1000\n",
      "176/176 [==============================] - 0s 456us/step - loss: 0.6743 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 66/1000\n",
      "176/176 [==============================] - 0s 428us/step - loss: 0.6742 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 67/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6741 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 68/1000\n",
      "176/176 [==============================] - 0s 442us/step - loss: 0.6740 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 69/1000\n",
      "176/176 [==============================] - 0s 431us/step - loss: 0.6739 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 70/1000\n",
      "176/176 [==============================] - 0s 439us/step - loss: 0.6738 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 71/1000\n",
      "176/176 [==============================] - 0s 425us/step - loss: 0.6737 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 72/1000\n",
      "176/176 [==============================] - 0s 472us/step - loss: 0.6735 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 73/1000\n",
      "176/176 [==============================] - 0s 493us/step - loss: 0.6735 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 74/1000\n",
      "176/176 [==============================] - 0s 495us/step - loss: 0.6734 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 75/1000\n",
      "176/176 [==============================] - 0s 477us/step - loss: 0.6733 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 76/1000\n",
      "176/176 [==============================] - 0s 476us/step - loss: 0.6731 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 77/1000\n",
      "176/176 [==============================] - 0s 480us/step - loss: 0.6730 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 78/1000\n",
      "176/176 [==============================] - 0s 490us/step - loss: 0.6729 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 79/1000\n",
      "176/176 [==============================] - 0s 474us/step - loss: 0.6728 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 80/1000\n",
      "176/176 [==============================] - 0s 534us/step - loss: 0.6727 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 81/1000\n",
      "176/176 [==============================] - 0s 517us/step - loss: 0.6726 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 82/1000\n",
      "176/176 [==============================] - 0s 456us/step - loss: 0.6725 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 83/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6724 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 84/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6724 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 85/1000\n",
      "176/176 [==============================] - 0s 433us/step - loss: 0.6722 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 86/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6721 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 87/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6720 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 88/1000\n",
      "176/176 [==============================] - 0s 531us/step - loss: 0.6719 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 89/1000\n",
      "176/176 [==============================] - 0s 629us/step - loss: 0.6718 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 90/1000\n",
      "176/176 [==============================] - 0s 565us/step - loss: 0.6717 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 91/1000\n",
      "176/176 [==============================] - 0s 756us/step - loss: 0.6716 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 92/1000\n",
      "176/176 [==============================] - 0s 738us/step - loss: 0.6715 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 93/1000\n",
      "176/176 [==============================] - 0s 677us/step - loss: 0.6714 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 94/1000\n",
      "176/176 [==============================] - 0s 469us/step - loss: 0.6713 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 95/1000\n",
      "176/176 [==============================] - 0s 798us/step - loss: 0.6712 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 96/1000\n",
      "176/176 [==============================] - 0s 650us/step - loss: 0.6710 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 97/1000\n",
      "176/176 [==============================] - 0s 820us/step - loss: 0.6710 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 98/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 99/1000\n",
      "176/176 [==============================] - 0s 767us/step - loss: 0.6708 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 100/1000\n",
      "176/176 [==============================] - 0s 782us/step - loss: 0.6707 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 101/1000\n",
      "176/176 [==============================] - 0s 494us/step - loss: 0.6705 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 102/1000\n",
      "176/176 [==============================] - 0s 858us/step - loss: 0.6705 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 103/1000\n",
      "176/176 [==============================] - 0s 702us/step - loss: 0.6703 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 104/1000\n",
      "176/176 [==============================] - 0s 901us/step - loss: 0.6703 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 105/1000\n",
      "176/176 [==============================] - 0s 568us/step - loss: 0.6701 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 106/1000\n",
      "176/176 [==============================] - 0s 504us/step - loss: 0.6700 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 107/1000\n",
      "176/176 [==============================] - 0s 501us/step - loss: 0.6699 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 108/1000\n",
      "176/176 [==============================] - 0s 477us/step - loss: 0.6698 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 109/1000\n",
      "176/176 [==============================] - 0s 471us/step - loss: 0.6697 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 454us/step - loss: 0.6696 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 111/1000\n",
      "176/176 [==============================] - 0s 449us/step - loss: 0.6695 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 112/1000\n",
      "176/176 [==============================] - 0s 590us/step - loss: 0.6694 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 113/1000\n",
      "176/176 [==============================] - 0s 526us/step - loss: 0.6693 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 114/1000\n",
      "176/176 [==============================] - 0s 498us/step - loss: 0.6692 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 115/1000\n",
      "176/176 [==============================] - 0s 477us/step - loss: 0.6691 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 116/1000\n",
      "176/176 [==============================] - 0s 551us/step - loss: 0.6690 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 117/1000\n",
      "176/176 [==============================] - 0s 536us/step - loss: 0.6689 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 118/1000\n",
      "176/176 [==============================] - 0s 464us/step - loss: 0.6688 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 119/1000\n",
      "176/176 [==============================] - 0s 463us/step - loss: 0.6687 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 120/1000\n",
      "176/176 [==============================] - 0s 469us/step - loss: 0.6686 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 121/1000\n",
      "176/176 [==============================] - 0s 499us/step - loss: 0.6685 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 122/1000\n",
      "176/176 [==============================] - 0s 475us/step - loss: 0.6684 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 123/1000\n",
      "176/176 [==============================] - 0s 589us/step - loss: 0.6683 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 124/1000\n",
      "176/176 [==============================] - 0s 497us/step - loss: 0.6682 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 125/1000\n",
      "176/176 [==============================] - 0s 485us/step - loss: 0.6681 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 126/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6680 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 127/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6679 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 128/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6678 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 129/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6677 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 130/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6676 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 131/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6675 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 132/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6674 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 133/1000\n",
      "176/176 [==============================] - 0s 480us/step - loss: 0.6673 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 134/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6672 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 135/1000\n",
      "176/176 [==============================] - 0s 449us/step - loss: 0.6671 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 136/1000\n",
      "176/176 [==============================] - 0s 643us/step - loss: 0.6670 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 137/1000\n",
      "176/176 [==============================] - 0s 449us/step - loss: 0.6668 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 138/1000\n",
      "176/176 [==============================] - 0s 463us/step - loss: 0.6668 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 139/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6667 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 140/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6666 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 141/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6664 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 142/1000\n",
      "176/176 [==============================] - 0s 444us/step - loss: 0.6664 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 143/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6663 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 144/1000\n",
      "176/176 [==============================] - 0s 449us/step - loss: 0.6662 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 145/1000\n",
      "176/176 [==============================] - 0s 426us/step - loss: 0.6661 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 146/1000\n",
      "176/176 [==============================] - 0s 444us/step - loss: 0.6660 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 147/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6659 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 148/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6658 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 149/1000\n",
      "176/176 [==============================] - 0s 422us/step - loss: 0.6657 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 150/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6656 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 151/1000\n",
      "176/176 [==============================] - 0s 435us/step - loss: 0.6654 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 152/1000\n",
      "176/176 [==============================] - 0s 431us/step - loss: 0.6654 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 153/1000\n",
      "176/176 [==============================] - 0s 431us/step - loss: 0.6653 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 154/1000\n",
      "176/176 [==============================] - 0s 421us/step - loss: 0.6652 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 155/1000\n",
      "176/176 [==============================] - 0s 430us/step - loss: 0.6651 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 156/1000\n",
      "176/176 [==============================] - 0s 436us/step - loss: 0.6650 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 157/1000\n",
      "176/176 [==============================] - 0s 475us/step - loss: 0.6649 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 158/1000\n",
      "176/176 [==============================] - 0s 433us/step - loss: 0.6648 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 159/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6647 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 160/1000\n",
      "176/176 [==============================] - 0s 423us/step - loss: 0.6646 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 161/1000\n",
      "176/176 [==============================] - 0s 427us/step - loss: 0.6645 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 162/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6644 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 163/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6643 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 164/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 414us/step - loss: 0.6642 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 165/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6641 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 166/1000\n",
      "176/176 [==============================] - 0s 459us/step - loss: 0.6640 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 167/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6639 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 168/1000\n",
      "176/176 [==============================] - 0s 420us/step - loss: 0.6638 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 169/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6637 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 170/1000\n",
      "176/176 [==============================] - 0s 419us/step - loss: 0.6636 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 171/1000\n",
      "176/176 [==============================] - 0s 427us/step - loss: 0.6635 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 172/1000\n",
      "176/176 [==============================] - 0s 442us/step - loss: 0.6634 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 173/1000\n",
      "176/176 [==============================] - 0s 439us/step - loss: 0.6633 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 174/1000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 0.6632 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 175/1000\n",
      "176/176 [==============================] - 0s 426us/step - loss: 0.6631 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 176/1000\n",
      "176/176 [==============================] - 0s 434us/step - loss: 0.6631 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 177/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6629 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 178/1000\n",
      "176/176 [==============================] - 0s 444us/step - loss: 0.6628 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 179/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6627 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 180/1000\n",
      "176/176 [==============================] - 0s 417us/step - loss: 0.6626 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 181/1000\n",
      "176/176 [==============================] - 0s 467us/step - loss: 0.6626 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 182/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6625 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 183/1000\n",
      "176/176 [==============================] - 0s 475us/step - loss: 0.6623 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 184/1000\n",
      "176/176 [==============================] - 0s 635us/step - loss: 0.6623 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 185/1000\n",
      "176/176 [==============================] - 0s 477us/step - loss: 0.6621 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 186/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6621 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 187/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6619 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 188/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6619 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 189/1000\n",
      "176/176 [==============================] - 0s 453us/step - loss: 0.6618 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 190/1000\n",
      "176/176 [==============================] - 0s 444us/step - loss: 0.6617 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 191/1000\n",
      "176/176 [==============================] - 0s 435us/step - loss: 0.6616 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 192/1000\n",
      "176/176 [==============================] - 0s 654us/step - loss: 0.6615 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 193/1000\n",
      "176/176 [==============================] - 0s 558us/step - loss: 0.6614 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 194/1000\n",
      "176/176 [==============================] - 0s 549us/step - loss: 0.6613 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 195/1000\n",
      "176/176 [==============================] - 0s 475us/step - loss: 0.6612 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 196/1000\n",
      "176/176 [==============================] - 0s 641us/step - loss: 0.6611 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 197/1000\n",
      "176/176 [==============================] - 0s 674us/step - loss: 0.6610 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 198/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6609 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 199/1000\n",
      "176/176 [==============================] - 0s 573us/step - loss: 0.6608 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 200/1000\n",
      "176/176 [==============================] - 0s 444us/step - loss: 0.6607 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 201/1000\n",
      "176/176 [==============================] - 0s 442us/step - loss: 0.6606 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 202/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6605 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 203/1000\n",
      "176/176 [==============================] - 0s 454us/step - loss: 0.6604 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 204/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6603 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 205/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6603 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 206/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6601 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 207/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6601 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 208/1000\n",
      "176/176 [==============================] - 0s 489us/step - loss: 0.6600 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 209/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6599 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 210/1000\n",
      "176/176 [==============================] - 0s 428us/step - loss: 0.6598 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 211/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6597 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 212/1000\n",
      "176/176 [==============================] - 0s 449us/step - loss: 0.6596 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 213/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6594 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 214/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6594 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 215/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6593 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 216/1000\n",
      "176/176 [==============================] - 0s 428us/step - loss: 0.6592 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 217/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6591 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 218/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 457us/step - loss: 0.6590 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 219/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6589 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 220/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6588 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 221/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6587 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 222/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6586 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 223/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6585 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 224/1000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 0.6584 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 225/1000\n",
      "176/176 [==============================] - 0s 449us/step - loss: 0.6583 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 226/1000\n",
      "176/176 [==============================] - 0s 459us/step - loss: 0.6583 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 227/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6582 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 228/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6581 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 229/1000\n",
      "176/176 [==============================] - 0s 586us/step - loss: 0.6580 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 230/1000\n",
      "176/176 [==============================] - 0s 960us/step - loss: 0.6579 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 231/1000\n",
      "176/176 [==============================] - 0s 925us/step - loss: 0.6578 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 232/1000\n",
      "176/176 [==============================] - 0s 743us/step - loss: 0.6577 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 233/1000\n",
      "176/176 [==============================] - 0s 610us/step - loss: 0.6576 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 234/1000\n",
      "176/176 [==============================] - 0s 576us/step - loss: 0.6575 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 235/1000\n",
      "176/176 [==============================] - 0s 499us/step - loss: 0.6574 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 236/1000\n",
      "176/176 [==============================] - 0s 510us/step - loss: 0.6573 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 237/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6572 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 238/1000\n",
      "176/176 [==============================] - 0s 473us/step - loss: 0.6572 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 239/1000\n",
      "176/176 [==============================] - 0s 473us/step - loss: 0.6570 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 240/1000\n",
      "176/176 [==============================] - 0s 543us/step - loss: 0.6569 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 241/1000\n",
      "176/176 [==============================] - 0s 465us/step - loss: 0.6569 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 242/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6568 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 243/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6567 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 244/1000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 0.6566 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 245/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6565 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 246/1000\n",
      "176/176 [==============================] - 0s 436us/step - loss: 0.6564 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 247/1000\n",
      "176/176 [==============================] - 0s 433us/step - loss: 0.6563 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 248/1000\n",
      "176/176 [==============================] - 0s 423us/step - loss: 0.6562 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 249/1000\n",
      "176/176 [==============================] - 0s 431us/step - loss: 0.6561 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 250/1000\n",
      "176/176 [==============================] - 0s 427us/step - loss: 0.6560 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 251/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6560 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 252/1000\n",
      "176/176 [==============================] - 0s 444us/step - loss: 0.6559 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 253/1000\n",
      "176/176 [==============================] - 0s 722us/step - loss: 0.6558 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 254/1000\n",
      "176/176 [==============================] - 0s 439us/step - loss: 0.6557 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 255/1000\n",
      "176/176 [==============================] - 0s 449us/step - loss: 0.6556 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 256/1000\n",
      "176/176 [==============================] - 0s 470us/step - loss: 0.6555 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 257/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6554 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 258/1000\n",
      "176/176 [==============================] - 0s 473us/step - loss: 0.6553 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 259/1000\n",
      "176/176 [==============================] - 0s 464us/step - loss: 0.6552 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 260/1000\n",
      "176/176 [==============================] - 0s 499us/step - loss: 0.6551 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 261/1000\n",
      "176/176 [==============================] - 0s 431us/step - loss: 0.6551 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 262/1000\n",
      "176/176 [==============================] - 0s 424us/step - loss: 0.6550 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 263/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6549 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 264/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6548 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 265/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6547 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 266/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6547 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 267/1000\n",
      "176/176 [==============================] - 0s 430us/step - loss: 0.6545 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 268/1000\n",
      "176/176 [==============================] - 0s 433us/step - loss: 0.6544 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 269/1000\n",
      "176/176 [==============================] - 0s 435us/step - loss: 0.6543 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 270/1000\n",
      "176/176 [==============================] - 0s 420us/step - loss: 0.6543 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 271/1000\n",
      "176/176 [==============================] - 0s 425us/step - loss: 0.6542 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 272/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 448us/step - loss: 0.6541 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 273/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6540 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 274/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6539 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 275/1000\n",
      "176/176 [==============================] - 0s 439us/step - loss: 0.6538 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 276/1000\n",
      "176/176 [==============================] - 0s 434us/step - loss: 0.6537 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 277/1000\n",
      "176/176 [==============================] - 0s 465us/step - loss: 0.6536 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 278/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6535 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 279/1000\n",
      "176/176 [==============================] - 0s 459us/step - loss: 0.6535 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 280/1000\n",
      "176/176 [==============================] - 0s 464us/step - loss: 0.6534 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 281/1000\n",
      "176/176 [==============================] - 0s 468us/step - loss: 0.6533 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 282/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6532 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 283/1000\n",
      "176/176 [==============================] - 0s 413us/step - loss: 0.6531 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 284/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6530 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 285/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6529 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 286/1000\n",
      "176/176 [==============================] - 0s 439us/step - loss: 0.6528 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 287/1000\n",
      "176/176 [==============================] - 0s 434us/step - loss: 0.6527 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 288/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6526 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 289/1000\n",
      "176/176 [==============================] - 0s 428us/step - loss: 0.6526 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 290/1000\n",
      "176/176 [==============================] - 0s 430us/step - loss: 0.6525 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 291/1000\n",
      "176/176 [==============================] - 0s 423us/step - loss: 0.6524 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 292/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6523 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 293/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6522 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 294/1000\n",
      "176/176 [==============================] - 0s 454us/step - loss: 0.6521 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 295/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6521 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 296/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6520 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 297/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6519 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 298/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6518 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 299/1000\n",
      "176/176 [==============================] - 0s 456us/step - loss: 0.6517 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 300/1000\n",
      "176/176 [==============================] - 0s 471us/step - loss: 0.6516 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 301/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6515 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 302/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6514 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 303/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6514 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 304/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6513 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 305/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6512 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 306/1000\n",
      "176/176 [==============================] - 0s 454us/step - loss: 0.6511 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 307/1000\n",
      "176/176 [==============================] - 0s 472us/step - loss: 0.6510 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 308/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6509 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 309/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6509 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 310/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6507 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 311/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6507 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 312/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6506 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 313/1000\n",
      "176/176 [==============================] - 0s 459us/step - loss: 0.6505 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 314/1000\n",
      "176/176 [==============================] - 0s 431us/step - loss: 0.6504 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 315/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6503 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 316/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6502 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 317/1000\n",
      "176/176 [==============================] - 0s 468us/step - loss: 0.6501 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 318/1000\n",
      "176/176 [==============================] - 0s 476us/step - loss: 0.6501 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 319/1000\n",
      "176/176 [==============================] - 0s 493us/step - loss: 0.6500 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 320/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6499 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 321/1000\n",
      "176/176 [==============================] - 0s 480us/step - loss: 0.6498 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 322/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6497 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 323/1000\n",
      "176/176 [==============================] - 0s 444us/step - loss: 0.6496 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 324/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6495 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 325/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6495 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 326/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 441us/step - loss: 0.6494 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 327/1000\n",
      "176/176 [==============================] - 0s 437us/step - loss: 0.6493 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 328/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6492 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 329/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6491 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 330/1000\n",
      "176/176 [==============================] - 0s 470us/step - loss: 0.6490 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 331/1000\n",
      "176/176 [==============================] - 0s 471us/step - loss: 0.6489 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 332/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6489 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 333/1000\n",
      "176/176 [==============================] - 0s 459us/step - loss: 0.6488 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 334/1000\n",
      "176/176 [==============================] - 0s 454us/step - loss: 0.6487 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 335/1000\n",
      "176/176 [==============================] - 0s 464us/step - loss: 0.6486 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 336/1000\n",
      "176/176 [==============================] - 0s 476us/step - loss: 0.6485 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 337/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6484 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 338/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6484 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 339/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6483 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 340/1000\n",
      "176/176 [==============================] - 0s 474us/step - loss: 0.6482 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 341/1000\n",
      "176/176 [==============================] - 0s 464us/step - loss: 0.6481 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 342/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6480 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 343/1000\n",
      "176/176 [==============================] - 0s 442us/step - loss: 0.6480 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 344/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6478 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 345/1000\n",
      "176/176 [==============================] - 0s 468us/step - loss: 0.6478 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 346/1000\n",
      "176/176 [==============================] - 0s 484us/step - loss: 0.6477 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 347/1000\n",
      "176/176 [==============================] - 0s 479us/step - loss: 0.6476 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 348/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6475 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 349/1000\n",
      "176/176 [==============================] - 0s 449us/step - loss: 0.6475 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 350/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6473 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 351/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6473 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 352/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6472 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 353/1000\n",
      "176/176 [==============================] - 0s 436us/step - loss: 0.6471 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 354/1000\n",
      "176/176 [==============================] - 0s 469us/step - loss: 0.6470 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 355/1000\n",
      "176/176 [==============================] - 0s 482us/step - loss: 0.6469 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 356/1000\n",
      "176/176 [==============================] - 0s 456us/step - loss: 0.6468 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 357/1000\n",
      "176/176 [==============================] - 0s 475us/step - loss: 0.6467 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 358/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6467 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 359/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6466 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 360/1000\n",
      "176/176 [==============================] - 0s 472us/step - loss: 0.6465 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 361/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6464 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 362/1000\n",
      "176/176 [==============================] - 0s 467us/step - loss: 0.6463 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 363/1000\n",
      "176/176 [==============================] - 0s 463us/step - loss: 0.6463 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 364/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6462 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 365/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6461 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 366/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6460 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 367/1000\n",
      "176/176 [==============================] - 0s 469us/step - loss: 0.6459 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 368/1000\n",
      "176/176 [==============================] - 0s 468us/step - loss: 0.6458 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 369/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6457 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 370/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6457 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 371/1000\n",
      "176/176 [==============================] - 0s 463us/step - loss: 0.6456 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 372/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6455 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 373/1000\n",
      "176/176 [==============================] - 0s 446us/step - loss: 0.6454 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 374/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6453 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 375/1000\n",
      "176/176 [==============================] - 0s 475us/step - loss: 0.6452 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 376/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6451 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 377/1000\n",
      "176/176 [==============================] - 0s 475us/step - loss: 0.6451 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 378/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6450 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 379/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6449 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 380/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 464us/step - loss: 0.6448 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 381/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6447 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 382/1000\n",
      "176/176 [==============================] - 0s 477us/step - loss: 0.6446 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 383/1000\n",
      "176/176 [==============================] - 0s 501us/step - loss: 0.6446 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 384/1000\n",
      "176/176 [==============================] - 0s 700us/step - loss: 0.6445 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 385/1000\n",
      "176/176 [==============================] - 0s 667us/step - loss: 0.6444 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 386/1000\n",
      "176/176 [==============================] - 0s 843us/step - loss: 0.6443 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 387/1000\n",
      "176/176 [==============================] - 0s 823us/step - loss: 0.6443 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 388/1000\n",
      "176/176 [==============================] - 0s 821us/step - loss: 0.6441 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 389/1000\n",
      "176/176 [==============================] - 0s 788us/step - loss: 0.6440 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 390/1000\n",
      "176/176 [==============================] - 0s 809us/step - loss: 0.6440 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 391/1000\n",
      "176/176 [==============================] - 0s 439us/step - loss: 0.6439 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 392/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6438 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 393/1000\n",
      "176/176 [==============================] - 0s 437us/step - loss: 0.6437 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 394/1000\n",
      "176/176 [==============================] - 0s 431us/step - loss: 0.6436 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 395/1000\n",
      "176/176 [==============================] - 0s 434us/step - loss: 0.6436 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 396/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6435 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 397/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6434 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 398/1000\n",
      "176/176 [==============================] - 0s 475us/step - loss: 0.6433 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 399/1000\n",
      "176/176 [==============================] - 0s 494us/step - loss: 0.6432 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 400/1000\n",
      "176/176 [==============================] - 0s 500us/step - loss: 0.6431 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 401/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6430 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 402/1000\n",
      "176/176 [==============================] - 0s 454us/step - loss: 0.6430 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 403/1000\n",
      "176/176 [==============================] - 0s 437us/step - loss: 0.6429 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 404/1000\n",
      "176/176 [==============================] - 0s 446us/step - loss: 0.6428 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 405/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6427 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 406/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6427 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 407/1000\n",
      "176/176 [==============================] - 0s 453us/step - loss: 0.6426 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 408/1000\n",
      "176/176 [==============================] - 0s 468us/step - loss: 0.6425 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 409/1000\n",
      "176/176 [==============================] - 0s 459us/step - loss: 0.6424 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 410/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6423 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 411/1000\n",
      "176/176 [==============================] - 0s 453us/step - loss: 0.6422 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 412/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6421 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 413/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6421 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 414/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6420 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 415/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6419 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 416/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6418 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 417/1000\n",
      "176/176 [==============================] - 0s 439us/step - loss: 0.6417 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 418/1000\n",
      "176/176 [==============================] - 0s 437us/step - loss: 0.6416 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 419/1000\n",
      "176/176 [==============================] - 0s 428us/step - loss: 0.6415 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 420/1000\n",
      "176/176 [==============================] - 0s 421us/step - loss: 0.6415 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 421/1000\n",
      "176/176 [==============================] - 0s 433us/step - loss: 0.6414 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 422/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6413 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 423/1000\n",
      "176/176 [==============================] - 0s 477us/step - loss: 0.6412 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 424/1000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 0.6411 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 425/1000\n",
      "176/176 [==============================] - 0s 426us/step - loss: 0.6411 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 426/1000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 0.6410 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 427/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6409 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 428/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6408 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 429/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6407 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 430/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6406 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 431/1000\n",
      "176/176 [==============================] - 0s 433us/step - loss: 0.6406 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 432/1000\n",
      "176/176 [==============================] - 0s 425us/step - loss: 0.6405 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 433/1000\n",
      "176/176 [==============================] - 0s 439us/step - loss: 0.6404 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 434/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 430us/step - loss: 0.6403 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 435/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6402 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 436/1000\n",
      "176/176 [==============================] - 0s 425us/step - loss: 0.6401 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 437/1000\n",
      "176/176 [==============================] - 0s 426us/step - loss: 0.6401 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 438/1000\n",
      "176/176 [==============================] - 0s 430us/step - loss: 0.6400 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 439/1000\n",
      "176/176 [==============================] - 0s 437us/step - loss: 0.6399 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 440/1000\n",
      "176/176 [==============================] - 0s 425us/step - loss: 0.6398 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 441/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6398 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 442/1000\n",
      "176/176 [==============================] - 0s 423us/step - loss: 0.6397 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 443/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6396 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 444/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6395 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 445/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6394 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 446/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6393 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 447/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6393 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 448/1000\n",
      "176/176 [==============================] - 0s 530us/step - loss: 0.6392 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 449/1000\n",
      "176/176 [==============================] - 0s 672us/step - loss: 0.6391 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 450/1000\n",
      "176/176 [==============================] - 0s 609us/step - loss: 0.6390 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 451/1000\n",
      "176/176 [==============================] - 0s 547us/step - loss: 0.6389 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 452/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6388 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 453/1000\n",
      "176/176 [==============================] - 0s 460us/step - loss: 0.6387 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 454/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6387 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 455/1000\n",
      "176/176 [==============================] - 0s 424us/step - loss: 0.6386 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 456/1000\n",
      "176/176 [==============================] - 0s 430us/step - loss: 0.6385 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 457/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6384 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 458/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6383 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 459/1000\n",
      "176/176 [==============================] - 0s 435us/step - loss: 0.6382 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 460/1000\n",
      "176/176 [==============================] - 0s 420us/step - loss: 0.6382 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 461/1000\n",
      "176/176 [==============================] - 0s 483us/step - loss: 0.6380 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 462/1000\n",
      "176/176 [==============================] - 0s 423us/step - loss: 0.6380 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 463/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6379 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 464/1000\n",
      "176/176 [==============================] - 0s 479us/step - loss: 0.6378 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 465/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6377 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 466/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6377 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 467/1000\n",
      "176/176 [==============================] - 0s 459us/step - loss: 0.6376 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 468/1000\n",
      "176/176 [==============================] - 0s 446us/step - loss: 0.6375 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 469/1000\n",
      "176/176 [==============================] - 0s 423us/step - loss: 0.6374 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 470/1000\n",
      "176/176 [==============================] - 0s 437us/step - loss: 0.6373 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 471/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6372 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 472/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6372 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 473/1000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 0.6371 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 474/1000\n",
      "176/176 [==============================] - 0s 437us/step - loss: 0.6370 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 475/1000\n",
      "176/176 [==============================] - 0s 454us/step - loss: 0.6370 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 476/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6368 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 477/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6368 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 478/1000\n",
      "176/176 [==============================] - 0s 444us/step - loss: 0.6367 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 479/1000\n",
      "176/176 [==============================] - 0s 454us/step - loss: 0.6366 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 480/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6365 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 481/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6364 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 482/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6364 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 483/1000\n",
      "176/176 [==============================] - 0s 469us/step - loss: 0.6363 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 484/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6362 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 485/1000\n",
      "176/176 [==============================] - 0s 444us/step - loss: 0.6361 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 486/1000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 0.6360 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 487/1000\n",
      "176/176 [==============================] - 0s 453us/step - loss: 0.6359 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 488/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 441us/step - loss: 0.6359 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 489/1000\n",
      "176/176 [==============================] - 0s 427us/step - loss: 0.6358 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 490/1000\n",
      "176/176 [==============================] - 0s 430us/step - loss: 0.6357 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 491/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6356 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 492/1000\n",
      "176/176 [==============================] - 0s 446us/step - loss: 0.6355 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 493/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6355 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 494/1000\n",
      "176/176 [==============================] - 0s 426us/step - loss: 0.6354 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 495/1000\n",
      "176/176 [==============================] - 0s 484us/step - loss: 0.6353 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 496/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6352 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 497/1000\n",
      "176/176 [==============================] - 0s 471us/step - loss: 0.6352 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 498/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6351 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 499/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6350 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 500/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6349 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 501/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6348 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 502/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6347 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 503/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6347 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 504/1000\n",
      "176/176 [==============================] - 0s 484us/step - loss: 0.6346 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 505/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6345 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 506/1000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 0.6344 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 507/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6344 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 508/1000\n",
      "176/176 [==============================] - 0s 446us/step - loss: 0.6343 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 509/1000\n",
      "176/176 [==============================] - 0s 456us/step - loss: 0.6342 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 510/1000\n",
      "176/176 [==============================] - 0s 453us/step - loss: 0.6341 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 511/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6340 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 512/1000\n",
      "176/176 [==============================] - 0s 468us/step - loss: 0.6339 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 513/1000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 0.6338 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 514/1000\n",
      "176/176 [==============================] - 0s 442us/step - loss: 0.6338 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 515/1000\n",
      "176/176 [==============================] - 0s 482us/step - loss: 0.6337 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 516/1000\n",
      "176/176 [==============================] - 0s 454us/step - loss: 0.6336 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 517/1000\n",
      "176/176 [==============================] - 0s 442us/step - loss: 0.6335 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 518/1000\n",
      "176/176 [==============================] - 0s 456us/step - loss: 0.6334 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 519/1000\n",
      "176/176 [==============================] - 0s 468us/step - loss: 0.6334 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 520/1000\n",
      "176/176 [==============================] - 0s 465us/step - loss: 0.6333 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 521/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6332 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 522/1000\n",
      "176/176 [==============================] - 0s 472us/step - loss: 0.6331 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 523/1000\n",
      "176/176 [==============================] - 0s 472us/step - loss: 0.6331 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 524/1000\n",
      "176/176 [==============================] - 0s 460us/step - loss: 0.6330 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 525/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6329 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 526/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6328 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 527/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6327 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 528/1000\n",
      "176/176 [==============================] - 0s 460us/step - loss: 0.6326 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 529/1000\n",
      "176/176 [==============================] - 0s 492us/step - loss: 0.6326 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 530/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6325 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 531/1000\n",
      "176/176 [==============================] - 0s 427us/step - loss: 0.6324 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 532/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6324 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 533/1000\n",
      "176/176 [==============================] - 0s 463us/step - loss: 0.6323 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 534/1000\n",
      "176/176 [==============================] - 0s 463us/step - loss: 0.6322 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 535/1000\n",
      "176/176 [==============================] - 0s 491us/step - loss: 0.6321 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 536/1000\n",
      "176/176 [==============================] - 0s 490us/step - loss: 0.6320 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 537/1000\n",
      "176/176 [==============================] - 0s 471us/step - loss: 0.6319 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 538/1000\n",
      "176/176 [==============================] - 0s 465us/step - loss: 0.6319 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 539/1000\n",
      "176/176 [==============================] - 0s 472us/step - loss: 0.6318 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 540/1000\n",
      "176/176 [==============================] - 0s 464us/step - loss: 0.6317 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 541/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6316 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 542/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 452us/step - loss: 0.6315 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 543/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6314 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 544/1000\n",
      "176/176 [==============================] - 0s 446us/step - loss: 0.6314 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 545/1000\n",
      "176/176 [==============================] - 0s 449us/step - loss: 0.6313 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 546/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6312 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 547/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6311 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 548/1000\n",
      "176/176 [==============================] - 0s 456us/step - loss: 0.6311 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 549/1000\n",
      "176/176 [==============================] - 0s 459us/step - loss: 0.6310 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 550/1000\n",
      "176/176 [==============================] - 0s 452us/step - loss: 0.6309 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 551/1000\n",
      "176/176 [==============================] - 0s 463us/step - loss: 0.6308 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 552/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6307 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 553/1000\n",
      "176/176 [==============================] - 0s 481us/step - loss: 0.6307 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 554/1000\n",
      "176/176 [==============================] - 0s 491us/step - loss: 0.6306 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 555/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6305 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 556/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6305 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 557/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6304 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 558/1000\n",
      "176/176 [==============================] - 0s 468us/step - loss: 0.6303 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 559/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6302 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 560/1000\n",
      "176/176 [==============================] - 0s 506us/step - loss: 0.6301 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 561/1000\n",
      "176/176 [==============================] - 0s 556us/step - loss: 0.6300 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 562/1000\n",
      "176/176 [==============================] - 0s 616us/step - loss: 0.6299 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 563/1000\n",
      "176/176 [==============================] - 0s 499us/step - loss: 0.6299 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 564/1000\n",
      "176/176 [==============================] - 0s 446us/step - loss: 0.6298 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 565/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6297 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 566/1000\n",
      "176/176 [==============================] - 0s 434us/step - loss: 0.6296 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 567/1000\n",
      "176/176 [==============================] - 0s 417us/step - loss: 0.6295 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 568/1000\n",
      "176/176 [==============================] - 0s 436us/step - loss: 0.6295 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 569/1000\n",
      "176/176 [==============================] - 0s 434us/step - loss: 0.6294 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 570/1000\n",
      "176/176 [==============================] - 0s 419us/step - loss: 0.6294 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 571/1000\n",
      "176/176 [==============================] - 0s 446us/step - loss: 0.6292 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 572/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6292 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 573/1000\n",
      "176/176 [==============================] - 0s 433us/step - loss: 0.6291 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 574/1000\n",
      "176/176 [==============================] - 0s 435us/step - loss: 0.6290 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 575/1000\n",
      "176/176 [==============================] - 0s 436us/step - loss: 0.6290 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 576/1000\n",
      "176/176 [==============================] - 0s 428us/step - loss: 0.6288 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 577/1000\n",
      "176/176 [==============================] - 0s 425us/step - loss: 0.6288 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 578/1000\n",
      "176/176 [==============================] - 0s 426us/step - loss: 0.6287 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 579/1000\n",
      "176/176 [==============================] - 0s 435us/step - loss: 0.6286 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 580/1000\n",
      "176/176 [==============================] - 0s 437us/step - loss: 0.6285 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 581/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6284 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 582/1000\n",
      "176/176 [==============================] - 0s 446us/step - loss: 0.6284 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 583/1000\n",
      "176/176 [==============================] - 0s 412us/step - loss: 0.6283 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 584/1000\n",
      "176/176 [==============================] - 0s 426us/step - loss: 0.6282 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 585/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6281 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 586/1000\n",
      "176/176 [==============================] - 0s 428us/step - loss: 0.6281 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 587/1000\n",
      "176/176 [==============================] - 0s 435us/step - loss: 0.6280 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 588/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6279 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 589/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6278 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 590/1000\n",
      "176/176 [==============================] - 0s 446us/step - loss: 0.6278 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 591/1000\n",
      "176/176 [==============================] - 0s 427us/step - loss: 0.6277 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 592/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6276 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 593/1000\n",
      "176/176 [==============================] - 0s 430us/step - loss: 0.6275 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 594/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6274 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 595/1000\n",
      "176/176 [==============================] - 0s 423us/step - loss: 0.6274 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 596/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 449us/step - loss: 0.6273 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 597/1000\n",
      "176/176 [==============================] - 0s 421us/step - loss: 0.6273 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 598/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6271 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 599/1000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 0.6270 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 600/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6270 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 601/1000\n",
      "176/176 [==============================] - 0s 444us/step - loss: 0.6269 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 602/1000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 0.6268 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 603/1000\n",
      "176/176 [==============================] - 0s 424us/step - loss: 0.6267 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 604/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6267 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 605/1000\n",
      "176/176 [==============================] - 0s 436us/step - loss: 0.6266 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 606/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6265 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 607/1000\n",
      "176/176 [==============================] - 0s 426us/step - loss: 0.6264 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 608/1000\n",
      "176/176 [==============================] - 0s 642us/step - loss: 0.6263 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 609/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 610/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6262 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 611/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6261 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 612/1000\n",
      "176/176 [==============================] - 0s 789us/step - loss: 0.6260 - accuracy: 0.6668 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 613/1000\n",
      "176/176 [==============================] - 0s 463us/step - loss: 0.6260 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 614/1000\n",
      "176/176 [==============================] - 0s 436us/step - loss: 0.6259 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 615/1000\n",
      "176/176 [==============================] - 0s 435us/step - loss: 0.6258 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 616/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6257 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 617/1000\n",
      "176/176 [==============================] - 0s 424us/step - loss: 0.6256 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 618/1000\n",
      "176/176 [==============================] - 0s 427us/step - loss: 0.6256 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 619/1000\n",
      "176/176 [==============================] - 0s 436us/step - loss: 0.6255 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 620/1000\n",
      "176/176 [==============================] - 0s 437us/step - loss: 0.6254 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 621/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6254 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 622/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6253 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 623/1000\n",
      "176/176 [==============================] - 0s 434us/step - loss: 0.6252 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 624/1000\n",
      "176/176 [==============================] - 0s 435us/step - loss: 0.6251 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 625/1000\n",
      "176/176 [==============================] - 0s 453us/step - loss: 0.6251 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 626/1000\n",
      "176/176 [==============================] - 0s 498us/step - loss: 0.6250 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 627/1000\n",
      "176/176 [==============================] - 0s 861us/step - loss: 0.6249 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 628/1000\n",
      "176/176 [==============================] - 0s 699us/step - loss: 0.6248 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 629/1000\n",
      "176/176 [==============================] - 0s 846us/step - loss: 0.6248 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 630/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 631/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 632/1000\n",
      "176/176 [==============================] - 0s 605us/step - loss: 0.6245 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 633/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6244 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 634/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 635/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6243 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 636/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6242 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 637/1000\n",
      "176/176 [==============================] - 0s 828us/step - loss: 0.6242 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 638/1000\n",
      "176/176 [==============================] - 0s 943us/step - loss: 0.6241 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 639/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6240 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 640/1000\n",
      "176/176 [==============================] - 0s 862us/step - loss: 0.6239 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 641/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6238 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 642/1000\n",
      "176/176 [==============================] - 0s 630us/step - loss: 0.6238 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 643/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6237 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 644/1000\n",
      "176/176 [==============================] - 0s 831us/step - loss: 0.6236 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 645/1000\n",
      "176/176 [==============================] - 0s 866us/step - loss: 0.6235 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 646/1000\n",
      "176/176 [==============================] - 0s 638us/step - loss: 0.6234 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 647/1000\n",
      "176/176 [==============================] - 0s 509us/step - loss: 0.6234 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 648/1000\n",
      "176/176 [==============================] - 0s 779us/step - loss: 0.6233 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 649/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6232 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 650/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 437us/step - loss: 0.6231 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 651/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6231 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 652/1000\n",
      "176/176 [==============================] - 0s 431us/step - loss: 0.6230 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 653/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6229 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 654/1000\n",
      "176/176 [==============================] - 0s 436us/step - loss: 0.6229 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 655/1000\n",
      "176/176 [==============================] - 0s 420us/step - loss: 0.6228 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 656/1000\n",
      "176/176 [==============================] - 0s 442us/step - loss: 0.6227 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 657/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6226 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 658/1000\n",
      "176/176 [==============================] - 0s 438us/step - loss: 0.6225 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 659/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6225 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 660/1000\n",
      "176/176 [==============================] - 0s 641us/step - loss: 0.6224 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 661/1000\n",
      "176/176 [==============================] - 0s 492us/step - loss: 0.6223 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 662/1000\n",
      "176/176 [==============================] - 0s 456us/step - loss: 0.6222 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 663/1000\n",
      "176/176 [==============================] - 0s 456us/step - loss: 0.6222 - accuracy: 0.6665 - precision: 0.3333 - recall: 8.5543e-04\n",
      "Epoch 664/1000\n",
      "176/176 [==============================] - 0s 449us/step - loss: 0.6221 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 665/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6220 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 666/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6219 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 667/1000\n",
      "176/176 [==============================] - 0s 459us/step - loss: 0.6218 - accuracy: 0.6662 - precision: 0.2500 - recall: 8.5543e-04\n",
      "Epoch 668/1000\n",
      "176/176 [==============================] - 0s 685us/step - loss: 0.6218 - accuracy: 0.6668 - precision: 0.5000 - recall: 8.5543e-04\n",
      "Epoch 669/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6217 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 670/1000\n",
      "176/176 [==============================] - 0s 428us/step - loss: 0.6216 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 671/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6215 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 672/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6215 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 673/1000\n",
      "176/176 [==============================] - 0s 434us/step - loss: 0.6214 - accuracy: 0.6662 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 674/1000\n",
      "176/176 [==============================] - 0s 435us/step - loss: 0.6213 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 675/1000\n",
      "176/176 [==============================] - 0s 428us/step - loss: 0.6212 - accuracy: 0.6665 - precision: 0.3333 - recall: 8.5543e-04\n",
      "Epoch 676/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6212 - accuracy: 0.6668 - precision: 0.5000 - recall: 8.5543e-04\n",
      "Epoch 677/1000\n",
      "176/176 [==============================] - 0s 460us/step - loss: 0.6211 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 678/1000\n",
      "176/176 [==============================] - 0s 456us/step - loss: 0.6210 - accuracy: 0.6662 - precision: 0.2500 - recall: 8.5543e-04\n",
      "Epoch 679/1000\n",
      "176/176 [==============================] - 0s 436us/step - loss: 0.6210 - accuracy: 0.6662 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 680/1000\n",
      "176/176 [==============================] - 0s 459us/step - loss: 0.6209 - accuracy: 0.6662 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 681/1000\n",
      "176/176 [==============================] - 0s 539us/step - loss: 0.6208 - accuracy: 0.6662 - precision: 0.2500 - recall: 8.5543e-04\n",
      "Epoch 682/1000\n",
      "176/176 [==============================] - 0s 561us/step - loss: 0.6207 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 683/1000\n",
      "176/176 [==============================] - 0s 435us/step - loss: 0.6206 - accuracy: 0.6665 - precision: 0.3333 - recall: 8.5543e-04\n",
      "Epoch 684/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6206 - accuracy: 0.6665 - precision: 0.3333 - recall: 8.5543e-04\n",
      "Epoch 685/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6205 - accuracy: 0.6665 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 686/1000\n",
      "176/176 [==============================] - 0s 460us/step - loss: 0.6204 - accuracy: 0.6668 - precision: 0.5000 - recall: 8.5543e-04\n",
      "Epoch 687/1000\n",
      "176/176 [==============================] - 0s 419us/step - loss: 0.6204 - accuracy: 0.6662 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
      "Epoch 688/1000\n",
      "176/176 [==============================] - 0s 444us/step - loss: 0.6203 - accuracy: 0.6662 - precision: 0.2500 - recall: 8.5543e-04\n",
      "Epoch 689/1000\n",
      "176/176 [==============================] - 0s 460us/step - loss: 0.6202 - accuracy: 0.6662 - precision: 0.2500 - recall: 8.5543e-04\n",
      "Epoch 690/1000\n",
      "176/176 [==============================] - 0s 446us/step - loss: 0.6201 - accuracy: 0.6668 - precision: 0.5000 - recall: 8.5543e-04\n",
      "Epoch 691/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6200 - accuracy: 0.6665 - precision: 0.3333 - recall: 8.5543e-04\n",
      "Epoch 692/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6200 - accuracy: 0.6668 - precision: 0.5000 - recall: 8.5543e-04\n",
      "Epoch 693/1000\n",
      "176/176 [==============================] - 0s 701us/step - loss: 0.6199 - accuracy: 0.6665 - precision: 0.3333 - recall: 8.5543e-04\n",
      "Epoch 694/1000\n",
      "176/176 [==============================] - 0s 483us/step - loss: 0.6198 - accuracy: 0.6662 - precision: 0.2500 - recall: 8.5543e-04\n",
      "Epoch 695/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6197 - accuracy: 0.6665 - precision: 0.3333 - recall: 8.5543e-04\n",
      "Epoch 696/1000\n",
      "176/176 [==============================] - 0s 807us/step - loss: 0.6197 - accuracy: 0.6668 - precision: 0.5000 - recall: 8.5543e-04\n",
      "Epoch 697/1000\n",
      "176/176 [==============================] - 0s 920us/step - loss: 0.6196 - accuracy: 0.6662 - precision: 0.2500 - recall: 8.5543e-04\n",
      "Epoch 698/1000\n",
      "176/176 [==============================] - 0s 802us/step - loss: 0.6195 - accuracy: 0.6665 - precision: 0.3333 - recall: 8.5543e-04\n",
      "Epoch 699/1000\n",
      "176/176 [==============================] - 0s 463us/step - loss: 0.6195 - accuracy: 0.6662 - precision: 0.2500 - recall: 8.5543e-04\n",
      "Epoch 700/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6194 - accuracy: 0.6665 - precision: 0.3333 - recall: 8.5543e-04\n",
      "Epoch 701/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6193 - accuracy: 0.6659 - precision: 0.2000 - recall: 8.5543e-04\n",
      "Epoch 702/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.6651 - precision: 0.1250 - recall: 8.5543e-04\n",
      "Epoch 703/1000\n",
      "176/176 [==============================] - 0s 851us/step - loss: 0.6191 - accuracy: 0.6662 - precision: 0.2500 - recall: 8.5543e-04\n",
      "Epoch 704/1000\n",
      "176/176 [==============================] - 0s 449us/step - loss: 0.6191 - accuracy: 0.6665 - precision: 0.3333 - recall: 8.5543e-04\n",
      "Epoch 705/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 435us/step - loss: 0.6190 - accuracy: 0.6662 - precision: 0.2500 - recall: 8.5543e-04\n",
      "Epoch 706/1000\n",
      "176/176 [==============================] - 0s 643us/step - loss: 0.6189 - accuracy: 0.6662 - precision: 0.2500 - recall: 8.5543e-04\n",
      "Epoch 707/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6188 - accuracy: 0.6659 - precision: 0.2000 - recall: 8.5543e-04\n",
      "Epoch 708/1000\n",
      "176/176 [==============================] - 0s 932us/step - loss: 0.6188 - accuracy: 0.6662 - precision: 0.2500 - recall: 8.5543e-04\n",
      "Epoch 709/1000\n",
      "176/176 [==============================] - 0s 987us/step - loss: 0.6187 - accuracy: 0.6659 - precision: 0.2000 - recall: 8.5543e-04\n",
      "Epoch 710/1000\n",
      "176/176 [==============================] - 0s 855us/step - loss: 0.6186 - accuracy: 0.6662 - precision: 0.2500 - recall: 8.5543e-04\n",
      "Epoch 711/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6186 - accuracy: 0.6653 - precision: 0.1429 - recall: 8.5543e-04\n",
      "Epoch 712/1000\n",
      "176/176 [==============================] - 0s 612us/step - loss: 0.6185 - accuracy: 0.6651 - precision: 0.1250 - recall: 8.5543e-04\n",
      "Epoch 713/1000\n",
      "176/176 [==============================] - 0s 486us/step - loss: 0.6184 - accuracy: 0.6665 - precision: 0.3333 - recall: 8.5543e-04\n",
      "Epoch 714/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6184 - accuracy: 0.6659 - precision: 0.3333 - recall: 0.0026\n",
      "Epoch 715/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6183 - accuracy: 0.6659 - precision: 0.2000 - recall: 8.5543e-04\n",
      "Epoch 716/1000\n",
      "176/176 [==============================] - 0s 950us/step - loss: 0.6182 - accuracy: 0.6651 - precision: 0.1250 - recall: 8.5543e-04\n",
      "Epoch 717/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.6659 - precision: 0.2000 - recall: 8.5543e-04\n",
      "Epoch 718/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6181 - accuracy: 0.6656 - precision: 0.1667 - recall: 8.5543e-04\n",
      "Epoch 719/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6180 - accuracy: 0.6653 - precision: 0.1429 - recall: 8.5543e-04\n",
      "Epoch 720/1000\n",
      "176/176 [==============================] - 0s 961us/step - loss: 0.6179 - accuracy: 0.6656 - precision: 0.1667 - recall: 8.5543e-04\n",
      "Epoch 721/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6178 - accuracy: 0.6656 - precision: 0.1667 - recall: 8.5543e-04\n",
      "Epoch 722/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.6659 - precision: 0.2000 - recall: 8.5543e-04\n",
      "Epoch 723/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.6651 - precision: 0.1250 - recall: 8.5543e-04\n",
      "Epoch 724/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.6651 - precision: 0.1250 - recall: 8.5543e-04\n",
      "Epoch 725/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.6656 - precision: 0.2500 - recall: 0.0017\n",
      "Epoch 726/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6656 - precision: 0.1667 - recall: 8.5543e-04\n",
      "Epoch 727/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.6659 - precision: 0.2000 - recall: 8.5543e-04\n",
      "Epoch 728/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6656 - precision: 0.1667 - recall: 8.5543e-04\n",
      "Epoch 729/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.6653 - precision: 0.1429 - recall: 8.5543e-04\n",
      "Epoch 730/1000\n",
      "176/176 [==============================] - 0s 907us/step - loss: 0.6172 - accuracy: 0.6653 - precision: 0.1429 - recall: 8.5543e-04\n",
      "Epoch 731/1000\n",
      "176/176 [==============================] - 0s 850us/step - loss: 0.6171 - accuracy: 0.6656 - precision: 0.3000 - recall: 0.0026 \n",
      "Epoch 732/1000\n",
      "176/176 [==============================] - 0s 956us/step - loss: 0.6170 - accuracy: 0.6656 - precision: 0.1667 - recall: 8.5543e-04\n",
      "Epoch 733/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6169 - accuracy: 0.6653 - precision: 0.1429 - recall: 8.5543e-04\n",
      "Epoch 734/1000\n",
      "176/176 [==============================] - 0s 850us/step - loss: 0.6169 - accuracy: 0.6651 - precision: 0.2000 - recall: 0.0017\n",
      "Epoch 735/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6168 - accuracy: 0.6653 - precision: 0.2222 - recall: 0.0017\n",
      "Epoch 736/1000\n",
      "176/176 [==============================] - 0s 896us/step - loss: 0.6167 - accuracy: 0.6653 - precision: 0.1429 - recall: 8.5543e-04\n",
      "Epoch 737/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6166 - accuracy: 0.6659 - precision: 0.3333 - recall: 0.0026   \n",
      "Epoch 738/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6166 - accuracy: 0.6662 - precision: 0.3750 - recall: 0.0026  \n",
      "Epoch 739/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6165 - accuracy: 0.6659 - precision: 0.2857 - recall: 0.0017\n",
      "Epoch 740/1000\n",
      "176/176 [==============================] - 0s 979us/step - loss: 0.6164 - accuracy: 0.6662 - precision: 0.4286 - recall: 0.0051\n",
      "Epoch 741/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6163 - accuracy: 0.6656 - precision: 0.3000 - recall: 0.0026    \n",
      "Epoch 742/1000\n",
      "176/176 [==============================] - 0s 903us/step - loss: 0.6163 - accuracy: 0.6656 - precision: 0.3333 - recall: 0.0034\n",
      "Epoch 743/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6162 - accuracy: 0.6653 - precision: 0.2222 - recall: 0.0017  \n",
      "Epoch 744/1000\n",
      "176/176 [==============================] - 0s 835us/step - loss: 0.6161 - accuracy: 0.6651 - precision: 0.2000 - recall: 0.0017\n",
      "Epoch 745/1000\n",
      "176/176 [==============================] - 0s 803us/step - loss: 0.6160 - accuracy: 0.6662 - precision: 0.4167 - recall: 0.0043\n",
      "Epoch 746/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6160 - accuracy: 0.6659 - precision: 0.4000 - recall: 0.0051  \n",
      "Epoch 747/1000\n",
      "176/176 [==============================] - 0s 825us/step - loss: 0.6159 - accuracy: 0.6656 - precision: 0.3000 - recall: 0.0026\n",
      "Epoch 748/1000\n",
      "176/176 [==============================] - 0s 783us/step - loss: 0.6158 - accuracy: 0.6656 - precision: 0.3333 - recall: 0.0034\n",
      "Epoch 749/1000\n",
      "176/176 [==============================] - 0s 788us/step - loss: 0.6158 - accuracy: 0.6659 - precision: 0.3636 - recall: 0.0034\n",
      "Epoch 750/1000\n",
      "176/176 [==============================] - 0s 805us/step - loss: 0.6157 - accuracy: 0.6656 - precision: 0.3333 - recall: 0.0034\n",
      "Epoch 751/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6156 - accuracy: 0.6656 - precision: 0.2500 - recall: 0.0017  \n",
      "Epoch 752/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6156 - accuracy: 0.6653 - precision: 0.3077 - recall: 0.0034 \n",
      "Epoch 753/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6155 - accuracy: 0.6653 - precision: 0.2222 - recall: 0.0017 \n",
      "Epoch 754/1000\n",
      "176/176 [==============================] - 0s 927us/step - loss: 0.6154 - accuracy: 0.6665 - precision: 0.4667 - recall: 0.0060\n",
      "Epoch 755/1000\n",
      "176/176 [==============================] - 0s 883us/step - loss: 0.6153 - accuracy: 0.6653 - precision: 0.2222 - recall: 0.0017 \n",
      "Epoch 756/1000\n",
      "176/176 [==============================] - 0s 952us/step - loss: 0.6153 - accuracy: 0.6665 - precision: 0.4615 - recall: 0.0051\n",
      "Epoch 757/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6152 - accuracy: 0.6659 - precision: 0.3846 - recall: 0.0043 \n",
      "Epoch 758/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.6662 - precision: 0.4286 - recall: 0.0051\n",
      "Epoch 759/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.6662 - precision: 0.4286 - recall: 0.0051\n",
      "Epoch 760/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6150 - accuracy: 0.6653 - precision: 0.2222 - recall: 0.0017   \n",
      "Epoch 761/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.6659 - precision: 0.3846 - recall: 0.0043\n",
      "Epoch 762/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6148 - accuracy: 0.6662 - precision: 0.4444 - recall: 0.0068 \n",
      "Epoch 763/1000\n",
      "176/176 [==============================] - 0s 994us/step - loss: 0.6147 - accuracy: 0.6659 - precision: 0.4118 - recall: 0.0060\n",
      "Epoch 764/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6147 - accuracy: 0.6656 - precision: 0.3571 - recall: 0.0043\n",
      "Epoch 765/1000\n",
      "176/176 [==============================] - 0s 892us/step - loss: 0.6146 - accuracy: 0.6662 - precision: 0.4286 - recall: 0.0051\n",
      "Epoch 766/1000\n",
      "176/176 [==============================] - 0s 856us/step - loss: 0.6145 - accuracy: 0.6665 - precision: 0.4667 - recall: 0.0060\n",
      "Epoch 767/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.6659 - precision: 0.4000 - recall: 0.0051 \n",
      "Epoch 768/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6144 - accuracy: 0.6656 - precision: 0.4000 - recall: 0.0068  \n",
      "Epoch 769/1000\n",
      "176/176 [==============================] - 0s 584us/step - loss: 0.6143 - accuracy: 0.6665 - precision: 0.4706 - recall: 0.0068\n",
      "Epoch 770/1000\n",
      "176/176 [==============================] - 0s 915us/step - loss: 0.6143 - accuracy: 0.6656 - precision: 0.3333 - recall: 0.0034 \n",
      "Epoch 771/1000\n",
      "176/176 [==============================] - 0s 866us/step - loss: 0.6142 - accuracy: 0.6662 - precision: 0.4500 - recall: 0.0077\n",
      "Epoch 772/1000\n",
      "176/176 [==============================] - 0s 894us/step - loss: 0.6141 - accuracy: 0.6665 - precision: 0.4706 - recall: 0.0068\n",
      "Epoch 773/1000\n",
      "176/176 [==============================] - 0s 807us/step - loss: 0.6140 - accuracy: 0.6662 - precision: 0.4444 - recall: 0.0068\n",
      "Epoch 774/1000\n",
      "176/176 [==============================] - 0s 812us/step - loss: 0.6139 - accuracy: 0.6662 - precision: 0.4286 - recall: 0.0051\n",
      "Epoch 775/1000\n",
      "176/176 [==============================] - 0s 815us/step - loss: 0.6139 - accuracy: 0.6665 - precision: 0.4737 - recall: 0.0077\n",
      "Epoch 776/1000\n",
      "176/176 [==============================] - 0s 799us/step - loss: 0.6138 - accuracy: 0.6665 - precision: 0.4706 - recall: 0.0068\n",
      "Epoch 777/1000\n",
      "176/176 [==============================] - 0s 961us/step - loss: 0.6137 - accuracy: 0.6665 - precision: 0.4706 - recall: 0.0068\n",
      "Epoch 778/1000\n",
      "176/176 [==============================] - 0s 831us/step - loss: 0.6136 - accuracy: 0.6659 - precision: 0.4000 - recall: 0.0051\n",
      "Epoch 779/1000\n",
      "176/176 [==============================] - 0s 801us/step - loss: 0.6136 - accuracy: 0.6659 - precision: 0.4118 - recall: 0.0060\n",
      "Epoch 780/1000\n",
      "176/176 [==============================] - 0s 807us/step - loss: 0.6135 - accuracy: 0.6662 - precision: 0.4500 - recall: 0.0077\n",
      "Epoch 781/1000\n",
      "176/176 [==============================] - 0s 810us/step - loss: 0.6134 - accuracy: 0.6662 - precision: 0.4286 - recall: 0.0051\n",
      "Epoch 782/1000\n",
      "176/176 [==============================] - 0s 786us/step - loss: 0.6134 - accuracy: 0.6656 - precision: 0.4000 - recall: 0.0068\n",
      "Epoch 783/1000\n",
      "176/176 [==============================] - 0s 803us/step - loss: 0.6133 - accuracy: 0.6656 - precision: 0.4000 - recall: 0.0068\n",
      "Epoch 784/1000\n",
      "176/176 [==============================] - 0s 778us/step - loss: 0.6132 - accuracy: 0.6665 - precision: 0.4706 - recall: 0.0068\n",
      "Epoch 785/1000\n",
      "176/176 [==============================] - 0s 807us/step - loss: 0.6131 - accuracy: 0.6656 - precision: 0.4000 - recall: 0.0068\n",
      "Epoch 786/1000\n",
      "176/176 [==============================] - 0s 851us/step - loss: 0.6131 - accuracy: 0.6665 - precision: 0.4706 - recall: 0.0068 \n",
      "Epoch 787/1000\n",
      "176/176 [==============================] - 0s 958us/step - loss: 0.6130 - accuracy: 0.6665 - precision: 0.4737 - recall: 0.0077\n",
      "Epoch 788/1000\n",
      "176/176 [==============================] - 0s 977us/step - loss: 0.6129 - accuracy: 0.6656 - precision: 0.4167 - recall: 0.0086\n",
      "Epoch 789/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6129 - accuracy: 0.6659 - precision: 0.4118 - recall: 0.0060 \n",
      "Epoch 790/1000\n",
      "176/176 [==============================] - 0s 808us/step - loss: 0.6128 - accuracy: 0.6659 - precision: 0.4118 - recall: 0.0060\n",
      "Epoch 791/1000\n",
      "176/176 [==============================] - 0s 532us/step - loss: 0.6127 - accuracy: 0.6659 - precision: 0.4286 - recall: 0.0077 \n",
      "Epoch 792/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6126 - accuracy: 0.6662 - precision: 0.4500 - recall: 0.0077\n",
      "Epoch 793/1000\n",
      "176/176 [==============================] - 0s 821us/step - loss: 0.6125 - accuracy: 0.6662 - precision: 0.4444 - recall: 0.0068\n",
      "Epoch 794/1000\n",
      "176/176 [==============================] - 0s 775us/step - loss: 0.6125 - accuracy: 0.6662 - precision: 0.4444 - recall: 0.0068\n",
      "Epoch 795/1000\n",
      "176/176 [==============================] - 0s 792us/step - loss: 0.6124 - accuracy: 0.6651 - precision: 0.3636 - recall: 0.0068\n",
      "Epoch 796/1000\n",
      "176/176 [==============================] - 0s 793us/step - loss: 0.6124 - accuracy: 0.6659 - precision: 0.4400 - recall: 0.0094\n",
      "Epoch 797/1000\n",
      "176/176 [==============================] - 0s 464us/step - loss: 0.6123 - accuracy: 0.6651 - precision: 0.3929 - recall: 0.0094 \n",
      "Epoch 798/1000\n",
      "176/176 [==============================] - 0s 905us/step - loss: 0.6122 - accuracy: 0.6662 - precision: 0.4500 - recall: 0.0077\n",
      "Epoch 799/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6121 - accuracy: 0.6662 - precision: 0.4444 - recall: 0.0068 \n",
      "Epoch 800/1000\n",
      "176/176 [==============================] - 0s 556us/step - loss: 0.6120 - accuracy: 0.6659 - precision: 0.4348 - recall: 0.0086 \n",
      "Epoch 801/1000\n",
      "176/176 [==============================] - 0s 482us/step - loss: 0.6120 - accuracy: 0.6651 - precision: 0.4000 - recall: 0.0103 \n",
      "Epoch 802/1000\n",
      "176/176 [==============================] - 0s 780us/step - loss: 0.6119 - accuracy: 0.6665 - precision: 0.4762 - recall: 0.0086\n",
      "Epoch 803/1000\n",
      "176/176 [==============================] - 0s 803us/step - loss: 0.6118 - accuracy: 0.6656 - precision: 0.4091 - recall: 0.0077\n",
      "Epoch 804/1000\n",
      "176/176 [==============================] - 0s 793us/step - loss: 0.6118 - accuracy: 0.6653 - precision: 0.4138 - recall: 0.0103\n",
      "Epoch 805/1000\n",
      "176/176 [==============================] - 0s 488us/step - loss: 0.6117 - accuracy: 0.6665 - precision: 0.4783 - recall: 0.0094\n",
      "Epoch 806/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6116 - accuracy: 0.6659 - precision: 0.4348 - recall: 0.0086 \n",
      "Epoch 807/1000\n",
      "176/176 [==============================] - 0s 634us/step - loss: 0.6115 - accuracy: 0.6656 - precision: 0.4167 - recall: 0.0086\n",
      "Epoch 808/1000\n",
      "176/176 [==============================] - 0s 567us/step - loss: 0.6115 - accuracy: 0.6659 - precision: 0.4348 - recall: 0.0086\n",
      "Epoch 809/1000\n",
      "176/176 [==============================] - 0s 492us/step - loss: 0.6114 - accuracy: 0.6653 - precision: 0.4074 - recall: 0.0094 \n",
      "Epoch 810/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6114 - accuracy: 0.6659 - precision: 0.4483 - recall: 0.0111 \n",
      "Epoch 811/1000\n",
      "176/176 [==============================] - 0s 435us/step - loss: 0.6113 - accuracy: 0.6653 - precision: 0.4074 - recall: 0.0094 \n",
      "Epoch 812/1000\n",
      "176/176 [==============================] - 0s 427us/step - loss: 0.6112 - accuracy: 0.6659 - precision: 0.4400 - recall: 0.0094 \n",
      "Epoch 813/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6111 - accuracy: 0.6653 - precision: 0.4000 - recall: 0.0086 \n",
      "Epoch 814/1000\n",
      "176/176 [==============================] - 0s 436us/step - loss: 0.6110 - accuracy: 0.6662 - precision: 0.4643 - recall: 0.0111 \n",
      "Epoch 815/1000\n",
      "176/176 [==============================] - 0s 444us/step - loss: 0.6110 - accuracy: 0.6662 - precision: 0.4688 - recall: 0.0128 \n",
      "Epoch 816/1000\n",
      "176/176 [==============================] - 0s 436us/step - loss: 0.6109 - accuracy: 0.6653 - precision: 0.4242 - recall: 0.0120\n",
      "Epoch 817/1000\n",
      "176/176 [==============================] - 0s 425us/step - loss: 0.6108 - accuracy: 0.6659 - precision: 0.4483 - recall: 0.0111 \n",
      "Epoch 818/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 414us/step - loss: 0.6108 - accuracy: 0.6656 - precision: 0.4231 - recall: 0.0094 \n",
      "Epoch 819/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6107 - accuracy: 0.6659 - precision: 0.4483 - recall: 0.0111 \n",
      "Epoch 820/1000\n",
      "176/176 [==============================] - 0s 425us/step - loss: 0.6107 - accuracy: 0.6653 - precision: 0.4138 - recall: 0.0103 \n",
      "Epoch 821/1000\n",
      "176/176 [==============================] - 0s 426us/step - loss: 0.6105 - accuracy: 0.6653 - precision: 0.4194 - recall: 0.0111 \n",
      "Epoch 822/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6105 - accuracy: 0.6653 - precision: 0.4138 - recall: 0.0103 \n",
      "Epoch 823/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6104 - accuracy: 0.6653 - precision: 0.4074 - recall: 0.0094 \n",
      "Epoch 824/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6103 - accuracy: 0.6659 - precision: 0.4483 - recall: 0.0111 \n",
      "Epoch 825/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6103 - accuracy: 0.6659 - precision: 0.4545 - recall: 0.0128 \n",
      "Epoch 826/1000\n",
      "176/176 [==============================] - 0s 425us/step - loss: 0.6102 - accuracy: 0.6656 - precision: 0.4231 - recall: 0.0094 \n",
      "Epoch 827/1000\n",
      "176/176 [==============================] - 0s 430us/step - loss: 0.6101 - accuracy: 0.6651 - precision: 0.4167 - recall: 0.0128 \n",
      "Epoch 828/1000\n",
      "176/176 [==============================] - 0s 428us/step - loss: 0.6100 - accuracy: 0.6651 - precision: 0.3929 - recall: 0.0094 \n",
      "Epoch 829/1000\n",
      "176/176 [==============================] - 0s 419us/step - loss: 0.6100 - accuracy: 0.6656 - precision: 0.4286 - recall: 0.0103 \n",
      "Epoch 830/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6099 - accuracy: 0.6648 - precision: 0.3793 - recall: 0.0094 \n",
      "Epoch 831/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6098 - accuracy: 0.6656 - precision: 0.4375 - recall: 0.0120 \n",
      "Epoch 832/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6098 - accuracy: 0.6653 - precision: 0.4194 - recall: 0.0111 \n",
      "Epoch 833/1000\n",
      "176/176 [==============================] - 0s 449us/step - loss: 0.6097 - accuracy: 0.6656 - precision: 0.4375 - recall: 0.0120\n",
      "Epoch 834/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6096 - accuracy: 0.6653 - precision: 0.4242 - recall: 0.0120 \n",
      "Epoch 835/1000\n",
      "176/176 [==============================] - 0s 426us/step - loss: 0.6096 - accuracy: 0.6656 - precision: 0.4375 - recall: 0.0120 \n",
      "Epoch 836/1000\n",
      "176/176 [==============================] - 0s 433us/step - loss: 0.6095 - accuracy: 0.6653 - precision: 0.4286 - recall: 0.0128 \n",
      "Epoch 837/1000\n",
      "176/176 [==============================] - 0s 431us/step - loss: 0.6094 - accuracy: 0.6653 - precision: 0.4242 - recall: 0.0120 \n",
      "Epoch 838/1000\n",
      "176/176 [==============================] - 0s 442us/step - loss: 0.6093 - accuracy: 0.6659 - precision: 0.4483 - recall: 0.0111 \n",
      "Epoch 839/1000\n",
      "176/176 [==============================] - 0s 432us/step - loss: 0.6092 - accuracy: 0.6651 - precision: 0.4000 - recall: 0.0103 \n",
      "Epoch 840/1000\n",
      "176/176 [==============================] - 0s 453us/step - loss: 0.6092 - accuracy: 0.6653 - precision: 0.4242 - recall: 0.0120 \n",
      "Epoch 841/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6091 - accuracy: 0.6653 - precision: 0.4194 - recall: 0.0111 \n",
      "Epoch 842/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6091 - accuracy: 0.6645 - precision: 0.3750 - recall: 0.0103 \n",
      "Epoch 843/1000\n",
      "176/176 [==============================] - 0s 437us/step - loss: 0.6090 - accuracy: 0.6659 - precision: 0.4545 - recall: 0.0128 \n",
      "Epoch 844/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6089 - accuracy: 0.6653 - precision: 0.4286 - recall: 0.0128 \n",
      "Epoch 845/1000\n",
      "176/176 [==============================] - 0s 442us/step - loss: 0.6088 - accuracy: 0.6651 - precision: 0.4062 - recall: 0.0111 \n",
      "Epoch 846/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6088 - accuracy: 0.6656 - precision: 0.4412 - recall: 0.0128 \n",
      "Epoch 847/1000\n",
      "176/176 [==============================] - 0s 456us/step - loss: 0.6087 - accuracy: 0.6662 - precision: 0.4688 - recall: 0.0128\n",
      "Epoch 848/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6086 - accuracy: 0.6651 - precision: 0.4167 - recall: 0.0128 \n",
      "Epoch 849/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6085 - accuracy: 0.6659 - precision: 0.4545 - recall: 0.0128 \n",
      "Epoch 850/1000\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.6085 - accuracy: 0.6656 - precision: 0.4412 - recall: 0.0128\n",
      "Epoch 851/1000\n",
      "176/176 [==============================] - 0s 1ms/step - loss: 0.6084 - accuracy: 0.6651 - precision: 0.4167 - recall: 0.0128 \n",
      "Epoch 852/1000\n",
      "176/176 [==============================] - 0s 467us/step - loss: 0.6083 - accuracy: 0.6656 - precision: 0.4412 - recall: 0.0128 \n",
      "Epoch 853/1000\n",
      "176/176 [==============================] - 0s 465us/step - loss: 0.6083 - accuracy: 0.6653 - precision: 0.4286 - recall: 0.0128 \n",
      "Epoch 854/1000\n",
      "176/176 [==============================] - 0s 451us/step - loss: 0.6082 - accuracy: 0.6642 - precision: 0.3846 - recall: 0.0128 \n",
      "Epoch 855/1000\n",
      "176/176 [==============================] - 0s 454us/step - loss: 0.6081 - accuracy: 0.6656 - precision: 0.4412 - recall: 0.0128 \n",
      "Epoch 856/1000\n",
      "176/176 [==============================] - 0s 472us/step - loss: 0.6081 - accuracy: 0.6653 - precision: 0.4286 - recall: 0.0128 \n",
      "Epoch 857/1000\n",
      "176/176 [==============================] - 0s 500us/step - loss: 0.6080 - accuracy: 0.6653 - precision: 0.4286 - recall: 0.0128 \n",
      "Epoch 858/1000\n",
      "176/176 [==============================] - 0s 695us/step - loss: 0.6079 - accuracy: 0.6653 - precision: 0.4286 - recall: 0.0128\n",
      "Epoch 859/1000\n",
      "176/176 [==============================] - 0s 477us/step - loss: 0.6078 - accuracy: 0.6656 - precision: 0.4412 - recall: 0.0128 \n",
      "Epoch 860/1000\n",
      "176/176 [==============================] - 0s 781us/step - loss: 0.6078 - accuracy: 0.6651 - precision: 0.4167 - recall: 0.0128\n",
      "Epoch 861/1000\n",
      "176/176 [==============================] - 0s 893us/step - loss: 0.6077 - accuracy: 0.6651 - precision: 0.4211 - recall: 0.0137\n",
      "Epoch 862/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6076 - accuracy: 0.6653 - precision: 0.4286 - recall: 0.0128 \n",
      "Epoch 863/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6075 - accuracy: 0.6648 - precision: 0.4054 - recall: 0.0128 \n",
      "Epoch 864/1000\n",
      "176/176 [==============================] - 0s 792us/step - loss: 0.6075 - accuracy: 0.6648 - precision: 0.4054 - recall: 0.0128\n",
      "Epoch 865/1000\n",
      "176/176 [==============================] - 0s 814us/step - loss: 0.6074 - accuracy: 0.6651 - precision: 0.4167 - recall: 0.0128\n",
      "Epoch 866/1000\n",
      "176/176 [==============================] - 0s 472us/step - loss: 0.6073 - accuracy: 0.6639 - precision: 0.3810 - recall: 0.0137 \n",
      "Epoch 867/1000\n",
      "176/176 [==============================] - 0s 471us/step - loss: 0.6073 - accuracy: 0.6651 - precision: 0.4167 - recall: 0.0128\n",
      "Epoch 868/1000\n",
      "176/176 [==============================] - 0s 467us/step - loss: 0.6072 - accuracy: 0.6633 - precision: 0.3696 - recall: 0.0145 \n",
      "Epoch 869/1000\n",
      "176/176 [==============================] - 0s 481us/step - loss: 0.6071 - accuracy: 0.6642 - precision: 0.3902 - recall: 0.0137 \n",
      "Epoch 870/1000\n",
      "176/176 [==============================] - 0s 496us/step - loss: 0.6071 - accuracy: 0.6645 - precision: 0.4048 - recall: 0.0145 \n",
      "Epoch 871/1000\n",
      "176/176 [==============================] - 0s 495us/step - loss: 0.6070 - accuracy: 0.6633 - precision: 0.3636 - recall: 0.0137 \n",
      "Epoch 872/1000\n",
      "176/176 [==============================] - 0s 475us/step - loss: 0.6069 - accuracy: 0.6642 - precision: 0.3846 - recall: 0.0128 \n",
      "Epoch 873/1000\n",
      "176/176 [==============================] - 0s 481us/step - loss: 0.6068 - accuracy: 0.6633 - precision: 0.3696 - recall: 0.0145 \n",
      "Epoch 874/1000\n",
      "176/176 [==============================] - 0s 486us/step - loss: 0.6067 - accuracy: 0.6639 - precision: 0.3864 - recall: 0.0145 \n",
      "Epoch 875/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 481us/step - loss: 0.6067 - accuracy: 0.6633 - precision: 0.3800 - recall: 0.0163 \n",
      "Epoch 876/1000\n",
      "176/176 [==============================] - 0s 483us/step - loss: 0.6066 - accuracy: 0.6653 - precision: 0.4286 - recall: 0.0128\n",
      "Epoch 877/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6065 - accuracy: 0.6639 - precision: 0.3864 - recall: 0.0145 \n",
      "Epoch 878/1000\n",
      "176/176 [==============================] - 0s 482us/step - loss: 0.6065 - accuracy: 0.6642 - precision: 0.3846 - recall: 0.0128 \n",
      "Epoch 879/1000\n",
      "176/176 [==============================] - 0s 464us/step - loss: 0.6064 - accuracy: 0.6639 - precision: 0.3810 - recall: 0.0137\n",
      "Epoch 880/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6063 - accuracy: 0.6639 - precision: 0.3810 - recall: 0.0137 \n",
      "Epoch 881/1000\n",
      "176/176 [==============================] - 0s 471us/step - loss: 0.6062 - accuracy: 0.6633 - precision: 0.3750 - recall: 0.0154 \n",
      "Epoch 882/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6062 - accuracy: 0.6636 - precision: 0.3778 - recall: 0.0145 \n",
      "Epoch 883/1000\n",
      "176/176 [==============================] - 0s 484us/step - loss: 0.6061 - accuracy: 0.6633 - precision: 0.3571 - recall: 0.0128 \n",
      "Epoch 884/1000\n",
      "176/176 [==============================] - 0s 495us/step - loss: 0.6060 - accuracy: 0.6642 - precision: 0.3902 - recall: 0.0137 \n",
      "Epoch 885/1000\n",
      "176/176 [==============================] - 0s 464us/step - loss: 0.6060 - accuracy: 0.6633 - precision: 0.3696 - recall: 0.0145 \n",
      "Epoch 886/1000\n",
      "176/176 [==============================] - 0s 487us/step - loss: 0.6059 - accuracy: 0.6648 - precision: 0.4103 - recall: 0.0137 \n",
      "Epoch 887/1000\n",
      "176/176 [==============================] - 0s 425us/step - loss: 0.6058 - accuracy: 0.6631 - precision: 0.3556 - recall: 0.0137 \n",
      "Epoch 888/1000\n",
      "176/176 [==============================] - 0s 442us/step - loss: 0.6058 - accuracy: 0.6633 - precision: 0.3696 - recall: 0.0145 \n",
      "Epoch 889/1000\n",
      "176/176 [==============================] - 0s 488us/step - loss: 0.6057 - accuracy: 0.6631 - precision: 0.3673 - recall: 0.0154 \n",
      "Epoch 890/1000\n",
      "176/176 [==============================] - 0s 495us/step - loss: 0.6056 - accuracy: 0.6633 - precision: 0.3750 - recall: 0.0154 \n",
      "Epoch 891/1000\n",
      "176/176 [==============================] - 0s 470us/step - loss: 0.6055 - accuracy: 0.6636 - precision: 0.3830 - recall: 0.0154 \n",
      "Epoch 892/1000\n",
      "176/176 [==============================] - 0s 489us/step - loss: 0.6055 - accuracy: 0.6633 - precision: 0.3696 - recall: 0.0145 \n",
      "Epoch 893/1000\n",
      "176/176 [==============================] - 0s 471us/step - loss: 0.6054 - accuracy: 0.6636 - precision: 0.3878 - recall: 0.0163 \n",
      "Epoch 894/1000\n",
      "176/176 [==============================] - 0s 475us/step - loss: 0.6053 - accuracy: 0.6631 - precision: 0.3617 - recall: 0.0145 \n",
      "Epoch 895/1000\n",
      "176/176 [==============================] - 0s 494us/step - loss: 0.6053 - accuracy: 0.6633 - precision: 0.3800 - recall: 0.0163 \n",
      "Epoch 896/1000\n",
      "176/176 [==============================] - 0s 466us/step - loss: 0.6052 - accuracy: 0.6633 - precision: 0.3800 - recall: 0.0163 \n",
      "Epoch 897/1000\n",
      "176/176 [==============================] - 0s 457us/step - loss: 0.6051 - accuracy: 0.6645 - precision: 0.4048 - recall: 0.0145 \n",
      "Epoch 898/1000\n",
      "176/176 [==============================] - 0s 489us/step - loss: 0.6051 - accuracy: 0.6628 - precision: 0.3478 - recall: 0.0137 \n",
      "Epoch 899/1000\n",
      "176/176 [==============================] - 0s 481us/step - loss: 0.6050 - accuracy: 0.6631 - precision: 0.3617 - recall: 0.0145 \n",
      "Epoch 900/1000\n",
      "176/176 [==============================] - 0s 502us/step - loss: 0.6049 - accuracy: 0.6633 - precision: 0.3889 - recall: 0.0180 \n",
      "Epoch 901/1000\n",
      "176/176 [==============================] - 0s 472us/step - loss: 0.6048 - accuracy: 0.6633 - precision: 0.3846 - recall: 0.0171 \n",
      "Epoch 902/1000\n",
      "176/176 [==============================] - 0s 751us/step - loss: 0.6048 - accuracy: 0.6636 - precision: 0.3830 - recall: 0.0154\n",
      "Epoch 903/1000\n",
      "176/176 [==============================] - 0s 811us/step - loss: 0.6047 - accuracy: 0.6639 - precision: 0.4000 - recall: 0.0171\n",
      "Epoch 904/1000\n",
      "176/176 [==============================] - 0s 640us/step - loss: 0.6046 - accuracy: 0.6625 - precision: 0.3529 - recall: 0.0154\n",
      "Epoch 905/1000\n",
      "176/176 [==============================] - 0s 464us/step - loss: 0.6046 - accuracy: 0.6631 - precision: 0.3617 - recall: 0.0145\n",
      "Epoch 906/1000\n",
      "176/176 [==============================] - 0s 455us/step - loss: 0.6045 - accuracy: 0.6633 - precision: 0.3800 - recall: 0.0163 \n",
      "Epoch 907/1000\n",
      "176/176 [==============================] - 0s 431us/step - loss: 0.6044 - accuracy: 0.6631 - precision: 0.3617 - recall: 0.0145 \n",
      "Epoch 908/1000\n",
      "176/176 [==============================] - 0s 440us/step - loss: 0.6043 - accuracy: 0.6625 - precision: 0.3684 - recall: 0.0180 \n",
      "Epoch 909/1000\n",
      "176/176 [==============================] - 0s 431us/step - loss: 0.6043 - accuracy: 0.6636 - precision: 0.3962 - recall: 0.0180 \n",
      "Epoch 910/1000\n",
      "176/176 [==============================] - 0s 426us/step - loss: 0.6042 - accuracy: 0.6631 - precision: 0.3725 - recall: 0.0163 \n",
      "Epoch 911/1000\n",
      "176/176 [==============================] - 0s 428us/step - loss: 0.6041 - accuracy: 0.6639 - precision: 0.4038 - recall: 0.0180 \n",
      "Epoch 912/1000\n",
      "176/176 [==============================] - 0s 428us/step - loss: 0.6040 - accuracy: 0.6633 - precision: 0.3800 - recall: 0.0163 \n",
      "Epoch 913/1000\n",
      "176/176 [==============================] - 0s 418us/step - loss: 0.6040 - accuracy: 0.6631 - precision: 0.3818 - recall: 0.0180\n",
      "Epoch 914/1000\n",
      "176/176 [==============================] - 0s 427us/step - loss: 0.6039 - accuracy: 0.6628 - precision: 0.3654 - recall: 0.0163 \n",
      "Epoch 915/1000\n",
      "176/176 [==============================] - 0s 428us/step - loss: 0.6038 - accuracy: 0.6628 - precision: 0.3750 - recall: 0.0180 \n",
      "Epoch 916/1000\n",
      "176/176 [==============================] - 0s 434us/step - loss: 0.6037 - accuracy: 0.6631 - precision: 0.3818 - recall: 0.0180\n",
      "Epoch 917/1000\n",
      "176/176 [==============================] - 0s 425us/step - loss: 0.6037 - accuracy: 0.6631 - precision: 0.3673 - recall: 0.0154 \n",
      "Epoch 918/1000\n",
      "176/176 [==============================] - 0s 419us/step - loss: 0.6036 - accuracy: 0.6636 - precision: 0.3830 - recall: 0.0154 \n",
      "Epoch 919/1000\n",
      "176/176 [==============================] - 0s 439us/step - loss: 0.6035 - accuracy: 0.6628 - precision: 0.3750 - recall: 0.0180 \n",
      "Epoch 920/1000\n",
      "176/176 [==============================] - 0s 433us/step - loss: 0.6035 - accuracy: 0.6619 - precision: 0.3559 - recall: 0.0180 \n",
      "Epoch 921/1000\n",
      "176/176 [==============================] - 0s 424us/step - loss: 0.6034 - accuracy: 0.6625 - precision: 0.3636 - recall: 0.0171 \n",
      "Epoch 922/1000\n",
      "176/176 [==============================] - 0s 418us/step - loss: 0.6033 - accuracy: 0.6628 - precision: 0.3833 - recall: 0.0197 \n",
      "Epoch 923/1000\n",
      "176/176 [==============================] - 0s 424us/step - loss: 0.6033 - accuracy: 0.6622 - precision: 0.3667 - recall: 0.0188 \n",
      "Epoch 924/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6032 - accuracy: 0.6619 - precision: 0.3559 - recall: 0.0180 \n",
      "Epoch 925/1000\n",
      "176/176 [==============================] - 0s 487us/step - loss: 0.6031 - accuracy: 0.6622 - precision: 0.3788 - recall: 0.0214 \n",
      "Epoch 926/1000\n",
      "176/176 [==============================] - 0s 487us/step - loss: 0.6031 - accuracy: 0.6636 - precision: 0.3878 - recall: 0.0163 \n",
      "Epoch 927/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6030 - accuracy: 0.6622 - precision: 0.3667 - recall: 0.0188 \n",
      "Epoch 928/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.6029 - accuracy: 0.6633 - precision: 0.3929 - recall: 0.0188\n",
      "Epoch 929/1000\n",
      "176/176 [==============================] - 0s 467us/step - loss: 0.6028 - accuracy: 0.6625 - precision: 0.3684 - recall: 0.0180 \n",
      "Epoch 930/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6027 - accuracy: 0.6619 - precision: 0.3559 - recall: 0.0180 \n",
      "Epoch 931/1000\n",
      "176/176 [==============================] - 0s 443us/step - loss: 0.6027 - accuracy: 0.6616 - precision: 0.3636 - recall: 0.0205 \n",
      "Epoch 932/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 454us/step - loss: 0.6026 - accuracy: 0.6619 - precision: 0.3651 - recall: 0.0197 \n",
      "Epoch 933/1000\n",
      "176/176 [==============================] - 0s 519us/step - loss: 0.6025 - accuracy: 0.6625 - precision: 0.3770 - recall: 0.0197 \n",
      "Epoch 934/1000\n",
      "176/176 [==============================] - 0s 468us/step - loss: 0.6025 - accuracy: 0.6622 - precision: 0.3519 - recall: 0.0163 \n",
      "Epoch 935/1000\n",
      "176/176 [==============================] - 0s 467us/step - loss: 0.6024 - accuracy: 0.6625 - precision: 0.3770 - recall: 0.0197 \n",
      "Epoch 936/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6023 - accuracy: 0.6622 - precision: 0.3824 - recall: 0.0222\n",
      "Epoch 937/1000\n",
      "176/176 [==============================] - 0s 435us/step - loss: 0.6023 - accuracy: 0.6628 - precision: 0.4000 - recall: 0.0240\n",
      "Epoch 938/1000\n",
      "176/176 [==============================] - 0s 450us/step - loss: 0.6022 - accuracy: 0.6625 - precision: 0.3684 - recall: 0.0180 \n",
      "Epoch 939/1000\n",
      "176/176 [==============================] - 0s 444us/step - loss: 0.6021 - accuracy: 0.6625 - precision: 0.3684 - recall: 0.0180 \n",
      "Epoch 940/1000\n",
      "176/176 [==============================] - 0s 441us/step - loss: 0.6020 - accuracy: 0.6628 - precision: 0.3793 - recall: 0.0188 \n",
      "Epoch 941/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6020 - accuracy: 0.6625 - precision: 0.3881 - recall: 0.0222 \n",
      "Epoch 942/1000\n",
      "176/176 [==============================] - 0s 460us/step - loss: 0.6019 - accuracy: 0.6613 - precision: 0.3623 - recall: 0.0214\n",
      "Epoch 943/1000\n",
      "176/176 [==============================] - 0s 429us/step - loss: 0.6018 - accuracy: 0.6616 - precision: 0.3548 - recall: 0.0188 \n",
      "Epoch 944/1000\n",
      "176/176 [==============================] - 0s 449us/step - loss: 0.6018 - accuracy: 0.6616 - precision: 0.3816 - recall: 0.0248 \n",
      "Epoch 945/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6017 - accuracy: 0.6616 - precision: 0.3636 - recall: 0.0205 \n",
      "Epoch 946/1000\n",
      "176/176 [==============================] - 0s 472us/step - loss: 0.6016 - accuracy: 0.6619 - precision: 0.3731 - recall: 0.0214 \n",
      "Epoch 947/1000\n",
      "176/176 [==============================] - 0s 459us/step - loss: 0.6015 - accuracy: 0.6631 - precision: 0.4000 - recall: 0.0222 \n",
      "Epoch 948/1000\n",
      "176/176 [==============================] - 0s 537us/step - loss: 0.6015 - accuracy: 0.6631 - precision: 0.3774 - recall: 0.0171 \n",
      "Epoch 949/1000\n",
      "176/176 [==============================] - 0s 485us/step - loss: 0.6014 - accuracy: 0.6622 - precision: 0.3824 - recall: 0.0222 \n",
      "Epoch 950/1000\n",
      "176/176 [==============================] - 0s 474us/step - loss: 0.6013 - accuracy: 0.6625 - precision: 0.3729 - recall: 0.0188 \n",
      "Epoch 951/1000\n",
      "176/176 [==============================] - 0s 470us/step - loss: 0.6013 - accuracy: 0.6625 - precision: 0.3944 - recall: 0.0240 \n",
      "Epoch 952/1000\n",
      "176/176 [==============================] - 0s 448us/step - loss: 0.6012 - accuracy: 0.6622 - precision: 0.3824 - recall: 0.0222 \n",
      "Epoch 953/1000\n",
      "176/176 [==============================] - 0s 467us/step - loss: 0.6011 - accuracy: 0.6625 - precision: 0.4026 - recall: 0.0265 \n",
      "Epoch 954/1000\n",
      "176/176 [==============================] - 0s 442us/step - loss: 0.6010 - accuracy: 0.6622 - precision: 0.3857 - recall: 0.0231 \n",
      "Epoch 955/1000\n",
      "176/176 [==============================] - 0s 447us/step - loss: 0.6009 - accuracy: 0.6622 - precision: 0.3824 - recall: 0.0222 \n",
      "Epoch 956/1000\n",
      "176/176 [==============================] - 0s 517us/step - loss: 0.6009 - accuracy: 0.6622 - precision: 0.3947 - recall: 0.0257 \n",
      "Epoch 957/1000\n",
      "176/176 [==============================] - 0s 492us/step - loss: 0.6008 - accuracy: 0.6622 - precision: 0.3889 - recall: 0.0240\n",
      "Epoch 958/1000\n",
      "176/176 [==============================] - 0s 463us/step - loss: 0.6007 - accuracy: 0.6613 - precision: 0.3623 - recall: 0.0214 \n",
      "Epoch 959/1000\n",
      "176/176 [==============================] - 0s 478us/step - loss: 0.6006 - accuracy: 0.6622 - precision: 0.3919 - recall: 0.0248 \n",
      "Epoch 960/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.6006 - accuracy: 0.6619 - precision: 0.3803 - recall: 0.0231 \n",
      "Epoch 961/1000\n",
      "176/176 [==============================] - 0s 476us/step - loss: 0.6005 - accuracy: 0.6642 - precision: 0.4494 - recall: 0.0342 \n",
      "Epoch 962/1000\n",
      "176/176 [==============================] - 0s 468us/step - loss: 0.6004 - accuracy: 0.6619 - precision: 0.3951 - recall: 0.0274 \n",
      "Epoch 963/1000\n",
      "176/176 [==============================] - 0s 465us/step - loss: 0.6003 - accuracy: 0.6619 - precision: 0.3896 - recall: 0.0257 \n",
      "Epoch 964/1000\n",
      "176/176 [==============================] - 0s 467us/step - loss: 0.6003 - accuracy: 0.6619 - precision: 0.3867 - recall: 0.0248 \n",
      "Epoch 965/1000\n",
      "176/176 [==============================] - 0s 464us/step - loss: 0.6002 - accuracy: 0.6622 - precision: 0.3889 - recall: 0.0240 \n",
      "Epoch 966/1000\n",
      "176/176 [==============================] - 0s 472us/step - loss: 0.6002 - accuracy: 0.6645 - precision: 0.4535 - recall: 0.0334 \n",
      "Epoch 967/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.6001 - accuracy: 0.6628 - precision: 0.3793 - recall: 0.0188 \n",
      "Epoch 968/1000\n",
      "176/176 [==============================] - 0s 458us/step - loss: 0.6000 - accuracy: 0.6616 - precision: 0.3750 - recall: 0.0231 \n",
      "Epoch 969/1000\n",
      "176/176 [==============================] - 0s 508us/step - loss: 0.5999 - accuracy: 0.6631 - precision: 0.4177 - recall: 0.0282 \n",
      "Epoch 970/1000\n",
      "176/176 [==============================] - 0s 481us/step - loss: 0.5999 - accuracy: 0.6639 - precision: 0.4457 - recall: 0.0351 \n",
      "Epoch 971/1000\n",
      "176/176 [==============================] - 0s 475us/step - loss: 0.5998 - accuracy: 0.6648 - precision: 0.4624 - recall: 0.0368 \n",
      "Epoch 972/1000\n",
      "176/176 [==============================] - 0s 474us/step - loss: 0.5997 - accuracy: 0.6616 - precision: 0.3784 - recall: 0.0240 \n",
      "Epoch 973/1000\n",
      "176/176 [==============================] - 0s 464us/step - loss: 0.5996 - accuracy: 0.6619 - precision: 0.3867 - recall: 0.0248\n",
      "Epoch 974/1000\n",
      "176/176 [==============================] - 0s 460us/step - loss: 0.5996 - accuracy: 0.6631 - precision: 0.4156 - recall: 0.0274 \n",
      "Epoch 975/1000\n",
      "176/176 [==============================] - 0s 463us/step - loss: 0.5995 - accuracy: 0.6636 - precision: 0.4321 - recall: 0.0299 \n",
      "Epoch 976/1000\n",
      "176/176 [==============================] - 0s 461us/step - loss: 0.5994 - accuracy: 0.6622 - precision: 0.3947 - recall: 0.0257 \n",
      "Epoch 977/1000\n",
      "176/176 [==============================] - 0s 480us/step - loss: 0.5994 - accuracy: 0.6633 - precision: 0.4318 - recall: 0.0325 \n",
      "Epoch 978/1000\n",
      "176/176 [==============================] - 0s 513us/step - loss: 0.5993 - accuracy: 0.6628 - precision: 0.4146 - recall: 0.0291 \n",
      "Epoch 979/1000\n",
      "176/176 [==============================] - 0s 468us/step - loss: 0.5992 - accuracy: 0.6628 - precision: 0.4028 - recall: 0.0248 \n",
      "Epoch 980/1000\n",
      "176/176 [==============================] - 0s 495us/step - loss: 0.5991 - accuracy: 0.6628 - precision: 0.4146 - recall: 0.0291 \n",
      "Epoch 981/1000\n",
      "176/176 [==============================] - 0s 494us/step - loss: 0.5991 - accuracy: 0.6628 - precision: 0.4103 - recall: 0.0274 \n",
      "Epoch 982/1000\n",
      "176/176 [==============================] - 0s 487us/step - loss: 0.5990 - accuracy: 0.6636 - precision: 0.4396 - recall: 0.0342 \n",
      "Epoch 983/1000\n",
      "176/176 [==============================] - 0s 509us/step - loss: 0.5989 - accuracy: 0.6639 - precision: 0.4405 - recall: 0.0317 \n",
      "Epoch 984/1000\n",
      "176/176 [==============================] - 0s 517us/step - loss: 0.5988 - accuracy: 0.6636 - precision: 0.4304 - recall: 0.0291 \n",
      "Epoch 985/1000\n",
      "176/176 [==============================] - 0s 497us/step - loss: 0.5988 - accuracy: 0.6636 - precision: 0.4353 - recall: 0.0317 \n",
      "Epoch 986/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.5987 - accuracy: 0.6642 - precision: 0.4458 - recall: 0.0317 \n",
      "Epoch 987/1000\n",
      "176/176 [==============================] - 0s 462us/step - loss: 0.5986 - accuracy: 0.6642 - precision: 0.4526 - recall: 0.0368 \n",
      "Epoch 988/1000\n",
      "176/176 [==============================] - 0s 467us/step - loss: 0.5986 - accuracy: 0.6645 - precision: 0.4565 - recall: 0.0359 \n",
      "Epoch 989/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 462us/step - loss: 0.5985 - accuracy: 0.6636 - precision: 0.4353 - recall: 0.0317 \n",
      "Epoch 990/1000\n",
      "176/176 [==============================] - 0s 482us/step - loss: 0.5984 - accuracy: 0.6639 - precision: 0.4419 - recall: 0.0325 \n",
      "Epoch 991/1000\n",
      "176/176 [==============================] - 0s 540us/step - loss: 0.5983 - accuracy: 0.6636 - precision: 0.4337 - recall: 0.0308 \n",
      "Epoch 992/1000\n",
      "176/176 [==============================] - 0s 526us/step - loss: 0.5982 - accuracy: 0.6633 - precision: 0.4333 - recall: 0.0334 \n",
      "Epoch 993/1000\n",
      "176/176 [==============================] - 0s 473us/step - loss: 0.5982 - accuracy: 0.6642 - precision: 0.4471 - recall: 0.0325 \n",
      "Epoch 994/1000\n",
      "176/176 [==============================] - 0s 496us/step - loss: 0.5981 - accuracy: 0.6639 - precision: 0.4444 - recall: 0.0342\n",
      "Epoch 995/1000\n",
      "176/176 [==============================] - 0s 492us/step - loss: 0.5980 - accuracy: 0.6642 - precision: 0.4483 - recall: 0.0334 \n",
      "Epoch 996/1000\n",
      "176/176 [==============================] - 0s 445us/step - loss: 0.5980 - accuracy: 0.6639 - precision: 0.4405 - recall: 0.0317 \n",
      "Epoch 997/1000\n",
      "176/176 [==============================] - 0s 487us/step - loss: 0.5979 - accuracy: 0.6710 - precision: 0.5556 - recall: 0.0642 \n",
      "Epoch 998/1000\n",
      "176/176 [==============================] - 0s 506us/step - loss: 0.5978 - accuracy: 0.6636 - precision: 0.4382 - recall: 0.0334\n",
      "Epoch 999/1000\n",
      "176/176 [==============================] - 0s 550us/step - loss: 0.5977 - accuracy: 0.6645 - precision: 0.4545 - recall: 0.0342\n",
      "Epoch 1000/1000\n",
      "176/176 [==============================] - 0s 511us/step - loss: 0.5977 - accuracy: 0.6682 - precision: 0.5207 - recall: 0.0539 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b7f6b2e0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model with data \n",
    "model2.fit(X_resampled2, y_resampled2, epochs=1000, batch_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "530933fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 815us/step\n"
     ]
    }
   ],
   "source": [
    "predictions2 = model2.predict(X_test2)\n",
    "y_pred2 = [\n",
    "    1 if prob > 0.5 else 0 for prob in np.ravel(predictions)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4bb7c144",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Neural Network 2\n",
      "Accuracy: 0.9504672897196261\n",
      "Recall: 0.021739130434782608\n",
      "Precision: 0.1111111111111111\n",
      "F1 Score: 0.03636363636363637\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[   1   45]\n",
      " [   8 1016]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1024\n",
      "           1       0.11      0.02      0.04        46\n",
      "\n",
      "    accuracy                           0.95      1070\n",
      "   macro avg       0.53      0.51      0.51      1070\n",
      "weighted avg       0.92      0.95      0.93      1070\n",
      "\n",
      "[0.9504672897196261, 0.021739130434782608, 0.1111111111111111, 0.03636363636363637]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_model_results_nn(\"Neural Network 2\", predictions2, y_pred2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b73ce0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
